{"custom_metrics": {"rewards/0_mean": 13.301619309645433, "rewards/0_min": -0.715484619140625, "rewards/0_max": 75.65019226074219, "rewards/1_mean": 13.301619309645433, "rewards/1_min": -0.715484619140625, "rewards/1_max": 75.65019226074219, "rewards/2_mean": 13.301619309645433, "rewards/2_min": -0.715484619140625, "rewards/2_max": 75.65019226074219, "rewards/3_mean": 13.301619309645433, "rewards/3_min": -0.715484619140625, "rewards/3_max": 75.65019226074219, "rewards/4_mean": 13.301619309645433, "rewards/4_min": -0.715484619140625, "rewards/4_max": 75.65019226074219}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.01926027761841262, "policy_loss": -0.0009938075465012203, "vf_loss": 0.15907379705044958, "vf_explained_var": 0.9897344626320733, "kl": 0.008858026779377286, "entropy": 17.778870896233453, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.2989438187192988}, "model": {}, "num_grad_updates_lifetime": 338.0, "diff_num_grad_updates_vs_sampler_policy": 337.0}}, "num_env_steps_sampled": 19527711, "num_env_steps_trained": 19527711, "num_agent_steps_sampled": 19527711, "num_agent_steps_trained": 19527711}, "sampler_results": {"episode_reward_max": 75.65019226074219, "episode_reward_min": -0.715484619140625, "episode_reward_mean": 13.301619309645433, "episode_len_mean": 475.26153846153846, "episode_media": {}, "episodes_this_iter": 130, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 13.301619309645433, "rewards/0_min": -0.715484619140625, "rewards/0_max": 75.65019226074219, "rewards/1_mean": 13.301619309645433, "rewards/1_min": -0.715484619140625, "rewards/1_max": 75.65019226074219, "rewards/2_mean": 13.301619309645433, "rewards/2_min": -0.715484619140625, "rewards/2_max": 75.65019226074219, "rewards/3_mean": 13.301619309645433, "rewards/3_min": -0.715484619140625, "rewards/3_max": 75.65019226074219, "rewards/4_mean": 13.301619309645433, "rewards/4_min": -0.715484619140625, "rewards/4_max": 75.65019226074219}, "hist_stats": {"episode_reward": [5.8730926513671875, 40.4691276550293, 0.0, -0.348236083984375, 0.0, 32.69532012939453, 4.1618194580078125, 34.85064697265625, 12.187530517578125, 0.0, 63.99620056152344, 0.1496124267578125, 43.182373046875, 20.906213760375977, 6.038982391357422, 0.44742584228515625, 0.0, 0.0, 0.1882476806640625, 59.61149597167969, -0.44355010986328125, 5.842353820800781, 0.08068084716796875, 15.120704650878906, 7.9310150146484375, -0.10004425048828125, 3.771341323852539, 54.592411041259766, 27.50098419189453, 0.0, 5.982490539550781, 49.88182830810547, 39.275848388671875, 0.0, 0.0, -0.03272247314453125, 0.0, 35.95252227783203, 59.86713409423828, 0.7131118774414062, 0.0, -0.0042877197265625, 0.0, -0.715484619140625, 0.0, 0.15492630004882812, 0.3238334655761719, 28.864425659179688, 38.922279357910156, 48.06755065917969, 7.047719955444336, 39.98232078552246, 20.164594650268555, 0.41019439697265625, 22.186187744140625, 0.832977294921875, 0.0, 1.3143692016601562, 0.0, 0.0, 22.190364837646484, 0.0, 56.05546569824219, 3.3395462036132812, 0.11305999755859375, 20.60552978515625, 46.657554626464844, 0.0, 60.25083923339844, 0.0, 0.4831085205078125, 49.23843002319336, 0.0, 0.0, 0.0, 16.762025833129883, 0.0, 19.63974380493164, 2.94879150390625, 45.19778823852539, 0.1080780029296875, 0.370635986328125, 13.84820556640625, 15.103073120117188, 0.0, 0.0, 8.414417266845703, 13.098098754882812, 2.1997299194335938, 37.39023017883301, 9.41379165649414, 47.727745056152344, 0.0, 0.2801513671875, 5.4093475341796875, -0.26027679443359375, 0.09403228759765625, 0.0, 0.0, 72.9151382446289, -0.02264404296875, 19.55889892578125, 0.0, 0.0, 1.3307571411132812, 10.335165023803711, 0.0, -0.6120147705078125, 40.34029769897461, 0.0, 0.0, -0.1758575439453125, 0.0, 63.75138854980469, 0.0018157958984375, 0.25843048095703125, 30.585723876953125, 0.0, -0.10628509521484375, 0.0, 14.366661071777344, -0.1254425048828125, 21.386245727539062, 75.65019226074219, 0.0, 0.0, 44.82847595214844, 0.0, 0.0, 0.366485595703125], "episode_lengths": [268, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 264, 500, 254, 466, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 295, 326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 210, 500, 198, 251, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 177, 500, 500, 43, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.402659285875098, "mean_inference_ms": 4.841477228823506, "mean_action_processing_ms": 7.703495608613347, "mean_env_wait_ms": 11.269373341905231, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 75.65019226074219, "episode_reward_min": -0.715484619140625, "episode_reward_mean": 13.301619309645433, "episode_len_mean": 475.26153846153846, "episodes_this_iter": 130, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [5.8730926513671875, 40.4691276550293, 0.0, -0.348236083984375, 0.0, 32.69532012939453, 4.1618194580078125, 34.85064697265625, 12.187530517578125, 0.0, 63.99620056152344, 0.1496124267578125, 43.182373046875, 20.906213760375977, 6.038982391357422, 0.44742584228515625, 0.0, 0.0, 0.1882476806640625, 59.61149597167969, -0.44355010986328125, 5.842353820800781, 0.08068084716796875, 15.120704650878906, 7.9310150146484375, -0.10004425048828125, 3.771341323852539, 54.592411041259766, 27.50098419189453, 0.0, 5.982490539550781, 49.88182830810547, 39.275848388671875, 0.0, 0.0, -0.03272247314453125, 0.0, 35.95252227783203, 59.86713409423828, 0.7131118774414062, 0.0, -0.0042877197265625, 0.0, -0.715484619140625, 0.0, 0.15492630004882812, 0.3238334655761719, 28.864425659179688, 38.922279357910156, 48.06755065917969, 7.047719955444336, 39.98232078552246, 20.164594650268555, 0.41019439697265625, 22.186187744140625, 0.832977294921875, 0.0, 1.3143692016601562, 0.0, 0.0, 22.190364837646484, 0.0, 56.05546569824219, 3.3395462036132812, 0.11305999755859375, 20.60552978515625, 46.657554626464844, 0.0, 60.25083923339844, 0.0, 0.4831085205078125, 49.23843002319336, 0.0, 0.0, 0.0, 16.762025833129883, 0.0, 19.63974380493164, 2.94879150390625, 45.19778823852539, 0.1080780029296875, 0.370635986328125, 13.84820556640625, 15.103073120117188, 0.0, 0.0, 8.414417266845703, 13.098098754882812, 2.1997299194335938, 37.39023017883301, 9.41379165649414, 47.727745056152344, 0.0, 0.2801513671875, 5.4093475341796875, -0.26027679443359375, 0.09403228759765625, 0.0, 0.0, 72.9151382446289, -0.02264404296875, 19.55889892578125, 0.0, 0.0, 1.3307571411132812, 10.335165023803711, 0.0, -0.6120147705078125, 40.34029769897461, 0.0, 0.0, -0.1758575439453125, 0.0, 63.75138854980469, 0.0018157958984375, 0.25843048095703125, 30.585723876953125, 0.0, -0.10628509521484375, 0.0, 14.366661071777344, -0.1254425048828125, 21.386245727539062, 75.65019226074219, 0.0, 0.0, 44.82847595214844, 0.0, 0.0, 0.366485595703125], "episode_lengths": [268, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 264, 500, 254, 466, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 295, 326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 210, 500, 198, 251, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 177, 500, 500, 43, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.402659285875098, "mean_inference_ms": 4.841477228823506, "mean_action_processing_ms": 7.703495608613347, "mean_env_wait_ms": 11.269373341905231, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19527711, "num_agent_steps_trained": 19527711, "num_env_steps_sampled": 19527711, "num_env_steps_trained": 19527711, "num_env_steps_sampled_this_iter": 61784, "num_env_steps_trained_this_iter": 61784, "timesteps_total": 19527711, "num_steps_trained_this_iter": 61784, "agent_timesteps_total": 19527711, "timers": {"training_iteration_time_ms": 56956.299, "load_time_ms": 46.881, "load_throughput": 1317884.386, "learn_time_ms": 28339.656, "learn_throughput": 2180.125, "synch_weights_time_ms": 18.705}, "counters": {"num_env_steps_sampled": 19527711, "num_env_steps_trained": 19527711, "num_agent_steps_sampled": 19527711, "num_agent_steps_trained": 19527711}, "done": false, "episodes_total": 39532, "training_iteration": 322, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-23-22", "timestamp": 1735107802, "time_this_iter_s": 56.966315507888794, "time_total_s": 8914.096214294434, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE51B0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E37553F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 56.966315507888794, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 25.803703703703707, "ram_util_percent": 92.66913580246913}}
{"custom_metrics": {"rewards/0_mean": 11.344221420288086, "rewards/0_min": -0.8692626953125, "rewards/0_max": 79.04386520385742, "rewards/1_mean": 11.344221420288086, "rewards/1_min": -0.8692626953125, "rewards/1_max": 79.04386520385742, "rewards/2_mean": 11.344221420288086, "rewards/2_min": -0.8692626953125, "rewards/2_max": 79.04386520385742, "rewards/3_mean": 11.344221420288086, "rewards/3_min": -0.8692626953125, "rewards/3_max": 79.04386520385742, "rewards/4_mean": 11.344221420288086, "rewards/4_min": -0.8692626953125, "rewards/4_max": 79.04386520385742}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08321754964135979, "policy_loss": -0.0029438767530437972, "vf_loss": 0.11631453551170934, "vf_explained_var": 0.9830406201264215, "kl": 0.012947694231416024, "entropy": 19.724369086916486, "entropy_coeff": 0.01, "grad_gnorm": 1.41060079812767}, "model": {}, "num_grad_updates_lifetime": 990.5, "diff_num_grad_updates_vs_sampler_policy": 989.5}}, "num_env_steps_sampled": 19588734, "num_env_steps_trained": 19588734, "num_agent_steps_sampled": 19588734, "num_agent_steps_trained": 19588734}, "sampler_results": {"episode_reward_max": 79.04386520385742, "episode_reward_min": -0.8692626953125, "episode_reward_mean": 11.344221420288086, "episode_len_mean": 488.184, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.344221420288086, "rewards/0_min": -0.8692626953125, "rewards/0_max": 79.04386520385742, "rewards/1_mean": 11.344221420288086, "rewards/1_min": -0.8692626953125, "rewards/1_max": 79.04386520385742, "rewards/2_mean": 11.344221420288086, "rewards/2_min": -0.8692626953125, "rewards/2_max": 79.04386520385742, "rewards/3_mean": 11.344221420288086, "rewards/3_min": -0.8692626953125, "rewards/3_max": 79.04386520385742, "rewards/4_mean": 11.344221420288086, "rewards/4_min": -0.8692626953125, "rewards/4_max": 79.04386520385742}, "hist_stats": {"episode_reward": [17.039453506469727, 0.0, 0.0, 7.858074188232422, -0.020843505859375, 52.29619598388672, 0.0, 0.0, 0.0, 0.0, 10.885040283203125, 16.6754150390625, 5.8462982177734375, 19.955123901367188, 0.0, 70.08643341064453, 0.0, 39.935123443603516, 21.03559112548828, 36.6116943359375, 32.074867248535156, 24.728965759277344, 0.0, 43.723182678222656, 12.555816650390625, 0.4668159484863281, 29.2669677734375, 0.0, 24.212356567382812, -0.14703369140625, -0.369415283203125, 0.0, 0.0, -0.378265380859375, -0.8692626953125, 0.0, -0.2581634521484375, 0.0, 0.0, 0.0, 0.205963134765625, 0.0, 53.395263671875, -0.0770721435546875, 0.0, 0.014892578125, 0.05693817138671875, 0.0, 11.517133712768555, 0.0, 0.34181976318359375, 46.35322570800781, 0.0, 0.0, -0.13578033447265625, 25.9298095703125, 0.0, 0.0, 19.725910186767578, 0.0, 0.0, 0.0, 19.495147705078125, 0.0, 0.0, 0.0, -0.10906791687011719, 0.10543060302734375, 5.4452972412109375, 0.0, 0.0, -0.0629425048828125, 31.230079650878906, 31.567745208740234, -0.0170440673828125, 2.298583984375, 56.078535079956055, 65.71213150024414, 0.5360221862792969, 23.35015869140625, 0.028839111328125, 5.0444488525390625, 0.0, 36.6998291015625, 79.04386520385742, 27.315322875976562, 0.0, -0.1470184326171875, 2.5285110473632812, 0.0, 6.295440673828125, 16.333877563476562, 0.0, 7.144401550292969, 5.9706268310546875, 0.1543731689453125, 46.808937072753906, 0.3811607360839844, 0.0, 0.0486907958984375, 29.897361755371094, 75.33763694763184, 0.0, 0.0, 0.0, 61.54821014404297, -0.2622528076171875, -0.23022842407226562, 0.0, 19.90430450439453, 0.0, 9.310714721679688, 7.0699615478515625, -0.032306671142578125, 43.30682373046875, 0.0, 0.0, 11.015762329101562, 0.7051849365234375, 4.1847991943359375, 0.0, 7.327934265136719, -0.1049041748046875, 5.668041229248047, 53.56071472167969], "episode_lengths": [278, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 265, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 447, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 398, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 344, 460, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 436, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.288989440933204, "mean_inference_ms": 4.929716185543431, "mean_action_processing_ms": 7.640673312706938, "mean_env_wait_ms": 11.330078714637358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 79.04386520385742, "episode_reward_min": -0.8692626953125, "episode_reward_mean": 11.344221420288086, "episode_len_mean": 488.184, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [17.039453506469727, 0.0, 0.0, 7.858074188232422, -0.020843505859375, 52.29619598388672, 0.0, 0.0, 0.0, 0.0, 10.885040283203125, 16.6754150390625, 5.8462982177734375, 19.955123901367188, 0.0, 70.08643341064453, 0.0, 39.935123443603516, 21.03559112548828, 36.6116943359375, 32.074867248535156, 24.728965759277344, 0.0, 43.723182678222656, 12.555816650390625, 0.4668159484863281, 29.2669677734375, 0.0, 24.212356567382812, -0.14703369140625, -0.369415283203125, 0.0, 0.0, -0.378265380859375, -0.8692626953125, 0.0, -0.2581634521484375, 0.0, 0.0, 0.0, 0.205963134765625, 0.0, 53.395263671875, -0.0770721435546875, 0.0, 0.014892578125, 0.05693817138671875, 0.0, 11.517133712768555, 0.0, 0.34181976318359375, 46.35322570800781, 0.0, 0.0, -0.13578033447265625, 25.9298095703125, 0.0, 0.0, 19.725910186767578, 0.0, 0.0, 0.0, 19.495147705078125, 0.0, 0.0, 0.0, -0.10906791687011719, 0.10543060302734375, 5.4452972412109375, 0.0, 0.0, -0.0629425048828125, 31.230079650878906, 31.567745208740234, -0.0170440673828125, 2.298583984375, 56.078535079956055, 65.71213150024414, 0.5360221862792969, 23.35015869140625, 0.028839111328125, 5.0444488525390625, 0.0, 36.6998291015625, 79.04386520385742, 27.315322875976562, 0.0, -0.1470184326171875, 2.5285110473632812, 0.0, 6.295440673828125, 16.333877563476562, 0.0, 7.144401550292969, 5.9706268310546875, 0.1543731689453125, 46.808937072753906, 0.3811607360839844, 0.0, 0.0486907958984375, 29.897361755371094, 75.33763694763184, 0.0, 0.0, 0.0, 61.54821014404297, -0.2622528076171875, -0.23022842407226562, 0.0, 19.90430450439453, 0.0, 9.310714721679688, 7.0699615478515625, -0.032306671142578125, 43.30682373046875, 0.0, 0.0, 11.015762329101562, 0.7051849365234375, 4.1847991943359375, 0.0, 7.327934265136719, -0.1049041748046875, 5.668041229248047, 53.56071472167969], "episode_lengths": [278, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 265, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 447, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 398, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 344, 460, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 436, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.288989440933204, "mean_inference_ms": 4.929716185543431, "mean_action_processing_ms": 7.640673312706938, "mean_env_wait_ms": 11.330078714637358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19588734, "num_agent_steps_trained": 19588734, "num_env_steps_sampled": 19588734, "num_env_steps_trained": 19588734, "num_env_steps_sampled_this_iter": 61023, "num_env_steps_trained_this_iter": 61023, "timesteps_total": 19588734, "num_steps_trained_this_iter": 61023, "agent_timesteps_total": 19588734, "timers": {"training_iteration_time_ms": 54123.841, "load_time_ms": 52.907, "load_throughput": 1160582.874, "learn_time_ms": 28417.718, "learn_throughput": 2160.747, "synch_weights_time_ms": 14.352}, "counters": {"num_env_steps_sampled": 19588734, "num_env_steps_trained": 19588734, "num_agent_steps_sampled": 19588734, "num_agent_steps_trained": 19588734}, "done": false, "episodes_total": 39657, "training_iteration": 323, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-24-14", "timestamp": 1735107854, "time_this_iter_s": 51.301384925842285, "time_total_s": 8965.397599220276, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B08BB0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E32AD1B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 108.26770043373108, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 27.601388888888884, "ram_util_percent": 93.27222222222221}}
{"custom_metrics": {"rewards/0_mean": 4.798244523220375, "rewards/0_min": -1.1077957153320312, "rewards/0_max": 68.94615173339844, "rewards/1_mean": 4.798244523220375, "rewards/1_min": -1.1077957153320312, "rewards/1_max": 68.94615173339844, "rewards/2_mean": 4.798244523220375, "rewards/2_min": -1.1077957153320312, "rewards/2_max": 68.94615173339844, "rewards/3_mean": 4.798244523220375, "rewards/3_min": -1.1077957153320312, "rewards/3_max": 68.94615173339844, "rewards/4_mean": 4.798244523220375, "rewards/4_min": -1.1077957153320312, "rewards/4_max": 68.94615173339844}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.18335046560932247, "policy_loss": 0.011988338014473104, "vf_loss": 0.04376770122612398, "vf_explained_var": 0.9804666684733496, "kl": 0.012662118396884392, "entropy": 23.974753025599888, "entropy_coeff": 0.01, "grad_gnorm": 1.323793492229685}, "model": {}, "num_grad_updates_lifetime": 1620.5, "diff_num_grad_updates_vs_sampler_policy": 1619.5}}, "num_env_steps_sampled": 19649409, "num_env_steps_trained": 19649409, "num_agent_steps_sampled": 19649409, "num_agent_steps_trained": 19649409}, "sampler_results": {"episode_reward_max": 68.94615173339844, "episode_reward_min": -1.1077957153320312, "episode_reward_mean": 4.798244523220375, "episode_len_mean": 497.3360655737705, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 4.798244523220375, "rewards/0_min": -1.1077957153320312, "rewards/0_max": 68.94615173339844, "rewards/1_mean": 4.798244523220375, "rewards/1_min": -1.1077957153320312, "rewards/1_max": 68.94615173339844, "rewards/2_mean": 4.798244523220375, "rewards/2_min": -1.1077957153320312, "rewards/2_max": 68.94615173339844, "rewards/3_mean": 4.798244523220375, "rewards/3_min": -1.1077957153320312, "rewards/3_max": 68.94615173339844, "rewards/4_mean": 4.798244523220375, "rewards/4_min": -1.1077957153320312, "rewards/4_max": 68.94615173339844}, "hist_stats": {"episode_reward": [0.0, -0.101593017578125, -0.162078857421875, 0.0, 0.0, 12.711021423339844, 0.0, 0.0, 0.0, 17.94952392578125, 0.0, 51.98451232910156, 0.0, 0.0, -0.29967498779296875, 0.0, 0.0, 0.0, -1.1077957153320312, 0.0, 0.0020751953125, 0.22571182250976562, 0.0, 0.0, -0.0690765380859375, 0.0, 0.0, 20.20177459716797, 0.07616424560546875, 0.0, -0.192657470703125, 0.0, 55.06995391845703, 0.19652557373046875, 0.24268341064453125, 0.0, 53.205345153808594, 0.0904693603515625, 68.94615173339844, 0.0, 0.0, -0.3478546142578125, 0.0, 1.0536270141601562, 0.0, 0.0, 0.0, -0.211883544921875, -0.047088623046875, 0.0, 0.0, 0.0, 0.0, 18.119461059570312, 0.14267730712890625, 0.0, 0.6581192016601562, 0.0, 0.0, 2.97003173828125, 0.0284423828125, 13.988639831542969, -0.082427978515625, 0.5189361572265625, 0.0, 0.0, 0.0, 0.0, 0.0, 24.606128692626953, 0.0, 3.52960205078125, 0.6895675659179688, 0.0044708251953125, 41.743059158325195, 10.928951263427734, 0.0, 0.0, 0.0, 0.261077880859375, 0.0, 0.0, 0.0, 46.992916107177734, 5.235439300537109, 0.0, 0.0, 0.0, 0.178863525390625, 0.0, 0.0, 0.0, 0.0, 9.300148010253906, 0.0741119384765625, 0.430419921875, 0.0, 0.0, 0.0, 15.545013427734375, -0.1117706298828125, 0.0, 0.0, 0.0, 0.0, -0.0687408447265625, 31.167781829833984, -0.05348968505859375, 27.474510192871094, 14.260940551757812, 4.3160400390625, -0.4463386535644531, 0.0, 0.0, 0.0, 0.0, 0.328887939453125, -0.0070343017578125, 0.0, 0.0, 0.0, 33.24555969238281], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 206, 500, 500, 500, 500, 469, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.621216300154632, "mean_inference_ms": 4.876486907563853, "mean_action_processing_ms": 7.619726436503175, "mean_env_wait_ms": 11.326523147016276, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 68.94615173339844, "episode_reward_min": -1.1077957153320312, "episode_reward_mean": 4.798244523220375, "episode_len_mean": 497.3360655737705, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, -0.101593017578125, -0.162078857421875, 0.0, 0.0, 12.711021423339844, 0.0, 0.0, 0.0, 17.94952392578125, 0.0, 51.98451232910156, 0.0, 0.0, -0.29967498779296875, 0.0, 0.0, 0.0, -1.1077957153320312, 0.0, 0.0020751953125, 0.22571182250976562, 0.0, 0.0, -0.0690765380859375, 0.0, 0.0, 20.20177459716797, 0.07616424560546875, 0.0, -0.192657470703125, 0.0, 55.06995391845703, 0.19652557373046875, 0.24268341064453125, 0.0, 53.205345153808594, 0.0904693603515625, 68.94615173339844, 0.0, 0.0, -0.3478546142578125, 0.0, 1.0536270141601562, 0.0, 0.0, 0.0, -0.211883544921875, -0.047088623046875, 0.0, 0.0, 0.0, 0.0, 18.119461059570312, 0.14267730712890625, 0.0, 0.6581192016601562, 0.0, 0.0, 2.97003173828125, 0.0284423828125, 13.988639831542969, -0.082427978515625, 0.5189361572265625, 0.0, 0.0, 0.0, 0.0, 0.0, 24.606128692626953, 0.0, 3.52960205078125, 0.6895675659179688, 0.0044708251953125, 41.743059158325195, 10.928951263427734, 0.0, 0.0, 0.0, 0.261077880859375, 0.0, 0.0, 0.0, 46.992916107177734, 5.235439300537109, 0.0, 0.0, 0.0, 0.178863525390625, 0.0, 0.0, 0.0, 0.0, 9.300148010253906, 0.0741119384765625, 0.430419921875, 0.0, 0.0, 0.0, 15.545013427734375, -0.1117706298828125, 0.0, 0.0, 0.0, 0.0, -0.0687408447265625, 31.167781829833984, -0.05348968505859375, 27.474510192871094, 14.260940551757812, 4.3160400390625, -0.4463386535644531, 0.0, 0.0, 0.0, 0.0, 0.328887939453125, -0.0070343017578125, 0.0, 0.0, 0.0, 33.24555969238281], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 206, 500, 500, 500, 500, 469, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.621216300154632, "mean_inference_ms": 4.876486907563853, "mean_action_processing_ms": 7.619726436503175, "mean_env_wait_ms": 11.326523147016276, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19649409, "num_agent_steps_trained": 19649409, "num_env_steps_sampled": 19649409, "num_env_steps_trained": 19649409, "num_env_steps_sampled_this_iter": 60675, "num_env_steps_trained_this_iter": 60675, "timesteps_total": 19649409, "num_steps_trained_this_iter": 60675, "agent_timesteps_total": 19649409, "timers": {"training_iteration_time_ms": 52103.135, "load_time_ms": 63.149, "load_throughput": 968506.686, "learn_time_ms": 27918.845, "learn_throughput": 2190.659, "synch_weights_time_ms": 12.877}, "counters": {"num_env_steps_sampled": 19649409, "num_env_steps_trained": 19649409, "num_agent_steps_sampled": 19649409, "num_agent_steps_trained": 19649409}, "done": false, "episodes_total": 39779, "training_iteration": 324, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-25-02", "timestamp": 1735107902, "time_this_iter_s": 48.071738481521606, "time_total_s": 9013.469337701797, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B09AB0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F49D0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 156.33943891525269, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.898529411764706, "ram_util_percent": 95.03235294117647}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7858257331772003, "mean_inference_ms": 3.632858603776334, "mean_action_processing_ms": 0.5279634289160936, "mean_env_wait_ms": 5.446465905317051, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 14.315067413330079, "rewards/0_min": -0.70501708984375, "rewards/0_max": 77.99330139160156, "rewards/1_mean": 14.315067413330079, "rewards/1_min": -0.70501708984375, "rewards/1_max": 77.99330139160156, "rewards/2_mean": 14.315067413330079, "rewards/2_min": -0.70501708984375, "rewards/2_max": 77.99330139160156, "rewards/3_mean": 14.315067413330079, "rewards/3_min": -0.70501708984375, "rewards/3_max": 77.99330139160156, "rewards/4_mean": 14.315067413330079, "rewards/4_min": -0.70501708984375, "rewards/4_max": 77.99330139160156}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.009538334519011043, "policy_loss": -0.003067553201894736, "vf_loss": 0.18689307643189318, "vf_explained_var": 0.9879305977669973, "kl": 0.013888833436760164, "entropy": 19.406698503948395, "entropy_coeff": 0.01, "grad_gnorm": 1.5079061540346297}, "model": {}, "num_grad_updates_lifetime": 2250.5, "diff_num_grad_updates_vs_sampler_policy": 2249.5}}, "num_env_steps_sampled": 19710679, "num_env_steps_trained": 19710679, "num_agent_steps_sampled": 19710679, "num_agent_steps_trained": 19710679}, "sampler_results": {"episode_reward_max": 77.99330139160156, "episode_reward_min": -0.70501708984375, "episode_reward_mean": 14.315067413330079, "episode_len_mean": 490.16, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 14.315067413330079, "rewards/0_min": -0.70501708984375, "rewards/0_max": 77.99330139160156, "rewards/1_mean": 14.315067413330079, "rewards/1_min": -0.70501708984375, "rewards/1_max": 77.99330139160156, "rewards/2_mean": 14.315067413330079, "rewards/2_min": -0.70501708984375, "rewards/2_max": 77.99330139160156, "rewards/3_mean": 14.315067413330079, "rewards/3_min": -0.70501708984375, "rewards/3_max": 77.99330139160156, "rewards/4_mean": 14.315067413330079, "rewards/4_min": -0.70501708984375, "rewards/4_max": 77.99330139160156}, "hist_stats": {"episode_reward": [0.46068572998046875, 30.824180603027344, -0.70501708984375, 0.165771484375, 0.0, 0.0, 0.0, 51.256805419921875, 0.0, 0.91107177734375, 0.0, 28.13475799560547, 0.0, 0.0, -0.03186798095703125, 33.27787208557129, -0.0282135009765625, 0.0, 0.0, 0.0, 75.95498657226562, 3.7533645629882812, 0.0, -0.14536285400390625, 0.0, 0.0, 57.53792762756348, 0.4159965515136719, 0.6938323974609375, 0.0593109130859375, 0.0, 39.83540344238281, 11.588386535644531, 0.0, 0.0, 77.99330139160156, 37.818565368652344, 10.072189331054688, -0.19196319580078125, 22.688167572021484, 0.0, 57.429317474365234, 0.0433349609375, 0.0, 0.08455657958984375, -0.244415283203125, 0.2284393310546875, 0.0, 43.13128662109375, 6.793279647827148, 37.205474853515625, 0.0, -0.21686553955078125, 69.96185302734375, 48.27960968017578, 20.995498657226562, 51.4549560546875, 0.0, 16.965408325195312, 0.0, 0.0449371337890625, 33.789161682128906, 39.079742431640625, 33.653472900390625, 0.0, 0.0, 7.08721923828125, -0.5106887817382812, 0.0, 0.0, 0.0, 0.09278106689453125, 0.0, 0.0, 48.039466857910156, 0.5373077392578125, 0.0, 0.0, 44.373687744140625, 41.94496154785156, 0.0, 0.0, 0.0, 0.0, 2.9464111328125, -0.0746612548828125, 23.230484008789062, 0.0, 0.0, 1.5051994323730469, 36.928340911865234, 31.33484649658203, 0.1567230224609375, 48.308563232421875, 0.0, 69.48139190673828, 0.0, 0.046875, 37.433828353881836, 0.0, -0.5022048950195312, 54.94510269165039, 60.300048828125, 0.0, 30.6922607421875, 27.795425415039062, 0.0, 54.66413116455078, 0.0, 0.0, 0.0, 49.219573974609375, -0.523040771484375, 0.0, 0.0, 0.0, 53.10319519042969, 0.0, 0.0, 11.43402099609375, 0.0, 57.943267822265625, 0.0, 0.0, 56.42970657348633], "episode_lengths": [500, 349, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 134, 500, 500, 500, 500, 398, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 500, 490, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 258, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.856775927799847, "mean_inference_ms": 4.920678586107514, "mean_action_processing_ms": 7.633665182115275, "mean_env_wait_ms": 11.425886933037592, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 77.99330139160156, "episode_reward_min": -0.70501708984375, "episode_reward_mean": 14.315067413330079, "episode_len_mean": 490.16, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.46068572998046875, 30.824180603027344, -0.70501708984375, 0.165771484375, 0.0, 0.0, 0.0, 51.256805419921875, 0.0, 0.91107177734375, 0.0, 28.13475799560547, 0.0, 0.0, -0.03186798095703125, 33.27787208557129, -0.0282135009765625, 0.0, 0.0, 0.0, 75.95498657226562, 3.7533645629882812, 0.0, -0.14536285400390625, 0.0, 0.0, 57.53792762756348, 0.4159965515136719, 0.6938323974609375, 0.0593109130859375, 0.0, 39.83540344238281, 11.588386535644531, 0.0, 0.0, 77.99330139160156, 37.818565368652344, 10.072189331054688, -0.19196319580078125, 22.688167572021484, 0.0, 57.429317474365234, 0.0433349609375, 0.0, 0.08455657958984375, -0.244415283203125, 0.2284393310546875, 0.0, 43.13128662109375, 6.793279647827148, 37.205474853515625, 0.0, -0.21686553955078125, 69.96185302734375, 48.27960968017578, 20.995498657226562, 51.4549560546875, 0.0, 16.965408325195312, 0.0, 0.0449371337890625, 33.789161682128906, 39.079742431640625, 33.653472900390625, 0.0, 0.0, 7.08721923828125, -0.5106887817382812, 0.0, 0.0, 0.0, 0.09278106689453125, 0.0, 0.0, 48.039466857910156, 0.5373077392578125, 0.0, 0.0, 44.373687744140625, 41.94496154785156, 0.0, 0.0, 0.0, 0.0, 2.9464111328125, -0.0746612548828125, 23.230484008789062, 0.0, 0.0, 1.5051994323730469, 36.928340911865234, 31.33484649658203, 0.1567230224609375, 48.308563232421875, 0.0, 69.48139190673828, 0.0, 0.046875, 37.433828353881836, 0.0, -0.5022048950195312, 54.94510269165039, 60.300048828125, 0.0, 30.6922607421875, 27.795425415039062, 0.0, 54.66413116455078, 0.0, 0.0, 0.0, 49.219573974609375, -0.523040771484375, 0.0, 0.0, 0.0, 53.10319519042969, 0.0, 0.0, 11.43402099609375, 0.0, 57.943267822265625, 0.0, 0.0, 56.42970657348633], "episode_lengths": [500, 349, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 134, 500, 500, 500, 500, 398, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 500, 490, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 258, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.856775927799847, "mean_inference_ms": 4.920678586107514, "mean_action_processing_ms": 7.633665182115275, "mean_env_wait_ms": 11.425886933037592, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19710679, "num_agent_steps_trained": 19710679, "num_env_steps_sampled": 19710679, "num_env_steps_trained": 19710679, "num_env_steps_sampled_this_iter": 61270, "num_env_steps_trained_this_iter": 61270, "timesteps_total": 19710679, "num_steps_trained_this_iter": 61270, "agent_timesteps_total": 19710679, "timers": {"training_iteration_time_ms": 51550.184, "load_time_ms": 61.918, "load_throughput": 988207.988, "learn_time_ms": 28185.223, "learn_throughput": 2170.925, "synch_weights_time_ms": 12.294}, "counters": {"num_env_steps_sampled": 19710679, "num_env_steps_trained": 19710679, "num_agent_steps_sampled": 19710679, "num_agent_steps_trained": 19710679}, "done": false, "episodes_total": 39904, "training_iteration": 325, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-25-52", "timestamp": 1735107952, "time_this_iter_s": 49.9079430103302, "time_total_s": 9063.377280712128, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A93460>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F76D0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 206.24738192558289, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 25.604285714285712, "ram_util_percent": 95.38000000000004}}
{"custom_metrics": {"rewards/0_mean": 10.9111115137736, "rewards/0_min": -0.7792510986328125, "rewards/0_max": 65.23373413085938, "rewards/1_mean": 10.9111115137736, "rewards/1_min": -0.7792510986328125, "rewards/1_max": 65.23373413085938, "rewards/2_mean": 10.9111115137736, "rewards/2_min": -0.7792510986328125, "rewards/2_max": 65.23373413085938, "rewards/3_mean": 10.9111115137736, "rewards/3_min": -0.7792510986328125, "rewards/3_max": 65.23373413085938, "rewards/4_mean": 10.9111115137736, "rewards/4_min": -0.7792510986328125, "rewards/4_max": 65.23373413085938}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.14870131050813057, "policy_loss": -0.003973864195942287, "vf_loss": 0.06992085273229769, "vf_explained_var": 0.9917681936233763, "kl": 0.014428000211242645, "entropy": 21.537872105553035, "entropy_coeff": 0.01, "grad_gnorm": 1.2521515618714074}, "model": {}, "num_grad_updates_lifetime": 2880.5, "diff_num_grad_updates_vs_sampler_policy": 2879.5}}, "num_env_steps_sampled": 19771838, "num_env_steps_trained": 19771838, "num_agent_steps_sampled": 19771838, "num_agent_steps_trained": 19771838}, "sampler_results": {"episode_reward_max": 65.23373413085938, "episode_reward_min": -0.7792510986328125, "episode_reward_mean": 10.9111115137736, "episode_len_mean": 485.3888888888889, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.9111115137736, "rewards/0_min": -0.7792510986328125, "rewards/0_max": 65.23373413085938, "rewards/1_mean": 10.9111115137736, "rewards/1_min": -0.7792510986328125, "rewards/1_max": 65.23373413085938, "rewards/2_mean": 10.9111115137736, "rewards/2_min": -0.7792510986328125, "rewards/2_max": 65.23373413085938, "rewards/3_mean": 10.9111115137736, "rewards/3_min": -0.7792510986328125, "rewards/3_max": 65.23373413085938, "rewards/4_mean": 10.9111115137736, "rewards/4_min": -0.7792510986328125, "rewards/4_max": 65.23373413085938}, "hist_stats": {"episode_reward": [5.67095947265625, 26.94857406616211, 0.0, -0.10089874267578125, 44.184852600097656, -0.01244354248046875, 0.0, 0.09910964965820312, 0.0, 0.0, 3.5752639770507812, 0.0, 0.0, 0.7976531982421875, 7.273345947265625, 0.0, 49.038063049316406, 18.83935546875, 0.0761566162109375, 0.0, 19.186504364013672, 0.0, 28.20831298828125, 0.0, 0.0, 42.59801483154297, 49.21318244934082, 33.46005439758301, 57.902976989746094, -0.2131195068359375, 0.0, 0.0, 0.0, 0.0, 0.0, 30.758804321289062, 0.0, 0.0, 0.0, 0.0, 2.3085594177246094, 0.0, 0.0, -0.165618896484375, 0.0, 0.0, 57.342058181762695, 0.0, 0.0, 25.539669036865234, 0.0, 23.817747116088867, 0.0, 23.22406005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 56.31864356994629, 0.0, 24.449148178100586, 3.6664352416992188, 0.224578857421875, 0.0, 0.04639434814453125, 0.841400146484375, 0.0, 0.0, 56.012107849121094, 4.395973205566406, 0.0, 0.0, 38.61063575744629, 42.73416328430176, 0.0, -0.7792510986328125, 0.0, 6.9392852783203125, 0.0, 0.0, 0.1330718994140625, 0.0, 0.270721435546875, 0.0, 34.518287658691406, 5.638805389404297, 26.713455200195312, 13.725723266601562, 0.0, 18.054702758789062, -0.32281494140625, 18.881263732910156, 65.23373413085938, 28.819259643554688, 0.0, 0.0, 0.0, 0.0566558837890625, 49.182430267333984, 0.0, 8.793365478515625, 0.0, 0.0, 0.0, 0.0, 0.0, 32.04917907714844, 46.971656799316406, 19.912887573242188, 0.0, 0.0, 48.6497688293457, 0.0, -0.091522216796875, 0.0, -0.3770904541015625, 0.35060882568359375, 64.94306182861328, -0.1556396484375, 50.81537628173828, 22.54783058166504, 0.0, 36.454559326171875], "episode_lengths": [500, 401, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 203, 500, 500, 500, 500, 318, 362, 372, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 395, 500, 500, 294, 500, 453, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 332, 430, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 490, 500, 500, 500, 500, 500, 368, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 241, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.249338443654478, "mean_inference_ms": 4.991943398870005, "mean_action_processing_ms": 7.742118982625927, "mean_env_wait_ms": 11.62161796872687, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 65.23373413085938, "episode_reward_min": -0.7792510986328125, "episode_reward_mean": 10.9111115137736, "episode_len_mean": 485.3888888888889, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [5.67095947265625, 26.94857406616211, 0.0, -0.10089874267578125, 44.184852600097656, -0.01244354248046875, 0.0, 0.09910964965820312, 0.0, 0.0, 3.5752639770507812, 0.0, 0.0, 0.7976531982421875, 7.273345947265625, 0.0, 49.038063049316406, 18.83935546875, 0.0761566162109375, 0.0, 19.186504364013672, 0.0, 28.20831298828125, 0.0, 0.0, 42.59801483154297, 49.21318244934082, 33.46005439758301, 57.902976989746094, -0.2131195068359375, 0.0, 0.0, 0.0, 0.0, 0.0, 30.758804321289062, 0.0, 0.0, 0.0, 0.0, 2.3085594177246094, 0.0, 0.0, -0.165618896484375, 0.0, 0.0, 57.342058181762695, 0.0, 0.0, 25.539669036865234, 0.0, 23.817747116088867, 0.0, 23.22406005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 56.31864356994629, 0.0, 24.449148178100586, 3.6664352416992188, 0.224578857421875, 0.0, 0.04639434814453125, 0.841400146484375, 0.0, 0.0, 56.012107849121094, 4.395973205566406, 0.0, 0.0, 38.61063575744629, 42.73416328430176, 0.0, -0.7792510986328125, 0.0, 6.9392852783203125, 0.0, 0.0, 0.1330718994140625, 0.0, 0.270721435546875, 0.0, 34.518287658691406, 5.638805389404297, 26.713455200195312, 13.725723266601562, 0.0, 18.054702758789062, -0.32281494140625, 18.881263732910156, 65.23373413085938, 28.819259643554688, 0.0, 0.0, 0.0, 0.0566558837890625, 49.182430267333984, 0.0, 8.793365478515625, 0.0, 0.0, 0.0, 0.0, 0.0, 32.04917907714844, 46.971656799316406, 19.912887573242188, 0.0, 0.0, 48.6497688293457, 0.0, -0.091522216796875, 0.0, -0.3770904541015625, 0.35060882568359375, 64.94306182861328, -0.1556396484375, 50.81537628173828, 22.54783058166504, 0.0, 36.454559326171875], "episode_lengths": [500, 401, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 203, 500, 500, 500, 500, 318, 362, 372, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 395, 500, 500, 294, 500, 453, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 332, 430, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 490, 500, 500, 500, 500, 500, 368, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 241, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.249338443654478, "mean_inference_ms": 4.991943398870005, "mean_action_processing_ms": 7.742118982625927, "mean_env_wait_ms": 11.62161796872687, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19771838, "num_agent_steps_trained": 19771838, "num_env_steps_sampled": 19771838, "num_env_steps_trained": 19771838, "num_env_steps_sampled_this_iter": 61159, "num_env_steps_trained_this_iter": 61159, "timesteps_total": 19771838, "num_steps_trained_this_iter": 61159, "agent_timesteps_total": 19771838, "timers": {"training_iteration_time_ms": 51484.898, "load_time_ms": 62.033, "load_throughput": 986283.431, "learn_time_ms": 28136.555, "learn_throughput": 2174.474, "synch_weights_time_ms": 12.776}, "counters": {"num_env_steps_sampled": 19771838, "num_env_steps_trained": 19771838, "num_agent_steps_sampled": 19771838, "num_agent_steps_trained": 19771838}, "done": false, "episodes_total": 40030, "training_iteration": 326, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-26-43", "timestamp": 1735108003, "time_this_iter_s": 51.23576068878174, "time_total_s": 9114.61304140091, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A140>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 257.4831426143646, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 33.236111111111114, "ram_util_percent": 94.67083333333332}}
{"custom_metrics": {"rewards/0_mean": 10.077886810302735, "rewards/0_min": -1.3580398559570312, "rewards/0_max": 78.69646835327148, "rewards/1_mean": 10.077886810302735, "rewards/1_min": -1.3580398559570312, "rewards/1_max": 78.69646835327148, "rewards/2_mean": 10.077886810302735, "rewards/2_min": -1.3580398559570312, "rewards/2_max": 78.69646835327148, "rewards/3_mean": 10.077886810302735, "rewards/3_min": -1.3580398559570312, "rewards/3_max": 78.69646835327148, "rewards/4_mean": 10.077886810302735, "rewards/4_min": -1.3580398559570312, "rewards/4_max": 78.69646835327148}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10980231559776243, "policy_loss": -0.010603473598640117, "vf_loss": 0.09697948894093907, "vf_explained_var": 0.9887239778798724, "kl": 0.011409435844019293, "entropy": 19.675593840886677, "entropy_coeff": 0.01, "grad_gnorm": 1.8265857897107562}, "model": {}, "num_grad_updates_lifetime": 3510.5, "diff_num_grad_updates_vs_sampler_policy": 3509.5}}, "num_env_steps_sampled": 19832996, "num_env_steps_trained": 19832996, "num_agent_steps_sampled": 19832996, "num_agent_steps_trained": 19832996}, "sampler_results": {"episode_reward_max": 78.69646835327148, "episode_reward_min": -1.3580398559570312, "episode_reward_mean": 10.077886810302735, "episode_len_mean": 489.264, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.077886810302735, "rewards/0_min": -1.3580398559570312, "rewards/0_max": 78.69646835327148, "rewards/1_mean": 10.077886810302735, "rewards/1_min": -1.3580398559570312, "rewards/1_max": 78.69646835327148, "rewards/2_mean": 10.077886810302735, "rewards/2_min": -1.3580398559570312, "rewards/2_max": 78.69646835327148, "rewards/3_mean": 10.077886810302735, "rewards/3_min": -1.3580398559570312, "rewards/3_max": 78.69646835327148, "rewards/4_mean": 10.077886810302735, "rewards/4_min": -1.3580398559570312, "rewards/4_max": 78.69646835327148}, "hist_stats": {"episode_reward": [47.77687454223633, 48.45359230041504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.79522705078125, -0.317138671875, 0.0, 0.14455413818359375, 0.0, 0.0, 38.46247100830078, 0.0, 6.5418548583984375, 44.5263671875, 39.813955307006836, 0.063079833984375, 3.0755157470703125, 63.58175849914551, 0.0, 15.501136779785156, 37.55513954162598, 0.0, 0.0, 0.5604400634765625, 66.84491729736328, 27.73737335205078, 0.0, 0.0, 74.74075317382812, -0.14199066162109375, 0.796630859375, 0.0, 1.1915969848632812, 0.0, 0.4053192138671875, 0.0, 48.655364990234375, 25.225616455078125, -0.1287384033203125, 38.59107208251953, 0.0, 2.6304588317871094, 0.0, 3.3405532836914062, -0.043853759765625, 0.0, 0.0, 0.0, 0.0, 9.546096801757812, 8.489471435546875, 0.0, 0.0, 0.0, 0.0, 55.733192443847656, -0.1080474853515625, 0.0, 0.34459686279296875, 0.0, 0.0, 12.145095825195312, 0.0, -1.3580398559570312, 0.0330657958984375, 29.674163818359375, 18.427804946899414, 0.0, 0.0, 12.865745544433594, 19.56470489501953, 10.5263671875, 31.75756072998047, 0.0, 34.40838623046875, 0.0, 0.0, 0.0, 15.715469360351562, 22.40111541748047, 0.0250244140625, 0.0, 0.0, 48.10154724121094, 0.0, -0.0035247802734375, 5.052513122558594, 0.0, 0.0, 60.09471893310547, 1.0100936889648438, 1.7475852966308594, 9.011852264404297, 0.0, 0.0, 0.0, 6.23042106628418, 8.222221374511719, 7.70538330078125, 0.0, 0.047878265380859375, 0.0, 0.0, 0.0, 78.69646835327148, 0.0, 0.0, 0.3515167236328125, 0.0, 4.514251708984375, 3.7200775146484375, 0.0, 0.0, -0.3973236083984375, 0.0, 0.0, 0.0, 36.94098663330078, 0.0, 19.117507934570312, 0.0], "episode_lengths": [500, 391, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 349, 500, 500, 472, 500, 500, 342, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 308, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 281, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.295700851963948, "mean_inference_ms": 4.948686521963671, "mean_action_processing_ms": 7.667587964013382, "mean_env_wait_ms": 11.549083808296295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.69646835327148, "episode_reward_min": -1.3580398559570312, "episode_reward_mean": 10.077886810302735, "episode_len_mean": 489.264, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [47.77687454223633, 48.45359230041504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.79522705078125, -0.317138671875, 0.0, 0.14455413818359375, 0.0, 0.0, 38.46247100830078, 0.0, 6.5418548583984375, 44.5263671875, 39.813955307006836, 0.063079833984375, 3.0755157470703125, 63.58175849914551, 0.0, 15.501136779785156, 37.55513954162598, 0.0, 0.0, 0.5604400634765625, 66.84491729736328, 27.73737335205078, 0.0, 0.0, 74.74075317382812, -0.14199066162109375, 0.796630859375, 0.0, 1.1915969848632812, 0.0, 0.4053192138671875, 0.0, 48.655364990234375, 25.225616455078125, -0.1287384033203125, 38.59107208251953, 0.0, 2.6304588317871094, 0.0, 3.3405532836914062, -0.043853759765625, 0.0, 0.0, 0.0, 0.0, 9.546096801757812, 8.489471435546875, 0.0, 0.0, 0.0, 0.0, 55.733192443847656, -0.1080474853515625, 0.0, 0.34459686279296875, 0.0, 0.0, 12.145095825195312, 0.0, -1.3580398559570312, 0.0330657958984375, 29.674163818359375, 18.427804946899414, 0.0, 0.0, 12.865745544433594, 19.56470489501953, 10.5263671875, 31.75756072998047, 0.0, 34.40838623046875, 0.0, 0.0, 0.0, 15.715469360351562, 22.40111541748047, 0.0250244140625, 0.0, 0.0, 48.10154724121094, 0.0, -0.0035247802734375, 5.052513122558594, 0.0, 0.0, 60.09471893310547, 1.0100936889648438, 1.7475852966308594, 9.011852264404297, 0.0, 0.0, 0.0, 6.23042106628418, 8.222221374511719, 7.70538330078125, 0.0, 0.047878265380859375, 0.0, 0.0, 0.0, 78.69646835327148, 0.0, 0.0, 0.3515167236328125, 0.0, 4.514251708984375, 3.7200775146484375, 0.0, 0.0, -0.3973236083984375, 0.0, 0.0, 0.0, 36.94098663330078, 0.0, 19.117507934570312, 0.0], "episode_lengths": [500, 391, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 349, 500, 500, 472, 500, 500, 342, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 308, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 281, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.295700851963948, "mean_inference_ms": 4.948686521963671, "mean_action_processing_ms": 7.667587964013382, "mean_env_wait_ms": 11.549083808296295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19832996, "num_agent_steps_trained": 19832996, "num_env_steps_sampled": 19832996, "num_env_steps_trained": 19832996, "num_env_steps_sampled_this_iter": 61158, "num_env_steps_trained_this_iter": 61158, "timesteps_total": 19832996, "num_steps_trained_this_iter": 61158, "agent_timesteps_total": 19832996, "timers": {"training_iteration_time_ms": 50771.391, "load_time_ms": 59.105, "load_throughput": 1035080.189, "learn_time_ms": 27860.717, "learn_throughput": 2195.858, "synch_weights_time_ms": 11.67}, "counters": {"num_env_steps_sampled": 19832996, "num_env_steps_trained": 19832996, "num_agent_steps_sampled": 19832996, "num_agent_steps_trained": 19832996}, "done": false, "episodes_total": 40155, "training_iteration": 327, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-27-31", "timestamp": 1735108051, "time_this_iter_s": 47.21143460273743, "time_total_s": 9161.824476003647, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B52FE0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E32AD1B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 304.69457721710205, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 26.931818181818187, "ram_util_percent": 93.7348484848485}}
{"custom_metrics": {"rewards/0_mean": 10.834720962524415, "rewards/0_min": -0.79754638671875, "rewards/0_max": 80.82243347167969, "rewards/1_mean": 10.834720962524415, "rewards/1_min": -0.79754638671875, "rewards/1_max": 80.82243347167969, "rewards/2_mean": 10.834720962524415, "rewards/2_min": -0.79754638671875, "rewards/2_max": 80.82243347167969, "rewards/3_mean": 10.834720962524415, "rewards/3_min": -0.79754638671875, "rewards/3_max": 80.82243347167969, "rewards/4_mean": 10.834720962524415, "rewards/4_min": -0.79754638671875, "rewards/4_max": 80.82243347167969}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07103223656205725, "policy_loss": 0.017065396932801898, "vf_loss": 0.11018676646792935, "vf_explained_var": 0.9860753610966697, "kl": 0.012322536314881984, "entropy": 19.890823373340424, "entropy_coeff": 0.01, "grad_gnorm": 1.534752850139898}, "model": {}, "num_grad_updates_lifetime": 4140.5, "diff_num_grad_updates_vs_sampler_policy": 4139.5}}, "num_env_steps_sampled": 19893997, "num_env_steps_trained": 19893997, "num_agent_steps_sampled": 19893997, "num_agent_steps_trained": 19893997}, "sampler_results": {"episode_reward_max": 80.82243347167969, "episode_reward_min": -0.79754638671875, "episode_reward_mean": 10.834720962524415, "episode_len_mean": 488.008, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.834720962524415, "rewards/0_min": -0.79754638671875, "rewards/0_max": 80.82243347167969, "rewards/1_mean": 10.834720962524415, "rewards/1_min": -0.79754638671875, "rewards/1_max": 80.82243347167969, "rewards/2_mean": 10.834720962524415, "rewards/2_min": -0.79754638671875, "rewards/2_max": 80.82243347167969, "rewards/3_mean": 10.834720962524415, "rewards/3_min": -0.79754638671875, "rewards/3_max": 80.82243347167969, "rewards/4_mean": 10.834720962524415, "rewards/4_min": -0.79754638671875, "rewards/4_max": 80.82243347167969}, "hist_stats": {"episode_reward": [0.5020980834960938, 0.0, 64.81695556640625, 52.85056114196777, 11.422595977783203, 31.251205444335938, 22.32897186279297, 0.0, 0.0018558502197265625, 26.298934936523438, 0.23157119750976562, 0.0, 35.059303283691406, 0.0, 0.0, 0.0, 30.40728759765625, -0.04080963134765625, 0.129791259765625, 8.740020751953125, 0.17461395263671875, -0.2491302490234375, 0.0, 0.0, 0.0, 0.0, 0.0, 13.335182189941406, 0.0, 0.27996826171875, -0.21395492553710938, 0.0, 38.920814514160156, 0.00099945068359375, 15.262069702148438, 7.525365829467773, 0.0128936767578125, 0.0, 19.38585662841797, 3.229248046875, 0.0, 0.0, 0.0, 24.63623809814453, 13.624317169189453, 40.08369445800781, 0.0, 80.82243347167969, 0.0, 0.0, 0.0, 4.218416213989258, 26.964574813842773, -0.3058929443359375, 0.0, 0.0, 19.461101531982422, 0.814605712890625, 0.0, 16.248580932617188, -0.20597076416015625, 0.0, 5.6914215087890625, 1.2770042419433594, 38.86771774291992, -0.3631134033203125, 0.0, 76.13561248779297, 5.936317443847656, -0.0137786865234375, 0.0, 10.29464340209961, 8.530963897705078, 34.890228271484375, 0.0, 30.497753143310547, 0.0, 0.0, 0.0, 24.687942504882812, 0.0, -0.4059295654296875, 13.170036315917969, 41.56964874267578, -0.02565765380859375, 0.0, -0.11330413818359375, 0.5649604797363281, 0.0, 14.370849609375, 8.587200164794922, 0.0, 29.358505249023438, 0.0, 0.0, 4.56993293762207, 0.0, -0.23334503173828125, 0.0, 45.353004455566406, -0.3621368408203125, 4.035055160522461, 0.0, 0.7659149169921875, 0.0, 54.00506591796875, 19.54986572265625, 11.921600341796875, 0.0, 11.189308166503906, 0.14125442504882812, 0.0, 0.0, 0.0, -0.79754638671875, -0.2399311065673828, 0.353515625, 0.0, 54.7191162109375, 48.36216735839844, 25.485898971557617, 51.1475715637207, 28.082687377929688, 44.75572967529297, 0.0], "episode_lengths": [500, 500, 500, 437, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 245, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 123, 500, 500, 500, 500, 287, 500, 500, 500, 500, 500, 469, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 319, 430, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.435648646576, "mean_inference_ms": 5.003918416866997, "mean_action_processing_ms": 7.743489576795093, "mean_env_wait_ms": 11.665913199903898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 80.82243347167969, "episode_reward_min": -0.79754638671875, "episode_reward_mean": 10.834720962524415, "episode_len_mean": 488.008, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.5020980834960938, 0.0, 64.81695556640625, 52.85056114196777, 11.422595977783203, 31.251205444335938, 22.32897186279297, 0.0, 0.0018558502197265625, 26.298934936523438, 0.23157119750976562, 0.0, 35.059303283691406, 0.0, 0.0, 0.0, 30.40728759765625, -0.04080963134765625, 0.129791259765625, 8.740020751953125, 0.17461395263671875, -0.2491302490234375, 0.0, 0.0, 0.0, 0.0, 0.0, 13.335182189941406, 0.0, 0.27996826171875, -0.21395492553710938, 0.0, 38.920814514160156, 0.00099945068359375, 15.262069702148438, 7.525365829467773, 0.0128936767578125, 0.0, 19.38585662841797, 3.229248046875, 0.0, 0.0, 0.0, 24.63623809814453, 13.624317169189453, 40.08369445800781, 0.0, 80.82243347167969, 0.0, 0.0, 0.0, 4.218416213989258, 26.964574813842773, -0.3058929443359375, 0.0, 0.0, 19.461101531982422, 0.814605712890625, 0.0, 16.248580932617188, -0.20597076416015625, 0.0, 5.6914215087890625, 1.2770042419433594, 38.86771774291992, -0.3631134033203125, 0.0, 76.13561248779297, 5.936317443847656, -0.0137786865234375, 0.0, 10.29464340209961, 8.530963897705078, 34.890228271484375, 0.0, 30.497753143310547, 0.0, 0.0, 0.0, 24.687942504882812, 0.0, -0.4059295654296875, 13.170036315917969, 41.56964874267578, -0.02565765380859375, 0.0, -0.11330413818359375, 0.5649604797363281, 0.0, 14.370849609375, 8.587200164794922, 0.0, 29.358505249023438, 0.0, 0.0, 4.56993293762207, 0.0, -0.23334503173828125, 0.0, 45.353004455566406, -0.3621368408203125, 4.035055160522461, 0.0, 0.7659149169921875, 0.0, 54.00506591796875, 19.54986572265625, 11.921600341796875, 0.0, 11.189308166503906, 0.14125442504882812, 0.0, 0.0, 0.0, -0.79754638671875, -0.2399311065673828, 0.353515625, 0.0, 54.7191162109375, 48.36216735839844, 25.485898971557617, 51.1475715637207, 28.082687377929688, 44.75572967529297, 0.0], "episode_lengths": [500, 500, 500, 437, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 245, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 123, 500, 500, 500, 500, 287, 500, 500, 500, 500, 500, 469, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 319, 430, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.435648646576, "mean_inference_ms": 5.003918416866997, "mean_action_processing_ms": 7.743489576795093, "mean_env_wait_ms": 11.665913199903898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19893997, "num_agent_steps_trained": 19893997, "num_env_steps_sampled": 19893997, "num_env_steps_trained": 19893997, "num_env_steps_sampled_this_iter": 61001, "num_env_steps_trained_this_iter": 61001, "timesteps_total": 19893997, "num_steps_trained_this_iter": 61001, "agent_timesteps_total": 19893997, "timers": {"training_iteration_time_ms": 50705.963, "load_time_ms": 56.376, "load_throughput": 1084730.516, "learn_time_ms": 27578.329, "learn_throughput": 2217.424, "synch_weights_time_ms": 11.421}, "counters": {"num_env_steps_sampled": 19893997, "num_env_steps_trained": 19893997, "num_agent_steps_sampled": 19893997, "num_agent_steps_trained": 19893997}, "done": false, "episodes_total": 40280, "training_iteration": 328, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-28-21", "timestamp": 1735108101, "time_this_iter_s": 50.3234007358551, "time_total_s": 9212.147876739502, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE7F40>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 355.01797795295715, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 28.79014084507042, "ram_util_percent": 95.93521126760568}}
{"custom_metrics": {"rewards/0_mean": 11.214164169311523, "rewards/0_min": -0.6852455139160156, "rewards/0_max": 81.89553833007812, "rewards/1_mean": 11.214164169311523, "rewards/1_min": -0.6852455139160156, "rewards/1_max": 81.89553833007812, "rewards/2_mean": 11.214164169311523, "rewards/2_min": -0.6852455139160156, "rewards/2_max": 81.89553833007812, "rewards/3_mean": 11.214164169311523, "rewards/3_min": -0.6852455139160156, "rewards/3_max": 81.89553833007812, "rewards/4_mean": 11.214164169311523, "rewards/4_min": -0.6852455139160156, "rewards/4_max": 81.89553833007812}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07976903254018416, "policy_loss": -0.002535591315337649, "vf_loss": 0.14498467114255098, "vf_explained_var": 0.9835503204474374, "kl": 0.012141577667364525, "entropy": 22.283278477381145, "entropy_coeff": 0.01, "grad_gnorm": 1.4682223546126532}, "model": {}, "num_grad_updates_lifetime": 4770.5, "diff_num_grad_updates_vs_sampler_policy": 4769.5}}, "num_env_steps_sampled": 19955087, "num_env_steps_trained": 19955087, "num_agent_steps_sampled": 19955087, "num_agent_steps_trained": 19955087}, "sampler_results": {"episode_reward_max": 81.89553833007812, "episode_reward_min": -0.6852455139160156, "episode_reward_mean": 11.214164169311523, "episode_len_mean": 488.72, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.214164169311523, "rewards/0_min": -0.6852455139160156, "rewards/0_max": 81.89553833007812, "rewards/1_mean": 11.214164169311523, "rewards/1_min": -0.6852455139160156, "rewards/1_max": 81.89553833007812, "rewards/2_mean": 11.214164169311523, "rewards/2_min": -0.6852455139160156, "rewards/2_max": 81.89553833007812, "rewards/3_mean": 11.214164169311523, "rewards/3_min": -0.6852455139160156, "rewards/3_max": 81.89553833007812, "rewards/4_mean": 11.214164169311523, "rewards/4_min": -0.6852455139160156, "rewards/4_max": 81.89553833007812}, "hist_stats": {"episode_reward": [0.0298614501953125, 0.0, 2.7111434936523438, 34.27294158935547, 15.209060668945312, 0.0, 0.0, 79.53753662109375, 31.986778259277344, 0.0, 0.2685546875, 0.0, 35.39897155761719, 0.0, 9.393463134765625, 0.0, 0.032154083251953125, 0.29052734375, 0.0, 0.0, 0.0, 21.850143432617188, -0.3040008544921875, 15.507001876831055, 54.23394775390625, 0.0, -0.197052001953125, 0.0, 0.0, 0.0, 0.0, 0.0, -0.42282867431640625, -0.4314422607421875, 0.01558685302734375, 0.055206298828125, 0.0, 19.5341796875, 0.0, 45.521400451660156, 0.0, -0.23307037353515625, 52.21247863769531, 0.0, 0.0, -0.207366943359375, 0.0, 0.0, 20.363388061523438, 38.40317726135254, 21.594200134277344, 0.0, 59.00959014892578, -0.27370452880859375, 4.8182830810546875, 0.0, 0.4000396728515625, 0.0, 0.006011962890625, 56.702919006347656, 0.0, 0.0, -0.08461761474609375, 68.74055480957031, -0.0522613525390625, 0.0, 7.95539665222168, -0.1615753173828125, 0.0, 0.0, 0.0, 0.0, -0.35369110107421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.89553833007812, 0.0, -0.348846435546875, 0.0, 0.0, 0.0, 0.0, 47.27935791015625, -0.5894927978515625, 0.0, 0.0, 19.965782165527344, 0.0, 0.0, 10.303524017333984, 0.0, 0.413604736328125, 2.524444580078125, 58.03833770751953, 26.221073150634766, 4.4811248779296875, 0.31258392333984375, -0.1399688720703125, 0.344573974609375, 0.0542755126953125, 0.0, 45.23790740966797, 65.54896545410156, 63.903404235839844, 0.0, 19.036762237548828, 0.0, 0.883331298828125, 0.0, 18.87896728515625, -0.05588531494140625, 0.0, 75.16272354125977, 50.61763000488281, 0.0, 54.20531463623047, 6.856327056884766, -0.6852455139160156, 0.0, 58.09151840209961, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 308, 311, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 334, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 312, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 276, 500, 500, 142, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 407, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.423847147670724, "mean_inference_ms": 5.000313029591555, "mean_action_processing_ms": 7.689854434632496, "mean_env_wait_ms": 11.618777038045224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 81.89553833007812, "episode_reward_min": -0.6852455139160156, "episode_reward_mean": 11.214164169311523, "episode_len_mean": 488.72, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0298614501953125, 0.0, 2.7111434936523438, 34.27294158935547, 15.209060668945312, 0.0, 0.0, 79.53753662109375, 31.986778259277344, 0.0, 0.2685546875, 0.0, 35.39897155761719, 0.0, 9.393463134765625, 0.0, 0.032154083251953125, 0.29052734375, 0.0, 0.0, 0.0, 21.850143432617188, -0.3040008544921875, 15.507001876831055, 54.23394775390625, 0.0, -0.197052001953125, 0.0, 0.0, 0.0, 0.0, 0.0, -0.42282867431640625, -0.4314422607421875, 0.01558685302734375, 0.055206298828125, 0.0, 19.5341796875, 0.0, 45.521400451660156, 0.0, -0.23307037353515625, 52.21247863769531, 0.0, 0.0, -0.207366943359375, 0.0, 0.0, 20.363388061523438, 38.40317726135254, 21.594200134277344, 0.0, 59.00959014892578, -0.27370452880859375, 4.8182830810546875, 0.0, 0.4000396728515625, 0.0, 0.006011962890625, 56.702919006347656, 0.0, 0.0, -0.08461761474609375, 68.74055480957031, -0.0522613525390625, 0.0, 7.95539665222168, -0.1615753173828125, 0.0, 0.0, 0.0, 0.0, -0.35369110107421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.89553833007812, 0.0, -0.348846435546875, 0.0, 0.0, 0.0, 0.0, 47.27935791015625, -0.5894927978515625, 0.0, 0.0, 19.965782165527344, 0.0, 0.0, 10.303524017333984, 0.0, 0.413604736328125, 2.524444580078125, 58.03833770751953, 26.221073150634766, 4.4811248779296875, 0.31258392333984375, -0.1399688720703125, 0.344573974609375, 0.0542755126953125, 0.0, 45.23790740966797, 65.54896545410156, 63.903404235839844, 0.0, 19.036762237548828, 0.0, 0.883331298828125, 0.0, 18.87896728515625, -0.05588531494140625, 0.0, 75.16272354125977, 50.61763000488281, 0.0, 54.20531463623047, 6.856327056884766, -0.6852455139160156, 0.0, 58.09151840209961, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 308, 311, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 334, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 312, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 276, 500, 500, 142, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 407, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.423847147670724, "mean_inference_ms": 5.000313029591555, "mean_action_processing_ms": 7.689854434632496, "mean_env_wait_ms": 11.618777038045224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19955087, "num_agent_steps_trained": 19955087, "num_env_steps_sampled": 19955087, "num_env_steps_trained": 19955087, "num_env_steps_sampled_this_iter": 61090, "num_env_steps_trained_this_iter": 61090, "timesteps_total": 19955087, "num_steps_trained_this_iter": 61090, "agent_timesteps_total": 19955087, "timers": {"training_iteration_time_ms": 50077.037, "load_time_ms": 56.492, "load_throughput": 1082357.635, "learn_time_ms": 27439.4, "learn_throughput": 2228.365, "synch_weights_time_ms": 11.235}, "counters": {"num_env_steps_sampled": 19955087, "num_env_steps_trained": 19955087, "num_agent_steps_sampled": 19955087, "num_agent_steps_trained": 19955087}, "done": false, "episodes_total": 40405, "training_iteration": 329, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-29-07", "timestamp": 1735108147, "time_this_iter_s": 45.68456721305847, "time_total_s": 9257.83244395256, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B51F90>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 400.7025451660156, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.91875, "ram_util_percent": 95.09375}}
{"evaluation": {"episode_reward_max": -0.185577392578125, "episode_reward_min": -0.185577392578125, "episode_reward_mean": -0.185577392578125, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": -0.185577392578125, "rewards/0_min": -0.185577392578125, "rewards/0_max": -0.185577392578125, "rewards/1_mean": -0.185577392578125, "rewards/1_min": -0.185577392578125, "rewards/1_max": -0.185577392578125, "rewards/2_mean": -0.185577392578125, "rewards/2_min": -0.185577392578125, "rewards/2_max": -0.185577392578125, "rewards/3_mean": -0.185577392578125, "rewards/3_min": -0.185577392578125, "rewards/3_max": -0.185577392578125, "rewards/4_mean": -0.185577392578125, "rewards/4_min": -0.185577392578125, "rewards/4_max": -0.185577392578125}, "hist_stats": {"episode_reward": [-0.185577392578125], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7552495607724795, "mean_inference_ms": 3.315682415957456, "mean_action_processing_ms": 0.5537801451020903, "mean_env_wait_ms": 5.605321783166785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 8.878637794556656, "rewards/0_min": -0.6001205444335938, "rewards/0_max": 74.27851867675781, "rewards/1_mean": 8.878637794556656, "rewards/1_min": -0.6001205444335938, "rewards/1_max": 74.27851867675781, "rewards/2_mean": 8.878637794556656, "rewards/2_min": -0.6001205444335938, "rewards/2_max": 74.27851867675781, "rewards/3_mean": 8.878637794556656, "rewards/3_min": -0.6001205444335938, "rewards/3_max": 74.27851867675781, "rewards/4_mean": 8.878637794556656, "rewards/4_min": -0.6001205444335938, "rewards/4_max": 74.27851867675781}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09019676619246307, "policy_loss": 0.0005467035906067827, "vf_loss": 0.1260325895563241, "vf_explained_var": 0.9861203376262907, "kl": 0.01093745443393432, "entropy": 21.73297734639001, "entropy_coeff": 0.01, "grad_gnorm": 1.2789868515398768}, "model": {}, "num_grad_updates_lifetime": 5400.5, "diff_num_grad_updates_vs_sampler_policy": 5399.5}}, "num_env_steps_sampled": 20015506, "num_env_steps_trained": 20015506, "num_agent_steps_sampled": 20015506, "num_agent_steps_trained": 20015506}, "sampler_results": {"episode_reward_max": 74.27851867675781, "episode_reward_min": -0.6001205444335938, "episode_reward_mean": 8.878637794556656, "episode_len_mean": 491.2113821138211, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.878637794556656, "rewards/0_min": -0.6001205444335938, "rewards/0_max": 74.27851867675781, "rewards/1_mean": 8.878637794556656, "rewards/1_min": -0.6001205444335938, "rewards/1_max": 74.27851867675781, "rewards/2_mean": 8.878637794556656, "rewards/2_min": -0.6001205444335938, "rewards/2_max": 74.27851867675781, "rewards/3_mean": 8.878637794556656, "rewards/3_min": -0.6001205444335938, "rewards/3_max": 74.27851867675781, "rewards/4_mean": 8.878637794556656, "rewards/4_min": -0.6001205444335938, "rewards/4_max": 74.27851867675781}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 22.416580200195312, 70.74299240112305, 0.0, 55.36039733886719, 0.0, 0.0, 22.487403869628906, 3.7696533203125, 0.24111175537109375, 0.0, 0.1547393798828125, 7.9838409423828125, -0.18792724609375, 0.0, 0.0749053955078125, 0.0, 1.8724517822265625, 0.17746734619140625, 12.010862350463867, 26.979665756225586, 0.0, 2.811717987060547, 0.0, 0.0, 0.0, 0.6522674560546875, 12.297077178955078, 40.8642578125, 12.803382873535156, 18.814022064208984, 13.335784912109375, 0.0, 0.0, -0.1623382568359375, 0.0, 0.0, 0.0433807373046875, 0.0, 0.0, 0.0, -0.282318115234375, 36.238136291503906, 0.1343841552734375, 56.08680725097656, -0.0896453857421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0089569091796875, 1.4699325561523438, 13.443626403808594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0535125732421875, 0.0, 17.21198272705078, 74.27851867675781, 0.0, 17.259305953979492, 0.6103515625, 32.81867218017578, 43.60664176940918, 0.0, 39.33003234863281, 0.0, 14.243423461914062, 18.781707763671875, 0.0, 0.0, 31.00908660888672, 70.64568710327148, 4.5946197509765625, 0.892791748046875, 0.0, -0.26380157470703125, -0.25955963134765625, 5.900970458984375, 47.1355037689209, 0.0, 57.45863723754883, 25.63800048828125, 0.0, 0.291595458984375, 0.0, 0.0, 0.0, 33.10517120361328, 0.0, 0.4181671142578125, -0.6001205444335938, 0.0, 0.0, 50.12123107910156, 25.623292922973633, 31.379989624023438, 0.2555084228515625, 0.02695465087890625, 0.8570442199707031, 0.0, 1.4348602294921875, 0.0, -0.21575164794921875, 0.0, 0.40303802490234375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20559310913085938, 15.784423828125, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 493, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 285, 286, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 223, 500, 500, 302, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 456, 500, 500, 500, 500, 500, 500, 374, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.49359190173097, "mean_inference_ms": 4.992507113164333, "mean_action_processing_ms": 7.697386738615829, "mean_env_wait_ms": 11.583576175575795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.27851867675781, "episode_reward_min": -0.6001205444335938, "episode_reward_mean": 8.878637794556656, "episode_len_mean": 491.2113821138211, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 22.416580200195312, 70.74299240112305, 0.0, 55.36039733886719, 0.0, 0.0, 22.487403869628906, 3.7696533203125, 0.24111175537109375, 0.0, 0.1547393798828125, 7.9838409423828125, -0.18792724609375, 0.0, 0.0749053955078125, 0.0, 1.8724517822265625, 0.17746734619140625, 12.010862350463867, 26.979665756225586, 0.0, 2.811717987060547, 0.0, 0.0, 0.0, 0.6522674560546875, 12.297077178955078, 40.8642578125, 12.803382873535156, 18.814022064208984, 13.335784912109375, 0.0, 0.0, -0.1623382568359375, 0.0, 0.0, 0.0433807373046875, 0.0, 0.0, 0.0, -0.282318115234375, 36.238136291503906, 0.1343841552734375, 56.08680725097656, -0.0896453857421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0089569091796875, 1.4699325561523438, 13.443626403808594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0535125732421875, 0.0, 17.21198272705078, 74.27851867675781, 0.0, 17.259305953979492, 0.6103515625, 32.81867218017578, 43.60664176940918, 0.0, 39.33003234863281, 0.0, 14.243423461914062, 18.781707763671875, 0.0, 0.0, 31.00908660888672, 70.64568710327148, 4.5946197509765625, 0.892791748046875, 0.0, -0.26380157470703125, -0.25955963134765625, 5.900970458984375, 47.1355037689209, 0.0, 57.45863723754883, 25.63800048828125, 0.0, 0.291595458984375, 0.0, 0.0, 0.0, 33.10517120361328, 0.0, 0.4181671142578125, -0.6001205444335938, 0.0, 0.0, 50.12123107910156, 25.623292922973633, 31.379989624023438, 0.2555084228515625, 0.02695465087890625, 0.8570442199707031, 0.0, 1.4348602294921875, 0.0, -0.21575164794921875, 0.0, 0.40303802490234375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20559310913085938, 15.784423828125, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 493, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 285, 286, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 223, 500, 500, 302, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 456, 500, 500, 500, 500, 500, 500, 374, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.49359190173097, "mean_inference_ms": 4.992507113164333, "mean_action_processing_ms": 7.697386738615829, "mean_env_wait_ms": 11.583576175575795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20015506, "num_agent_steps_trained": 20015506, "num_env_steps_sampled": 20015506, "num_env_steps_trained": 20015506, "num_env_steps_sampled_this_iter": 60419, "num_env_steps_trained_this_iter": 60419, "timesteps_total": 20015506, "num_steps_trained_this_iter": 60419, "agent_timesteps_total": 20015506, "timers": {"training_iteration_time_ms": 49800.243, "load_time_ms": 55.174, "load_throughput": 1106753.781, "learn_time_ms": 27459.414, "learn_throughput": 2223.803, "synch_weights_time_ms": 11.096}, "counters": {"num_env_steps_sampled": 20015506, "num_env_steps_trained": 20015506, "num_agent_steps_sampled": 20015506, "num_agent_steps_trained": 20015506}, "done": false, "episodes_total": 40528, "training_iteration": 330, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-29-55", "timestamp": 1735108195, "time_this_iter_s": 47.59588885307312, "time_total_s": 9305.428332805634, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0B460>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 448.29843401908875, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.807462686567163, "ram_util_percent": 95.7}}
{"custom_metrics": {"rewards/0_mean": 10.867662506718789, "rewards/0_min": -0.76971435546875, "rewards/0_max": 78.74819946289062, "rewards/1_mean": 10.867662506718789, "rewards/1_min": -0.76971435546875, "rewards/1_max": 78.74819946289062, "rewards/2_mean": 10.867662506718789, "rewards/2_min": -0.76971435546875, "rewards/2_max": 78.74819946289062, "rewards/3_mean": 10.867662506718789, "rewards/3_min": -0.76971435546875, "rewards/3_max": 78.74819946289062, "rewards/4_mean": 10.867662506718789, "rewards/4_min": -0.76971435546875, "rewards/4_max": 78.74819946289062}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08247305637684933, "policy_loss": -0.0009249884387596496, "vf_loss": 0.12515662141026013, "vf_explained_var": 0.9880963393620082, "kl": 0.014789825584000302, "entropy": 20.745342870742554, "entropy_coeff": 0.01, "grad_gnorm": 1.4724128558285652}, "model": {}, "num_grad_updates_lifetime": 6030.5, "diff_num_grad_updates_vs_sampler_policy": 6029.5}}, "num_env_steps_sampled": 20076408, "num_env_steps_trained": 20076408, "num_agent_steps_sampled": 20076408, "num_agent_steps_trained": 20076408}, "sampler_results": {"episode_reward_max": 78.74819946289062, "episode_reward_min": -0.76971435546875, "episode_reward_mean": 10.867662506718789, "episode_len_mean": 491.14516129032256, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.867662506718789, "rewards/0_min": -0.76971435546875, "rewards/0_max": 78.74819946289062, "rewards/1_mean": 10.867662506718789, "rewards/1_min": -0.76971435546875, "rewards/1_max": 78.74819946289062, "rewards/2_mean": 10.867662506718789, "rewards/2_min": -0.76971435546875, "rewards/2_max": 78.74819946289062, "rewards/3_mean": 10.867662506718789, "rewards/3_min": -0.76971435546875, "rewards/3_max": 78.74819946289062, "rewards/4_mean": 10.867662506718789, "rewards/4_min": -0.76971435546875, "rewards/4_max": 78.74819946289062}, "hist_stats": {"episode_reward": [0.0, 0.0, 15.903549194335938, 0.0, 7.06982421875, 0.0, 0.046173095703125, 40.07579231262207, 33.157470703125, -0.76971435546875, 0.0, -0.36307525634765625, 0.0, 59.401336669921875, -0.0465850830078125, 0.0, 0.0, 0.0, 5.949029922485352, 0.0, 13.279579162597656, 73.99919128417969, 0.0, -0.16130828857421875, 6.889984130859375, 38.25336456298828, 1.1182880401611328, 0.0, 34.0676155090332, 0.39005279541015625, 0.0, 41.220726013183594, 75.41980743408203, 13.633346557617188, 0.0, -0.304931640625, 15.1138916015625, 0.2599945068359375, 0.0, 8.643417358398438, 41.165672302246094, 0.0, 2.5619659423828125, 26.319900512695312, -0.12432098388671875, 0.0, 0.0, 78.74819946289062, 34.818729400634766, 65.79103088378906, -0.13030242919921875, -0.0710906982421875, 30.12194061279297, 37.65448760986328, 0.7623748779296875, 0.0, 0.0, 0.0, 2.7293548583984375, 2.7831039428710938, 0.0, 55.6094856262207, 0.0, 3.0821075439453125, 0.0, 0.0, 0.0, 0.228302001953125, -0.2177886962890625, 0.00460052490234375, 62.75098419189453, 0.0, 0.0, 12.190805435180664, 0.0, 0.0, 6.29425048828125, 0.0, 0.0, 0.0, 0.0, 23.50640869140625, 0.0, 0.0, 0.39520263671875, 0.0, 10.675857543945312, 0.0, -0.4002532958984375, 73.3317642211914, 0.0, 0.12804794311523438, 0.0, 0.374114990234375, 0.23653411865234375, 0.0, 0.0, 0.0, 17.218780517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4568061828613281, 0.0, 27.200210571289062, 0.0, 49.77445983886719, -0.04979896545410156, 0.0, 49.828060150146484, 0.0, -0.070465087890625, 0.0, 0.16622161865234375, 63.404685974121094, 0.0, -0.2975006103515625, 21.139755249023438, 0.0, 0.0, 65.43730545043945, -0.1866607666015625], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 221, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 410, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.55754893695095, "mean_inference_ms": 4.977875769677692, "mean_action_processing_ms": 7.6564255310362395, "mean_env_wait_ms": 11.557786275825379, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.74819946289062, "episode_reward_min": -0.76971435546875, "episode_reward_mean": 10.867662506718789, "episode_len_mean": 491.14516129032256, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 15.903549194335938, 0.0, 7.06982421875, 0.0, 0.046173095703125, 40.07579231262207, 33.157470703125, -0.76971435546875, 0.0, -0.36307525634765625, 0.0, 59.401336669921875, -0.0465850830078125, 0.0, 0.0, 0.0, 5.949029922485352, 0.0, 13.279579162597656, 73.99919128417969, 0.0, -0.16130828857421875, 6.889984130859375, 38.25336456298828, 1.1182880401611328, 0.0, 34.0676155090332, 0.39005279541015625, 0.0, 41.220726013183594, 75.41980743408203, 13.633346557617188, 0.0, -0.304931640625, 15.1138916015625, 0.2599945068359375, 0.0, 8.643417358398438, 41.165672302246094, 0.0, 2.5619659423828125, 26.319900512695312, -0.12432098388671875, 0.0, 0.0, 78.74819946289062, 34.818729400634766, 65.79103088378906, -0.13030242919921875, -0.0710906982421875, 30.12194061279297, 37.65448760986328, 0.7623748779296875, 0.0, 0.0, 0.0, 2.7293548583984375, 2.7831039428710938, 0.0, 55.6094856262207, 0.0, 3.0821075439453125, 0.0, 0.0, 0.0, 0.228302001953125, -0.2177886962890625, 0.00460052490234375, 62.75098419189453, 0.0, 0.0, 12.190805435180664, 0.0, 0.0, 6.29425048828125, 0.0, 0.0, 0.0, 0.0, 23.50640869140625, 0.0, 0.0, 0.39520263671875, 0.0, 10.675857543945312, 0.0, -0.4002532958984375, 73.3317642211914, 0.0, 0.12804794311523438, 0.0, 0.374114990234375, 0.23653411865234375, 0.0, 0.0, 0.0, 17.218780517578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4568061828613281, 0.0, 27.200210571289062, 0.0, 49.77445983886719, -0.04979896545410156, 0.0, 49.828060150146484, 0.0, -0.070465087890625, 0.0, 0.16622161865234375, 63.404685974121094, 0.0, -0.2975006103515625, 21.139755249023438, 0.0, 0.0, 65.43730545043945, -0.1866607666015625], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 221, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 141, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 410, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.55754893695095, "mean_inference_ms": 4.977875769677692, "mean_action_processing_ms": 7.6564255310362395, "mean_env_wait_ms": 11.557786275825379, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20076408, "num_agent_steps_trained": 20076408, "num_env_steps_sampled": 20076408, "num_env_steps_trained": 20076408, "num_env_steps_sampled_this_iter": 60902, "num_env_steps_trained_this_iter": 60902, "timesteps_total": 20076408, "num_steps_trained_this_iter": 60902, "agent_timesteps_total": 20076408, "timers": {"training_iteration_time_ms": 49803.427, "load_time_ms": 54.345, "load_throughput": 1123348.633, "learn_time_ms": 27447.426, "learn_throughput": 2224.183, "synch_weights_time_ms": 10.988}, "counters": {"num_env_steps_sampled": 20076408, "num_env_steps_trained": 20076408, "num_agent_steps_sampled": 20076408, "num_agent_steps_trained": 20076408}, "done": false, "episodes_total": 40652, "training_iteration": 331, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-30-45", "timestamp": 1735108245, "time_this_iter_s": 49.84209084510803, "time_total_s": 9355.270423650742, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE8FD0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E32AD1B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 498.1405248641968, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.125714285714285, "ram_util_percent": 96.21571428571428}}
{"custom_metrics": {"rewards/0_mean": 6.349233705489362, "rewards/0_min": -0.60040283203125, "rewards/0_max": 70.55531311035156, "rewards/1_mean": 6.349233705489362, "rewards/1_min": -0.60040283203125, "rewards/1_max": 70.55531311035156, "rewards/2_mean": 6.349233705489362, "rewards/2_min": -0.60040283203125, "rewards/2_max": 70.55531311035156, "rewards/3_mean": 6.349233705489362, "rewards/3_min": -0.60040283203125, "rewards/3_max": 70.55531311035156, "rewards/4_mean": 6.349233705489362, "rewards/4_min": -0.60040283203125, "rewards/4_max": 70.55531311035156}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.1186849212185258, "policy_loss": 0.019968939986493853, "vf_loss": 0.08613607127400529, "vf_explained_var": 0.9646797386899827, "kl": 0.010438996298046458, "entropy": 22.53184109642392, "entropy_coeff": 0.01, "grad_gnorm": 1.1906644839142997}, "model": {}, "num_grad_updates_lifetime": 6660.5, "diff_num_grad_updates_vs_sampler_policy": 6659.5}}, "num_env_steps_sampled": 20137036, "num_env_steps_trained": 20137036, "num_agent_steps_sampled": 20137036, "num_agent_steps_trained": 20137036}, "sampler_results": {"episode_reward_max": 70.55531311035156, "episode_reward_min": -0.60040283203125, "episode_reward_mean": 6.349233705489362, "episode_len_mean": 496.95081967213116, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 6.349233705489362, "rewards/0_min": -0.60040283203125, "rewards/0_max": 70.55531311035156, "rewards/1_mean": 6.349233705489362, "rewards/1_min": -0.60040283203125, "rewards/1_max": 70.55531311035156, "rewards/2_mean": 6.349233705489362, "rewards/2_min": -0.60040283203125, "rewards/2_max": 70.55531311035156, "rewards/3_mean": 6.349233705489362, "rewards/3_min": -0.60040283203125, "rewards/3_max": 70.55531311035156, "rewards/4_mean": 6.349233705489362, "rewards/4_min": -0.60040283203125, "rewards/4_max": 70.55531311035156}, "hist_stats": {"episode_reward": [-0.0468902587890625, 0.0, 0.0, 0.0, 45.70545196533203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.302146911621094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.095458984375, 0.0, 70.55531311035156, 0.1506805419921875, 0.0, 39.678802490234375, 0.0, 28.80060577392578, 5.366382598876953, 6.5594635009765625, 0.0, 0.09813690185546875, 11.737045288085938, -0.034423828125, 0.0, 0.0, 0.0, 0.0, 8.832557678222656, 22.223712921142578, 0.0, 0.0, 33.6749267578125, 0.0, 10.797897338867188, 0.0, 0.0, 0.43428802490234375, 16.1697998046875, 0.0, 0.0, 8.388023376464844, 0.0, 26.590187072753906, 40.016395568847656, -0.361297607421875, 0.25447845458984375, 6.265785217285156, 0.02783966064453125, 0.0, 9.62933349609375, 0.0, 20.279518127441406, 0.0, 0.881439208984375, 0.0, 0.0, 0.052112579345703125, 3.4786758422851562, 0.0, 0.0, 0.0, 18.658405303955078, 0.0, 0.0, 0.5498275756835938, 26.4183349609375, 0.0, 0.3818016052246094, 20.200286865234375, 12.866561889648438, 0.0, 15.285224914550781, 0.0, 0.01639556884765625, 0.0, -0.5671844482421875, 4.436759948730469, 0.0, 10.234840393066406, 0.0, 36.47772979736328, 44.59734344482422, -0.60040283203125, 0.0, 0.0, 0.535003662109375, 0.0, -0.29227447509765625, 3.382396697998047, 0.0, 2.1942481994628906, -0.20973587036132812, 0.0, 0.0, -0.034942626953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.72823715209961, 27.489837646484375, 49.307634353637695, 40.13725280761719], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 213, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 415, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.574794568705034, "mean_inference_ms": 4.976982162091292, "mean_action_processing_ms": 7.661930752837511, "mean_env_wait_ms": 11.537294990930683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 70.55531311035156, "episode_reward_min": -0.60040283203125, "episode_reward_mean": 6.349233705489362, "episode_len_mean": 496.95081967213116, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.0468902587890625, 0.0, 0.0, 0.0, 45.70545196533203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.302146911621094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.095458984375, 0.0, 70.55531311035156, 0.1506805419921875, 0.0, 39.678802490234375, 0.0, 28.80060577392578, 5.366382598876953, 6.5594635009765625, 0.0, 0.09813690185546875, 11.737045288085938, -0.034423828125, 0.0, 0.0, 0.0, 0.0, 8.832557678222656, 22.223712921142578, 0.0, 0.0, 33.6749267578125, 0.0, 10.797897338867188, 0.0, 0.0, 0.43428802490234375, 16.1697998046875, 0.0, 0.0, 8.388023376464844, 0.0, 26.590187072753906, 40.016395568847656, -0.361297607421875, 0.25447845458984375, 6.265785217285156, 0.02783966064453125, 0.0, 9.62933349609375, 0.0, 20.279518127441406, 0.0, 0.881439208984375, 0.0, 0.0, 0.052112579345703125, 3.4786758422851562, 0.0, 0.0, 0.0, 18.658405303955078, 0.0, 0.0, 0.5498275756835938, 26.4183349609375, 0.0, 0.3818016052246094, 20.200286865234375, 12.866561889648438, 0.0, 15.285224914550781, 0.0, 0.01639556884765625, 0.0, -0.5671844482421875, 4.436759948730469, 0.0, 10.234840393066406, 0.0, 36.47772979736328, 44.59734344482422, -0.60040283203125, 0.0, 0.0, 0.535003662109375, 0.0, -0.29227447509765625, 3.382396697998047, 0.0, 2.1942481994628906, -0.20973587036132812, 0.0, 0.0, -0.034942626953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.72823715209961, 27.489837646484375, 49.307634353637695, 40.13725280761719], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 213, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 415, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.574794568705034, "mean_inference_ms": 4.976982162091292, "mean_action_processing_ms": 7.661930752837511, "mean_env_wait_ms": 11.537294990930683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20137036, "num_agent_steps_trained": 20137036, "num_env_steps_sampled": 20137036, "num_env_steps_trained": 20137036, "num_env_steps_sampled_this_iter": 60628, "num_env_steps_trained_this_iter": 60628, "timesteps_total": 20137036, "num_steps_trained_this_iter": 60628, "agent_timesteps_total": 20137036, "timers": {"training_iteration_time_ms": 48730.377, "load_time_ms": 54.352, "load_throughput": 1121077.365, "learn_time_ms": 27250.357, "learn_throughput": 2236.026, "synch_weights_time_ms": 10.117}, "counters": {"num_env_steps_sampled": 20137036, "num_env_steps_trained": 20137036, "num_agent_steps_sampled": 20137036, "num_agent_steps_trained": 20137036}, "done": false, "episodes_total": 40774, "training_iteration": 332, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-31-31", "timestamp": 1735108291, "time_this_iter_s": 46.235799074172974, "time_total_s": 9401.506222724915, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE7D60>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 544.3763239383698, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.733846153846155, "ram_util_percent": 96.13384615384616}}
{"custom_metrics": {"rewards/0_mean": 9.990186472408107, "rewards/0_min": -0.935150146484375, "rewards/0_max": 74.58151245117188, "rewards/1_mean": 9.990186472408107, "rewards/1_min": -0.935150146484375, "rewards/1_max": 74.58151245117188, "rewards/2_mean": 9.990186472408107, "rewards/2_min": -0.935150146484375, "rewards/2_max": 74.58151245117188, "rewards/3_mean": 9.990186472408107, "rewards/3_min": -0.935150146484375, "rewards/3_max": 74.58151245117188, "rewards/4_mean": 9.990186472408107, "rewards/4_min": -0.935150146484375, "rewards/4_max": 74.58151245117188}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.04177214335135114, "policy_loss": -0.0012853941081890038, "vf_loss": 0.16658861051065965, "vf_explained_var": 0.961155221599435, "kl": 0.009281988161808205, "entropy": 20.754526584867445, "entropy_coeff": 0.01, "grad_gnorm": 1.3532654868350142}, "model": {}, "num_grad_updates_lifetime": 7290.5, "diff_num_grad_updates_vs_sampler_policy": 7289.5}}, "num_env_steps_sampled": 20197397, "num_env_steps_trained": 20197397, "num_agent_steps_sampled": 20197397, "num_agent_steps_trained": 20197397}, "sampler_results": {"episode_reward_max": 74.58151245117188, "episode_reward_min": -0.935150146484375, "episode_reward_mean": 9.990186472408107, "episode_len_mean": 494.76229508196724, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.990186472408107, "rewards/0_min": -0.935150146484375, "rewards/0_max": 74.58151245117188, "rewards/1_mean": 9.990186472408107, "rewards/1_min": -0.935150146484375, "rewards/1_max": 74.58151245117188, "rewards/2_mean": 9.990186472408107, "rewards/2_min": -0.935150146484375, "rewards/2_max": 74.58151245117188, "rewards/3_mean": 9.990186472408107, "rewards/3_min": -0.935150146484375, "rewards/3_max": 74.58151245117188, "rewards/4_mean": 9.990186472408107, "rewards/4_min": -0.935150146484375, "rewards/4_max": 74.58151245117188}, "hist_stats": {"episode_reward": [3.4577407836914062, -0.935150146484375, 0.0, 38.818084716796875, 66.64925384521484, 0.5412940979003906, 0.0, 16.95734405517578, 0.0, 18.39563751220703, 0.30426788330078125, 4.098243713378906, 0.0, 55.03446960449219, 0.0, 8.963043212890625, 0.53570556640625, 0.0, 51.86002540588379, 0.0, 0.0, 74.58151245117188, 0.0, 0.0, 0.0, 37.98145294189453, 0.050037384033203125, 0.7193679809570312, 0.0, -0.0609893798828125, 1.52984619140625, 0.06377410888671875, 0.0, -0.15335845947265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8187255859375, 0.0, 13.354995727539062, 21.099044799804688, 0.0, 0.0, 0.0, 51.5230827331543, 0.082244873046875, 0.0, 0.0, 0.0, 35.49401092529297, 52.98914337158203, 0.0, 0.0, 20.77581024169922, 0.0, 0.0, 19.456825256347656, 23.78585433959961, 11.995067596435547, 0.0, 58.72880554199219, 0.0, 8.611166000366211, 50.423828125, 0.0, 32.61597442626953, 46.621925354003906, 0.0, 26.592761993408203, 16.067750930786133, 22.522750854492188, 28.79657745361328, 0.0, 10.093564987182617, 15.932197570800781, 0.0, 0.0, -0.58380126953125, 0.0, 6.49993896484375, 0.0, 0.0, 0.0, 0.0, 10.300636291503906, 26.095474243164062, 0.5143508911132812, 69.71736145019531, 0.5969009399414062, 0.0, 0.0, 30.33679962158203, -0.13835525512695312, 0.0, 28.863235473632812, 0.0, 0.0, -0.43036651611328125, 0.0, 0.0, 0.0, 28.034420013427734, 0.8825035095214844, 0.0, 1.115692138671875, 0.0, -0.0080413818359375, 17.110702514648438, 0.0, 0.0, 0.0, 0.0, 0.3240699768066406, -0.00049591064453125, 0.0, 0.0, 53.435462951660156, 0.0, 0.0], "episode_lengths": [500, 500, 500, 364, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 182, 500, 500, 500, 500, 500, 500, 476, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625394296052063, "mean_inference_ms": 4.979065381511365, "mean_action_processing_ms": 7.682449126511249, "mean_env_wait_ms": 11.565029039216435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.58151245117188, "episode_reward_min": -0.935150146484375, "episode_reward_mean": 9.990186472408107, "episode_len_mean": 494.76229508196724, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [3.4577407836914062, -0.935150146484375, 0.0, 38.818084716796875, 66.64925384521484, 0.5412940979003906, 0.0, 16.95734405517578, 0.0, 18.39563751220703, 0.30426788330078125, 4.098243713378906, 0.0, 55.03446960449219, 0.0, 8.963043212890625, 0.53570556640625, 0.0, 51.86002540588379, 0.0, 0.0, 74.58151245117188, 0.0, 0.0, 0.0, 37.98145294189453, 0.050037384033203125, 0.7193679809570312, 0.0, -0.0609893798828125, 1.52984619140625, 0.06377410888671875, 0.0, -0.15335845947265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8187255859375, 0.0, 13.354995727539062, 21.099044799804688, 0.0, 0.0, 0.0, 51.5230827331543, 0.082244873046875, 0.0, 0.0, 0.0, 35.49401092529297, 52.98914337158203, 0.0, 0.0, 20.77581024169922, 0.0, 0.0, 19.456825256347656, 23.78585433959961, 11.995067596435547, 0.0, 58.72880554199219, 0.0, 8.611166000366211, 50.423828125, 0.0, 32.61597442626953, 46.621925354003906, 0.0, 26.592761993408203, 16.067750930786133, 22.522750854492188, 28.79657745361328, 0.0, 10.093564987182617, 15.932197570800781, 0.0, 0.0, -0.58380126953125, 0.0, 6.49993896484375, 0.0, 0.0, 0.0, 0.0, 10.300636291503906, 26.095474243164062, 0.5143508911132812, 69.71736145019531, 0.5969009399414062, 0.0, 0.0, 30.33679962158203, -0.13835525512695312, 0.0, 28.863235473632812, 0.0, 0.0, -0.43036651611328125, 0.0, 0.0, 0.0, 28.034420013427734, 0.8825035095214844, 0.0, 1.115692138671875, 0.0, -0.0080413818359375, 17.110702514648438, 0.0, 0.0, 0.0, 0.0, 0.3240699768066406, -0.00049591064453125, 0.0, 0.0, 53.435462951660156, 0.0, 0.0], "episode_lengths": [500, 500, 500, 364, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 182, 500, 500, 500, 500, 500, 500, 476, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625394296052063, "mean_inference_ms": 4.979065381511365, "mean_action_processing_ms": 7.682449126511249, "mean_env_wait_ms": 11.565029039216435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20197397, "num_agent_steps_trained": 20197397, "num_env_steps_sampled": 20197397, "num_env_steps_trained": 20197397, "num_env_steps_sampled_this_iter": 60361, "num_env_steps_trained_this_iter": 60361, "timesteps_total": 20197397, "num_steps_trained_this_iter": 60361, "agent_timesteps_total": 20197397, "timers": {"training_iteration_time_ms": 48356.55, "load_time_ms": 53.139, "load_throughput": 1145427.12, "learn_time_ms": 27125.305, "learn_throughput": 2243.894, "synch_weights_time_ms": 10.111}, "counters": {"num_env_steps_sampled": 20197397, "num_env_steps_trained": 20197397, "num_agent_steps_sampled": 20197397, "num_agent_steps_trained": 20197397}, "done": false, "episodes_total": 40896, "training_iteration": 333, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-32-19", "timestamp": 1735108339, "time_this_iter_s": 47.563111543655396, "time_total_s": 9449.06933426857, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A91DB0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3959E10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 591.9394354820251, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.45522388059701, "ram_util_percent": 96.34328358208955}}
{"custom_metrics": {"rewards/0_mean": 8.678951263427734, "rewards/0_min": -0.7646293640136719, "rewards/0_max": 69.29899597167969, "rewards/1_mean": 8.678951263427734, "rewards/1_min": -0.7646293640136719, "rewards/1_max": 69.29899597167969, "rewards/2_mean": 8.678951263427734, "rewards/2_min": -0.7646293640136719, "rewards/2_max": 69.29899597167969, "rewards/3_mean": 8.678951263427734, "rewards/3_min": -0.7646293640136719, "rewards/3_max": 69.29899597167969, "rewards/4_mean": 8.678951263427734, "rewards/4_min": -0.7646293640136719, "rewards/4_max": 69.29899597167969}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.1350035462596838, "policy_loss": -0.006154567257515967, "vf_loss": 0.08485442977731249, "vf_explained_var": 0.9892307381781321, "kl": 0.013070635383002578, "entropy": 21.436511459047832, "entropy_coeff": 0.01, "grad_gnorm": 1.7128360948510586}, "model": {}, "num_grad_updates_lifetime": 7920.5, "diff_num_grad_updates_vs_sampler_policy": 7919.5}}, "num_env_steps_sampled": 20258185, "num_env_steps_trained": 20258185, "num_agent_steps_sampled": 20258185, "num_agent_steps_trained": 20258185}, "sampler_results": {"episode_reward_max": 69.29899597167969, "episode_reward_min": -0.7646293640136719, "episode_reward_mean": 8.678951263427734, "episode_len_mean": 490.2258064516129, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.678951263427734, "rewards/0_min": -0.7646293640136719, "rewards/0_max": 69.29899597167969, "rewards/1_mean": 8.678951263427734, "rewards/1_min": -0.7646293640136719, "rewards/1_max": 69.29899597167969, "rewards/2_mean": 8.678951263427734, "rewards/2_min": -0.7646293640136719, "rewards/2_max": 69.29899597167969, "rewards/3_mean": 8.678951263427734, "rewards/3_min": -0.7646293640136719, "rewards/3_max": 69.29899597167969, "rewards/4_mean": 8.678951263427734, "rewards/4_min": -0.7646293640136719, "rewards/4_max": 69.29899597167969}, "hist_stats": {"episode_reward": [0.0, 47.69636154174805, 0.0, 0.0, 0.0, 0.0, 21.819137573242188, 25.510658264160156, 0.0, 61.700557708740234, 0.0, 10.60443115234375, 0.0, 48.586647033691406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6465606689453125, 0.088043212890625, 1.50152587890625, 0.0, 0.0, 3.8093414306640625, 0.2113800048828125, 52.55257606506348, 0.0, 0.02497100830078125, 4.407135009765625, 0.0, 0.0, -0.0607452392578125, 4.1516265869140625, 53.22253227233887, 65.94178009033203, 15.05575942993164, 0.0, 0.16184234619140625, 0.019077301025390625, 0.0, 17.450923919677734, 0.0, 0.0, 0.0, 53.87028503417969, 0.0, 0.0, 44.79601287841797, -0.7646293640136719, 0.0, -0.6111679077148438, -0.08266448974609375, 0.0, 0.0, 12.242294311523438, -0.1312713623046875, 0.0, 56.96691131591797, 0.0, 0.26180267333984375, -0.15055084228515625, 0.0, 10.479087829589844, 0.4092903137207031, -0.00832366943359375, -0.163909912109375, -0.2985954284667969, 9.985477447509766, 0.0976104736328125, 9.645528793334961, 0.0, -0.13338088989257812, 0.0, 0.0, 0.0, -0.7284698486328125, 0.015838623046875, 0.0, -0.02455902099609375, 25.14532470703125, 0.0, 0.0, 69.29899597167969, 11.313972473144531, 0.0, 0.0, 0.0, 55.51144790649414, 0.0, 59.88560485839844, -0.4496002197265625, 60.45100212097168, 0.0, 0.11090087890625, 0.3431358337402344, 0.0, -0.024932861328125, 2.2506561279296875, -0.00519561767578125, 0.0, 0.0, 0.0, -0.05930328369140625, 0.0, 0.0, 0.0, 0.0, 41.121490478515625, 0.0, 6.7910308837890625, 0.126495361328125, -0.14164352416992188, 16.664512634277344, 0.0, 0.0, 4.887847900390625, 50.9061393737793, -0.01007080078125, 6.017425537109375, 11.580970764160156, 13.644332885742188, 10.054676055908203], "episode_lengths": [500, 341, 500, 500, 500, 500, 460, 500, 500, 500, 500, 500, 500, 322, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 402, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 178, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 418, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.636456034068114, "mean_inference_ms": 4.99563349885024, "mean_action_processing_ms": 7.660082564192342, "mean_env_wait_ms": 11.547455492226671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 69.29899597167969, "episode_reward_min": -0.7646293640136719, "episode_reward_mean": 8.678951263427734, "episode_len_mean": 490.2258064516129, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 47.69636154174805, 0.0, 0.0, 0.0, 0.0, 21.819137573242188, 25.510658264160156, 0.0, 61.700557708740234, 0.0, 10.60443115234375, 0.0, 48.586647033691406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6465606689453125, 0.088043212890625, 1.50152587890625, 0.0, 0.0, 3.8093414306640625, 0.2113800048828125, 52.55257606506348, 0.0, 0.02497100830078125, 4.407135009765625, 0.0, 0.0, -0.0607452392578125, 4.1516265869140625, 53.22253227233887, 65.94178009033203, 15.05575942993164, 0.0, 0.16184234619140625, 0.019077301025390625, 0.0, 17.450923919677734, 0.0, 0.0, 0.0, 53.87028503417969, 0.0, 0.0, 44.79601287841797, -0.7646293640136719, 0.0, -0.6111679077148438, -0.08266448974609375, 0.0, 0.0, 12.242294311523438, -0.1312713623046875, 0.0, 56.96691131591797, 0.0, 0.26180267333984375, -0.15055084228515625, 0.0, 10.479087829589844, 0.4092903137207031, -0.00832366943359375, -0.163909912109375, -0.2985954284667969, 9.985477447509766, 0.0976104736328125, 9.645528793334961, 0.0, -0.13338088989257812, 0.0, 0.0, 0.0, -0.7284698486328125, 0.015838623046875, 0.0, -0.02455902099609375, 25.14532470703125, 0.0, 0.0, 69.29899597167969, 11.313972473144531, 0.0, 0.0, 0.0, 55.51144790649414, 0.0, 59.88560485839844, -0.4496002197265625, 60.45100212097168, 0.0, 0.11090087890625, 0.3431358337402344, 0.0, -0.024932861328125, 2.2506561279296875, -0.00519561767578125, 0.0, 0.0, 0.0, -0.05930328369140625, 0.0, 0.0, 0.0, 0.0, 41.121490478515625, 0.0, 6.7910308837890625, 0.126495361328125, -0.14164352416992188, 16.664512634277344, 0.0, 0.0, 4.887847900390625, 50.9061393737793, -0.01007080078125, 6.017425537109375, 11.580970764160156, 13.644332885742188, 10.054676055908203], "episode_lengths": [500, 341, 500, 500, 500, 500, 460, 500, 500, 500, 500, 500, 500, 322, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 402, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 178, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 418, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.636456034068114, "mean_inference_ms": 4.99563349885024, "mean_action_processing_ms": 7.660082564192342, "mean_env_wait_ms": 11.547455492226671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20258185, "num_agent_steps_trained": 20258185, "num_env_steps_sampled": 20258185, "num_env_steps_trained": 20258185, "num_env_steps_sampled_this_iter": 60788, "num_env_steps_trained_this_iter": 60788, "timesteps_total": 20258185, "num_steps_trained_this_iter": 60788, "agent_timesteps_total": 20258185, "timers": {"training_iteration_time_ms": 48171.204, "load_time_ms": 49.716, "load_throughput": 1224513.764, "learn_time_ms": 27044.089, "learn_throughput": 2251.05, "synch_weights_time_ms": 10.118}, "counters": {"num_env_steps_sampled": 20258185, "num_env_steps_trained": 20258185, "num_agent_steps_sampled": 20258185, "num_agent_steps_trained": 20258185}, "done": false, "episodes_total": 41020, "training_iteration": 334, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-33-05", "timestamp": 1735108385, "time_this_iter_s": 46.21825432777405, "time_total_s": 9495.287588596344, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEB220>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 638.1576898097992, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.88615384615385, "ram_util_percent": 96.13230769230769}}
{"evaluation": {"episode_reward_max": 13.80859375, "episode_reward_min": 13.80859375, "episode_reward_mean": 13.80859375, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 13.80859375, "rewards/0_min": 13.80859375, "rewards/0_max": 13.80859375, "rewards/1_mean": 13.80859375, "rewards/1_min": 13.80859375, "rewards/1_max": 13.80859375, "rewards/2_mean": 13.80859375, "rewards/2_min": 13.80859375, "rewards/2_max": 13.80859375, "rewards/3_mean": 13.80859375, "rewards/3_min": 13.80859375, "rewards/3_max": 13.80859375, "rewards/4_mean": 13.80859375, "rewards/4_min": 13.80859375, "rewards/4_max": 13.80859375}, "hist_stats": {"episode_reward": [13.80859375], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7078390293006973, "mean_inference_ms": 3.410352380334497, "mean_action_processing_ms": 0.5098156417551872, "mean_env_wait_ms": 5.776744139821906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 7.413671850188961, "rewards/0_min": -0.810546875, "rewards/0_max": 72.78057098388672, "rewards/1_mean": 7.413671850188961, "rewards/1_min": -0.810546875, "rewards/1_max": 72.78057098388672, "rewards/2_mean": 7.413671850188961, "rewards/2_min": -0.810546875, "rewards/2_max": 72.78057098388672, "rewards/3_mean": 7.413671850188961, "rewards/3_min": -0.810546875, "rewards/3_max": 72.78057098388672, "rewards/4_mean": 7.413671850188961, "rewards/4_min": -0.810546875, "rewards/4_max": 72.78057098388672}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10325498823889546, "policy_loss": 0.0004270128772727081, "vf_loss": 0.12042011177677306, "vf_explained_var": 0.9499983339082627, "kl": 0.009154218024692483, "entropy": 22.456555121285575, "entropy_coeff": 0.01, "grad_gnorm": 1.1739786228135465}, "model": {}, "num_grad_updates_lifetime": 8550.5, "diff_num_grad_updates_vs_sampler_policy": 8549.5}}, "num_env_steps_sampled": 20318776, "num_env_steps_trained": 20318776, "num_agent_steps_sampled": 20318776, "num_agent_steps_trained": 20318776}, "sampler_results": {"episode_reward_max": 72.78057098388672, "episode_reward_min": -0.810546875, "episode_reward_mean": 7.413671850188961, "episode_len_mean": 492.609756097561, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.413671850188961, "rewards/0_min": -0.810546875, "rewards/0_max": 72.78057098388672, "rewards/1_mean": 7.413671850188961, "rewards/1_min": -0.810546875, "rewards/1_max": 72.78057098388672, "rewards/2_mean": 7.413671850188961, "rewards/2_min": -0.810546875, "rewards/2_max": 72.78057098388672, "rewards/3_mean": 7.413671850188961, "rewards/3_min": -0.810546875, "rewards/3_max": 72.78057098388672, "rewards/4_mean": 7.413671850188961, "rewards/4_min": -0.810546875, "rewards/4_max": 72.78057098388672}, "hist_stats": {"episode_reward": [60.54566955566406, 0.0, 0.2642402648925781, 0.0, 0.0, 0.0, 18.1435546875, -0.0927886962890625, 0.0, -0.20449066162109375, 0.18073654174804688, -0.204315185546875, 0.7474899291992188, -0.1451263427734375, 0.0, 0.4053497314453125, 0.0, 0.0, 0.14166259765625, 0.0, 0.0, -0.01667022705078125, 66.75529479980469, 72.78057098388672, 0.0, 0.0, 0.33819580078125, 0.0, 0.0, 0.0, 0.09822845458984375, 0.0, 0.0, -0.810546875, 33.272666931152344, 33.679718017578125, 0.1358795166015625, 0.0, 0.0705108642578125, 18.89923095703125, 0.0, 0.0, 1.9173431396484375, 0.50689697265625, 0.6473159790039062, 0.0, 0.0, -0.3739471435546875, 0.0, 0.0, 30.235870361328125, 42.295875549316406, 0.0, 0.0, 37.113555908203125, -0.07348251342773438, 0.904144287109375, -0.007465362548828125, 0.0, 0.6349906921386719, 0.0, 0.0, 7.219707489013672, 6.114261627197266, 40.221405029296875, 17.64508056640625, -0.08501434326171875, -0.17119598388671875, 25.77525520324707, 58.36114501953125, 19.496124267578125, 0.0, 0.0, 0.0, 36.12318420410156, 0.0, 0.31572723388671875, 0.0, 21.315570831298828, 64.53355407714844, 0.28118133544921875, 9.735336303710938, 12.660888671875, 0.0, 0.0, 0.0, 0.0, 7.670923233032227, 3.7826995849609375, 0.0, 11.471492767333984, 0.0, -0.24229049682617188, -0.0570068359375, 0.0, -0.330230712890625, 23.79433822631836, 0.0, 0.0, 0.0410919189453125, 0.6466064453125, 0.0, 11.65549087524414, 0.41033935546875, 2.7884063720703125, 0.0, 0.0, 45.701812744140625, 0.0, 59.86927032470703, 0.0, -0.4071769714355469, 0.0, 7.072227478027344, 0.0, 0.0, 0.0, 0.0, 0.0599212646484375, 0.0, -0.3746490478515625, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 500, 500, 500, 500, 246, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 154, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.636029631490633, "mean_inference_ms": 4.996140426358344, "mean_action_processing_ms": 7.6429998043007865, "mean_env_wait_ms": 11.550861580550439, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 72.78057098388672, "episode_reward_min": -0.810546875, "episode_reward_mean": 7.413671850188961, "episode_len_mean": 492.609756097561, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [60.54566955566406, 0.0, 0.2642402648925781, 0.0, 0.0, 0.0, 18.1435546875, -0.0927886962890625, 0.0, -0.20449066162109375, 0.18073654174804688, -0.204315185546875, 0.7474899291992188, -0.1451263427734375, 0.0, 0.4053497314453125, 0.0, 0.0, 0.14166259765625, 0.0, 0.0, -0.01667022705078125, 66.75529479980469, 72.78057098388672, 0.0, 0.0, 0.33819580078125, 0.0, 0.0, 0.0, 0.09822845458984375, 0.0, 0.0, -0.810546875, 33.272666931152344, 33.679718017578125, 0.1358795166015625, 0.0, 0.0705108642578125, 18.89923095703125, 0.0, 0.0, 1.9173431396484375, 0.50689697265625, 0.6473159790039062, 0.0, 0.0, -0.3739471435546875, 0.0, 0.0, 30.235870361328125, 42.295875549316406, 0.0, 0.0, 37.113555908203125, -0.07348251342773438, 0.904144287109375, -0.007465362548828125, 0.0, 0.6349906921386719, 0.0, 0.0, 7.219707489013672, 6.114261627197266, 40.221405029296875, 17.64508056640625, -0.08501434326171875, -0.17119598388671875, 25.77525520324707, 58.36114501953125, 19.496124267578125, 0.0, 0.0, 0.0, 36.12318420410156, 0.0, 0.31572723388671875, 0.0, 21.315570831298828, 64.53355407714844, 0.28118133544921875, 9.735336303710938, 12.660888671875, 0.0, 0.0, 0.0, 0.0, 7.670923233032227, 3.7826995849609375, 0.0, 11.471492767333984, 0.0, -0.24229049682617188, -0.0570068359375, 0.0, -0.330230712890625, 23.79433822631836, 0.0, 0.0, 0.0410919189453125, 0.6466064453125, 0.0, 11.65549087524414, 0.41033935546875, 2.7884063720703125, 0.0, 0.0, 45.701812744140625, 0.0, 59.86927032470703, 0.0, -0.4071769714355469, 0.0, 7.072227478027344, 0.0, 0.0, 0.0, 0.0, 0.0599212646484375, 0.0, -0.3746490478515625, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 500, 500, 500, 500, 246, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 154, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.636029631490633, "mean_inference_ms": 4.996140426358344, "mean_action_processing_ms": 7.6429998043007865, "mean_env_wait_ms": 11.550861580550439, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20318776, "num_agent_steps_trained": 20318776, "num_env_steps_sampled": 20318776, "num_env_steps_trained": 20318776, "num_env_steps_sampled_this_iter": 60591, "num_env_steps_trained_this_iter": 60591, "timesteps_total": 20318776, "num_steps_trained_this_iter": 60591, "agent_timesteps_total": 20318776, "timers": {"training_iteration_time_ms": 47779.594, "load_time_ms": 48.581, "load_throughput": 1251724.4, "learn_time_ms": 26771.019, "learn_throughput": 2271.475, "synch_weights_time_ms": 10.064}, "counters": {"num_env_steps_sampled": 20318776, "num_env_steps_trained": 20318776, "num_agent_steps_sampled": 20318776, "num_agent_steps_trained": 20318776}, "done": false, "episodes_total": 41143, "training_iteration": 335, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-33-51", "timestamp": 1735108431, "time_this_iter_s": 45.985230684280396, "time_total_s": 9541.272819280624, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B09570>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E32AD1B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 684.1429204940796, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.01230769230769, "ram_util_percent": 96.18769230769229}}
{"custom_metrics": {"rewards/0_mean": 10.547712218376898, "rewards/0_min": -0.8438758850097656, "rewards/0_max": 85.14298248291016, "rewards/1_mean": 10.547712218376898, "rewards/1_min": -0.8438758850097656, "rewards/1_max": 85.14298248291016, "rewards/2_mean": 10.547712218376898, "rewards/2_min": -0.8438758850097656, "rewards/2_max": 85.14298248291016, "rewards/3_mean": 10.547712218376898, "rewards/3_min": -0.8438758850097656, "rewards/3_max": 85.14298248291016, "rewards/4_mean": 10.547712218376898, "rewards/4_min": -0.8438758850097656, "rewards/4_max": 85.14298248291016}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08577174772286698, "policy_loss": 0.0025365335558215894, "vf_loss": 0.1226826692059163, "vf_explained_var": 0.9906219598792848, "kl": 0.012497396894272358, "entropy": 21.16236369117858, "entropy_coeff": 0.01, "grad_gnorm": 1.3889595153076308}, "model": {}, "num_grad_updates_lifetime": 9180.5, "diff_num_grad_updates_vs_sampler_policy": 9179.5}}, "num_env_steps_sampled": 20379749, "num_env_steps_trained": 20379749, "num_agent_steps_sampled": 20379749, "num_agent_steps_trained": 20379749}, "sampler_results": {"episode_reward_max": 85.14298248291016, "episode_reward_min": -0.8438758850097656, "episode_reward_mean": 10.547712218376898, "episode_len_mean": 491.71774193548384, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.547712218376898, "rewards/0_min": -0.8438758850097656, "rewards/0_max": 85.14298248291016, "rewards/1_mean": 10.547712218376898, "rewards/1_min": -0.8438758850097656, "rewards/1_max": 85.14298248291016, "rewards/2_mean": 10.547712218376898, "rewards/2_min": -0.8438758850097656, "rewards/2_max": 85.14298248291016, "rewards/3_mean": 10.547712218376898, "rewards/3_min": -0.8438758850097656, "rewards/3_max": 85.14298248291016, "rewards/4_mean": 10.547712218376898, "rewards/4_min": -0.8438758850097656, "rewards/4_max": 85.14298248291016}, "hist_stats": {"episode_reward": [0.0, 0.0, 58.179649353027344, 0.0, 62.44404983520508, 0.0, 0.0, 0.0, -0.009857177734375, 0.0, -0.13542556762695312, 0.0, 22.930479049682617, 21.333675384521484, 0.0, 68.69441986083984, 1.55084228515625, 58.46437072753906, 0.0, 1.8836517333984375, 0.0, 18.577529907226562, 0.0, 0.0, 0.0, 0.0, 0.0, 52.32831954956055, 0.0, 0.0, 0.0, 0.35900115966796875, 2.6723480224609375, 34.036834716796875, 59.86638641357422, 0.0, 0.0, 0.0, 0.0, 0.338134765625, 0.0, 0.0, 0.0, 0.10089874267578125, -0.32666778564453125, -0.18869781494140625, 16.76068115234375, 0.0, 75.44509887695312, 0.0, 0.0, -0.8438758850097656, 0.0, 4.431488037109375, 0.0002593994140625, 0.0, 0.319244384765625, 15.5770263671875, 0.0, 0.28647613525390625, 0.0, 19.204505920410156, 5.204193115234375, 0.0, 31.086715698242188, 37.66399574279785, 8.553485870361328, 33.385751724243164, 49.31201171875, 0.0, 0.0, 11.608394622802734, -0.0167999267578125, 0.0, 2.94854736328125, 0.0, 51.745941162109375, 0.6613311767578125, 0.0, -0.139404296875, 13.272872924804688, 0.08153915405273438, 0.0, -0.20684814453125, 85.14298248291016, 0.0, 22.452804565429688, 19.018760681152344, 0.0, 0.15772247314453125, -0.03900146484375, 38.6986083984375, 0.0, -0.268798828125, -0.1772613525390625, -0.2289581298828125, 16.386157989501953, 29.036094665527344, 0.06313323974609375, 0.0, 38.15087890625, 0.0, 0.0, 65.99894714355469, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5179176330566406, 0.0, 2.257904052734375, 15.466482162475586, 0.0, 0.0, 41.8592529296875, 30.43903350830078, 33.62933158874512, 0.0, 0.0, 0.0, 30.044506072998047, 1.05645751953125, -0.15338134765625], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 207, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 298, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 430, 500, 500, 500, 274, 264, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.62041383017534, "mean_inference_ms": 4.977378828690993, "mean_action_processing_ms": 7.602707935187667, "mean_env_wait_ms": 11.518965719918079, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 85.14298248291016, "episode_reward_min": -0.8438758850097656, "episode_reward_mean": 10.547712218376898, "episode_len_mean": 491.71774193548384, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 58.179649353027344, 0.0, 62.44404983520508, 0.0, 0.0, 0.0, -0.009857177734375, 0.0, -0.13542556762695312, 0.0, 22.930479049682617, 21.333675384521484, 0.0, 68.69441986083984, 1.55084228515625, 58.46437072753906, 0.0, 1.8836517333984375, 0.0, 18.577529907226562, 0.0, 0.0, 0.0, 0.0, 0.0, 52.32831954956055, 0.0, 0.0, 0.0, 0.35900115966796875, 2.6723480224609375, 34.036834716796875, 59.86638641357422, 0.0, 0.0, 0.0, 0.0, 0.338134765625, 0.0, 0.0, 0.0, 0.10089874267578125, -0.32666778564453125, -0.18869781494140625, 16.76068115234375, 0.0, 75.44509887695312, 0.0, 0.0, -0.8438758850097656, 0.0, 4.431488037109375, 0.0002593994140625, 0.0, 0.319244384765625, 15.5770263671875, 0.0, 0.28647613525390625, 0.0, 19.204505920410156, 5.204193115234375, 0.0, 31.086715698242188, 37.66399574279785, 8.553485870361328, 33.385751724243164, 49.31201171875, 0.0, 0.0, 11.608394622802734, -0.0167999267578125, 0.0, 2.94854736328125, 0.0, 51.745941162109375, 0.6613311767578125, 0.0, -0.139404296875, 13.272872924804688, 0.08153915405273438, 0.0, -0.20684814453125, 85.14298248291016, 0.0, 22.452804565429688, 19.018760681152344, 0.0, 0.15772247314453125, -0.03900146484375, 38.6986083984375, 0.0, -0.268798828125, -0.1772613525390625, -0.2289581298828125, 16.386157989501953, 29.036094665527344, 0.06313323974609375, 0.0, 38.15087890625, 0.0, 0.0, 65.99894714355469, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5179176330566406, 0.0, 2.257904052734375, 15.466482162475586, 0.0, 0.0, 41.8592529296875, 30.43903350830078, 33.62933158874512, 0.0, 0.0, 0.0, 30.044506072998047, 1.05645751953125, -0.15338134765625], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 207, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 298, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 430, 500, 500, 500, 274, 264, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.62041383017534, "mean_inference_ms": 4.977378828690993, "mean_action_processing_ms": 7.602707935187667, "mean_env_wait_ms": 11.518965719918079, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20379749, "num_agent_steps_trained": 20379749, "num_env_steps_sampled": 20379749, "num_env_steps_trained": 20379749, "num_env_steps_sampled_this_iter": 60973, "num_env_steps_trained_this_iter": 60973, "timesteps_total": 20379749, "num_steps_trained_this_iter": 60973, "agent_timesteps_total": 20379749, "timers": {"training_iteration_time_ms": 47337.51, "load_time_ms": 47.017, "load_throughput": 1292956.657, "learn_time_ms": 26541.956, "learn_throughput": 2290.378, "synch_weights_time_ms": 9.595}, "counters": {"num_env_steps_sampled": 20379749, "num_env_steps_trained": 20379749, "num_agent_steps_sampled": 20379749, "num_agent_steps_trained": 20379749}, "done": false, "episodes_total": 41267, "training_iteration": 336, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-34-38", "timestamp": 1735108478, "time_this_iter_s": 46.8129141330719, "time_total_s": 9588.085733413696, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0BDF0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E39F7760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 730.9558346271515, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 19.469696969696965, "ram_util_percent": 95.78030303030302}}
{"custom_metrics": {"rewards/0_mean": 12.191718760544692, "rewards/0_min": -0.6708221435546875, "rewards/0_max": 82.72962951660156, "rewards/1_mean": 12.191718760544692, "rewards/1_min": -0.6708221435546875, "rewards/1_max": 82.72962951660156, "rewards/2_mean": 12.191718760544692, "rewards/2_min": -0.6708221435546875, "rewards/2_max": 82.72962951660156, "rewards/3_mean": 12.191718760544692, "rewards/3_min": -0.6708221435546875, "rewards/3_max": 82.72962951660156, "rewards/4_mean": 12.191718760544692, "rewards/4_min": -0.6708221435546875, "rewards/4_max": 82.72962951660156}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07613206923392321, "policy_loss": -0.005811409088265565, "vf_loss": 0.13262387695944025, "vf_explained_var": 0.9905246901133704, "kl": 0.012851553448357634, "entropy": 20.359515176500594, "entropy_coeff": 0.01, "grad_gnorm": 1.7173174113035201}, "model": {}, "num_grad_updates_lifetime": 9810.5, "diff_num_grad_updates_vs_sampler_policy": 9809.5}}, "num_env_steps_sampled": 20440537, "num_env_steps_trained": 20440537, "num_agent_steps_sampled": 20440537, "num_agent_steps_trained": 20440537}, "sampler_results": {"episode_reward_max": 82.72962951660156, "episode_reward_min": -0.6708221435546875, "episode_reward_mean": 12.191718760544692, "episode_len_mean": 494.2113821138211, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 12.191718760544692, "rewards/0_min": -0.6708221435546875, "rewards/0_max": 82.72962951660156, "rewards/1_mean": 12.191718760544692, "rewards/1_min": -0.6708221435546875, "rewards/1_max": 82.72962951660156, "rewards/2_mean": 12.191718760544692, "rewards/2_min": -0.6708221435546875, "rewards/2_max": 82.72962951660156, "rewards/3_mean": 12.191718760544692, "rewards/3_min": -0.6708221435546875, "rewards/3_max": 82.72962951660156, "rewards/4_mean": 12.191718760544692, "rewards/4_min": -0.6708221435546875, "rewards/4_max": 82.72962951660156}, "hist_stats": {"episode_reward": [-0.0700225830078125, 0.0, 0.0, 0.0, 0.0, 0.33148193359375, 7.5496673583984375, 0.6422271728515625, 0.0, 0.0, 0.26154327392578125, 0.0, -0.1358795166015625, 59.42650604248047, 0.0, 9.302169799804688, 44.47801208496094, 0.0, 0.0, 0.0, 44.974327087402344, -0.41802978515625, 0.0, 16.62305450439453, 21.804237365722656, 0.0, 15.239803314208984, 6.586677551269531, 0.0, 18.53618621826172, 0.0, 0.0, 55.14153289794922, 68.6307373046875, 4.1927337646484375, 0.0, 0.3500862121582031, 0.0, 0.0, 34.26506042480469, 29.425392150878906, 0.0, 0.0929718017578125, 11.198127746582031, 27.37554931640625, 0.2264404296875, 0.0, 5.89764404296875, 0.0, 0.0, 0.131744384765625, 0.0, 14.050056457519531, 82.72962951660156, 61.527915954589844, 0.0, 0.46437835693359375, 0.2767791748046875, 41.21818542480469, -0.1230316162109375, 0.0, 62.332061767578125, 26.128246307373047, 56.28288459777832, 0.0, 0.0, 0.0, 63.01264953613281, 0.0, 0.1232147216796875, 0.0, 57.477272033691406, 0.0, -0.029571533203125, 0.5637588500976562, 56.793182373046875, 0.0, 5.8123016357421875, 0.0, 0.0, 0.0, 34.97760009765625, 9.709259033203125, 50.28558349609375, 0.15246963500976562, 69.64163970947266, 0.0, 19.896177291870117, 56.19946479797363, 0.0, 0.0, 0.0, 0.0190887451171875, 0.0, 0.0, 58.829254150390625, 0.0, 32.63865661621094, -0.09515380859375, 0.0, 0.0, 0.0584259033203125, 0.0, -0.085845947265625, 0.0, 37.06475067138672, 0.0, 0.19055557250976562, 41.57420349121094, -0.1206512451171875, -0.6708221435546875, 0.0, 0.0, 0.061206817626953125, 21.2520751953125, -0.0923004150390625, 0.0, 0.0, 0.0, -0.00818634033203125, 0.0, 57.58721160888672, -0.1831512451171875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 286, 500, 500, 500, 500, 500, 500, 500, 379, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.566137658898255, "mean_inference_ms": 4.9569653033479435, "mean_action_processing_ms": 7.585796125166216, "mean_env_wait_ms": 11.482777441995246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 82.72962951660156, "episode_reward_min": -0.6708221435546875, "episode_reward_mean": 12.191718760544692, "episode_len_mean": 494.2113821138211, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.0700225830078125, 0.0, 0.0, 0.0, 0.0, 0.33148193359375, 7.5496673583984375, 0.6422271728515625, 0.0, 0.0, 0.26154327392578125, 0.0, -0.1358795166015625, 59.42650604248047, 0.0, 9.302169799804688, 44.47801208496094, 0.0, 0.0, 0.0, 44.974327087402344, -0.41802978515625, 0.0, 16.62305450439453, 21.804237365722656, 0.0, 15.239803314208984, 6.586677551269531, 0.0, 18.53618621826172, 0.0, 0.0, 55.14153289794922, 68.6307373046875, 4.1927337646484375, 0.0, 0.3500862121582031, 0.0, 0.0, 34.26506042480469, 29.425392150878906, 0.0, 0.0929718017578125, 11.198127746582031, 27.37554931640625, 0.2264404296875, 0.0, 5.89764404296875, 0.0, 0.0, 0.131744384765625, 0.0, 14.050056457519531, 82.72962951660156, 61.527915954589844, 0.0, 0.46437835693359375, 0.2767791748046875, 41.21818542480469, -0.1230316162109375, 0.0, 62.332061767578125, 26.128246307373047, 56.28288459777832, 0.0, 0.0, 0.0, 63.01264953613281, 0.0, 0.1232147216796875, 0.0, 57.477272033691406, 0.0, -0.029571533203125, 0.5637588500976562, 56.793182373046875, 0.0, 5.8123016357421875, 0.0, 0.0, 0.0, 34.97760009765625, 9.709259033203125, 50.28558349609375, 0.15246963500976562, 69.64163970947266, 0.0, 19.896177291870117, 56.19946479797363, 0.0, 0.0, 0.0, 0.0190887451171875, 0.0, 0.0, 58.829254150390625, 0.0, 32.63865661621094, -0.09515380859375, 0.0, 0.0, 0.0584259033203125, 0.0, -0.085845947265625, 0.0, 37.06475067138672, 0.0, 0.19055557250976562, 41.57420349121094, -0.1206512451171875, -0.6708221435546875, 0.0, 0.0, 0.061206817626953125, 21.2520751953125, -0.0923004150390625, 0.0, 0.0, 0.0, -0.00818634033203125, 0.0, 57.58721160888672, -0.1831512451171875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 286, 500, 500, 500, 500, 500, 500, 500, 379, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.566137658898255, "mean_inference_ms": 4.9569653033479435, "mean_action_processing_ms": 7.585796125166216, "mean_env_wait_ms": 11.482777441995246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20440537, "num_agent_steps_trained": 20440537, "num_env_steps_sampled": 20440537, "num_env_steps_trained": 20440537, "num_env_steps_sampled_this_iter": 60788, "num_env_steps_trained_this_iter": 60788, "timesteps_total": 20440537, "num_steps_trained_this_iter": 60788, "agent_timesteps_total": 20440537, "timers": {"training_iteration_time_ms": 47486.195, "load_time_ms": 47.257, "load_throughput": 1285601.025, "learn_time_ms": 26549.921, "learn_throughput": 2288.297, "synch_weights_time_ms": 9.987}, "counters": {"num_env_steps_sampled": 20440537, "num_env_steps_trained": 20440537, "num_agent_steps_sampled": 20440537, "num_agent_steps_trained": 20440537}, "done": false, "episodes_total": 41390, "training_iteration": 337, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-35-27", "timestamp": 1735108527, "time_this_iter_s": 48.70064854621887, "time_total_s": 9636.786381959915, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A380>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3959E10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 779.6564831733704, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 19.583823529411767, "ram_util_percent": 95.78823529411763}}
{"custom_metrics": {"rewards/0_mean": 12.303343997738226, "rewards/0_min": -0.5508880615234375, "rewards/0_max": 74.59282684326172, "rewards/1_mean": 12.303343997738226, "rewards/1_min": -0.5508880615234375, "rewards/1_max": 74.59282684326172, "rewards/2_mean": 12.303343997738226, "rewards/2_min": -0.5508880615234375, "rewards/2_max": 74.59282684326172, "rewards/3_mean": 12.303343997738226, "rewards/3_min": -0.5508880615234375, "rewards/3_max": 74.59282684326172, "rewards/4_mean": 12.303343997738226, "rewards/4_min": -0.5508880615234375, "rewards/4_max": 74.59282684326172}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.04141488342900716, "policy_loss": -0.008410008503715434, "vf_loss": 0.16241890078499205, "vf_explained_var": 0.979384919480672, "kl": 0.010853652275049143, "entropy": 19.5973245938619, "entropy_coeff": 0.01, "grad_gnorm": 1.6117541729221267}, "model": {}, "num_grad_updates_lifetime": 10440.5, "diff_num_grad_updates_vs_sampler_policy": 10439.5}}, "num_env_steps_sampled": 20501354, "num_env_steps_trained": 20501354, "num_agent_steps_sampled": 20501354, "num_agent_steps_trained": 20501354}, "sampler_results": {"episode_reward_max": 74.59282684326172, "episode_reward_min": -0.5508880615234375, "episode_reward_mean": 12.303343997738226, "episode_len_mean": 494.4471544715447, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 12.303343997738226, "rewards/0_min": -0.5508880615234375, "rewards/0_max": 74.59282684326172, "rewards/1_mean": 12.303343997738226, "rewards/1_min": -0.5508880615234375, "rewards/1_max": 74.59282684326172, "rewards/2_mean": 12.303343997738226, "rewards/2_min": -0.5508880615234375, "rewards/2_max": 74.59282684326172, "rewards/3_mean": 12.303343997738226, "rewards/3_min": -0.5508880615234375, "rewards/3_max": 74.59282684326172, "rewards/4_mean": 12.303343997738226, "rewards/4_min": -0.5508880615234375, "rewards/4_max": 74.59282684326172}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 5.454414367675781, 0.0, 45.36255645751953, 2.6632843017578125, 0.3384056091308594, 17.995208740234375, 0.0, 0.42371368408203125, 28.86566162109375, 56.45525550842285, 53.83992385864258, -0.0597076416015625, 27.16046905517578, 0.0, 0.0, 74.59282684326172, 53.91433906555176, 0.0, 0.0, -0.2881011962890625, 11.091197967529297, 59.48826599121094, 0.0, 1.2034072875976562, -0.03035736083984375, 0.0, 0.0, 14.273490905761719, -0.1347198486328125, 45.230743408203125, 15.6492919921875, 0.0857696533203125, 19.948165893554688, -0.1901397705078125, 0.0, 10.958457946777344, -0.1154327392578125, 37.81927490234375, 0.0, 25.5452880859375, 0.6880111694335938, 16.31304359436035, 0.0, 0.0, 0.0, 34.7098331451416, -0.3851165771484375, 0.914764404296875, -0.05933380126953125, 0.0, 0.26816558837890625, -0.0516357421875, 0.0, -0.286590576171875, 0.0, 25.06695556640625, 0.25742340087890625, 0.0, 60.670379638671875, 0.0, 0.0, 0.0, 0.0, -0.5508880615234375, 65.72041702270508, 63.602638244628906, -0.006805419921875, 44.53944396972656, 0.0, 23.181865692138672, 24.621063232421875, 0.0, 0.0, 0.0, 33.19658660888672, 0.0, 15.441696166992188, 64.6492691040039, 10.289176940917969, 44.55714416503906, 0.0, 0.0, 0.0, 11.896224975585938, 1.1642646789550781, 5.024602890014648, 0.0, 0.0, 0.9089889526367188, 0.0, 10.529670715332031, 0.0, 0.209716796875, 5.9873199462890625, 0.0, 0.0, -0.1732635498046875, 0.0, 0.0, 0.0, 0.0, 0.0, 54.57058334350586, 24.697303771972656, 49.561279296875, 40.170738220214844, 0.0, 0.0, 0.0, 58.36180877685547, 0.0, 0.0, 30.174095153808594, 35.000511169433594, -0.03997802734375, 0.0, 0.0, 50.37898254394531, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500, 500, 500, 500, 500, 500, 433, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 225, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 271, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599264144902898, "mean_inference_ms": 4.953149366039553, "mean_action_processing_ms": 7.58119836465682, "mean_env_wait_ms": 11.49707277568236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.59282684326172, "episode_reward_min": -0.5508880615234375, "episode_reward_mean": 12.303343997738226, "episode_len_mean": 494.4471544715447, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 5.454414367675781, 0.0, 45.36255645751953, 2.6632843017578125, 0.3384056091308594, 17.995208740234375, 0.0, 0.42371368408203125, 28.86566162109375, 56.45525550842285, 53.83992385864258, -0.0597076416015625, 27.16046905517578, 0.0, 0.0, 74.59282684326172, 53.91433906555176, 0.0, 0.0, -0.2881011962890625, 11.091197967529297, 59.48826599121094, 0.0, 1.2034072875976562, -0.03035736083984375, 0.0, 0.0, 14.273490905761719, -0.1347198486328125, 45.230743408203125, 15.6492919921875, 0.0857696533203125, 19.948165893554688, -0.1901397705078125, 0.0, 10.958457946777344, -0.1154327392578125, 37.81927490234375, 0.0, 25.5452880859375, 0.6880111694335938, 16.31304359436035, 0.0, 0.0, 0.0, 34.7098331451416, -0.3851165771484375, 0.914764404296875, -0.05933380126953125, 0.0, 0.26816558837890625, -0.0516357421875, 0.0, -0.286590576171875, 0.0, 25.06695556640625, 0.25742340087890625, 0.0, 60.670379638671875, 0.0, 0.0, 0.0, 0.0, -0.5508880615234375, 65.72041702270508, 63.602638244628906, -0.006805419921875, 44.53944396972656, 0.0, 23.181865692138672, 24.621063232421875, 0.0, 0.0, 0.0, 33.19658660888672, 0.0, 15.441696166992188, 64.6492691040039, 10.289176940917969, 44.55714416503906, 0.0, 0.0, 0.0, 11.896224975585938, 1.1642646789550781, 5.024602890014648, 0.0, 0.0, 0.9089889526367188, 0.0, 10.529670715332031, 0.0, 0.209716796875, 5.9873199462890625, 0.0, 0.0, -0.1732635498046875, 0.0, 0.0, 0.0, 0.0, 0.0, 54.57058334350586, 24.697303771972656, 49.561279296875, 40.170738220214844, 0.0, 0.0, 0.0, 58.36180877685547, 0.0, 0.0, 30.174095153808594, 35.000511169433594, -0.03997802734375, 0.0, 0.0, 50.37898254394531, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500, 500, 500, 500, 500, 500, 433, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 225, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 271, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599264144902898, "mean_inference_ms": 4.953149366039553, "mean_action_processing_ms": 7.58119836465682, "mean_env_wait_ms": 11.49707277568236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20501354, "num_agent_steps_trained": 20501354, "num_env_steps_sampled": 20501354, "num_env_steps_trained": 20501354, "num_env_steps_sampled_this_iter": 60817, "num_env_steps_trained_this_iter": 60817, "timesteps_total": 20501354, "num_steps_trained_this_iter": 60817, "agent_timesteps_total": 20501354, "timers": {"training_iteration_time_ms": 47230.923, "load_time_ms": 47.945, "load_throughput": 1266791.233, "learn_time_ms": 26647.803, "learn_throughput": 2279.201, "synch_weights_time_ms": 9.993}, "counters": {"num_env_steps_sampled": 20501354, "num_env_steps_trained": 20501354, "num_agent_steps_sampled": 20501354, "num_agent_steps_trained": 20501354}, "done": false, "episodes_total": 41513, "training_iteration": 338, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-36-15", "timestamp": 1735108575, "time_this_iter_s": 47.77067971229553, "time_total_s": 9684.55706167221, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B52F50>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C70940>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 827.4271628856659, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.31940298507463, "ram_util_percent": 96.2179104477612}}
{"custom_metrics": {"rewards/0_mean": 10.908135898529537, "rewards/0_min": -1.0734024047851562, "rewards/0_max": 77.04888725280762, "rewards/1_mean": 10.908135898529537, "rewards/1_min": -1.0734024047851562, "rewards/1_max": 77.04888725280762, "rewards/2_mean": 10.908135898529537, "rewards/2_min": -1.0734024047851562, "rewards/2_max": 77.04888725280762, "rewards/3_mean": 10.908135898529537, "rewards/3_min": -1.0734024047851562, "rewards/3_max": 77.04888725280762, "rewards/4_mean": 10.908135898529537, "rewards/4_min": -1.0734024047851562, "rewards/4_max": 77.04888725280762}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.07355554191397796, "policy_loss": -0.000731884489099078, "vf_loss": 0.13887345167911716, "vf_explained_var": 0.987665707623517, "kl": 0.012271940314935312, "entropy": 21.23183789005986, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.4221403410258115}, "model": {}, "num_grad_updates_lifetime": 11093.0, "diff_num_grad_updates_vs_sampler_policy": 11092.0}}, "num_env_steps_sampled": 20562931, "num_env_steps_trained": 20562931, "num_agent_steps_sampled": 20562931, "num_agent_steps_trained": 20562931}, "sampler_results": {"episode_reward_max": 77.04888725280762, "episode_reward_min": -1.0734024047851562, "episode_reward_mean": 10.908135898529537, "episode_len_mean": 488.7063492063492, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.908135898529537, "rewards/0_min": -1.0734024047851562, "rewards/0_max": 77.04888725280762, "rewards/1_mean": 10.908135898529537, "rewards/1_min": -1.0734024047851562, "rewards/1_max": 77.04888725280762, "rewards/2_mean": 10.908135898529537, "rewards/2_min": -1.0734024047851562, "rewards/2_max": 77.04888725280762, "rewards/3_mean": 10.908135898529537, "rewards/3_min": -1.0734024047851562, "rewards/3_max": 77.04888725280762, "rewards/4_mean": 10.908135898529537, "rewards/4_min": -1.0734024047851562, "rewards/4_max": 77.04888725280762}, "hist_stats": {"episode_reward": [14.220001220703125, 35.2552490234375, 0.0, 0.0, 0.0, 0.0, 50.4823112487793, 0.14228057861328125, 65.02029418945312, -0.37384033203125, 57.974281311035156, 0.0, 2.249908447265625, 0.0, 77.04888725280762, 10.168815612792969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0862579345703125, 26.984371185302734, 11.31911849975586, 0.0, 0.03247833251953125, 49.288330078125, 0.137542724609375, 0.0, 0.30976104736328125, 0.0, 0.0, 43.89513397216797, 13.622604370117188, 68.75180053710938, 44.37760925292969, 0.04868316650390625, 0.1760406494140625, 29.210006713867188, 0.0, -1.0734024047851562, 53.35567855834961, 0.062530517578125, -0.157989501953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.659477233886719, 0.0, -0.0582275390625, -0.1973114013671875, 56.05213928222656, 0.02069091796875, 73.00089263916016, 0.0, 39.265132904052734, 0.0, 60.701881408691406, 0.0, 0.0, 0.0, 0.0, 10.450813293457031, 29.143512725830078, 40.12506103515625, 0.0, 0.0, 0.048919677734375, 0.12334060668945312, 38.409202575683594, 0.0, 49.08588409423828, 0.0, 0.0, 0.1818389892578125, 69.49536514282227, 0.0, 0.0, -0.980255126953125, 0.0, -0.563873291015625, 0.0, 0.0, 0.02289581298828125, 51.322837829589844, 46.929481506347656, 0.0, 0.0, 0.0, 5.878456115722656, -0.2827911376953125, 48.65046691894531, 13.257575988769531, 10.385501861572266, 0.0, -0.0473785400390625, 0.0, 0.0, 0.0, 0.0, 0.0, 16.453903198242188, 12.41387939453125, 0.0, 18.39105224609375, 0.0247344970703125, 0.0, 4.4034423828125, 0.0, 9.77227783203125, 0.0, 0.0, 0.0, 0.0, 0.0, 2.747722625732422, -0.21197509765625, 3.9063262939453125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 463, 500, 500, 500, 457, 181, 500, 500, 500, 500, 500, 500, 500, 500, 314, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 265, 500, 500, 500, 500, 500, 500, 258, 276, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 487, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.598716561678058, "mean_inference_ms": 4.956674177399953, "mean_action_processing_ms": 7.578468012237255, "mean_env_wait_ms": 11.471950826681146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 77.04888725280762, "episode_reward_min": -1.0734024047851562, "episode_reward_mean": 10.908135898529537, "episode_len_mean": 488.7063492063492, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [14.220001220703125, 35.2552490234375, 0.0, 0.0, 0.0, 0.0, 50.4823112487793, 0.14228057861328125, 65.02029418945312, -0.37384033203125, 57.974281311035156, 0.0, 2.249908447265625, 0.0, 77.04888725280762, 10.168815612792969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0862579345703125, 26.984371185302734, 11.31911849975586, 0.0, 0.03247833251953125, 49.288330078125, 0.137542724609375, 0.0, 0.30976104736328125, 0.0, 0.0, 43.89513397216797, 13.622604370117188, 68.75180053710938, 44.37760925292969, 0.04868316650390625, 0.1760406494140625, 29.210006713867188, 0.0, -1.0734024047851562, 53.35567855834961, 0.062530517578125, -0.157989501953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.659477233886719, 0.0, -0.0582275390625, -0.1973114013671875, 56.05213928222656, 0.02069091796875, 73.00089263916016, 0.0, 39.265132904052734, 0.0, 60.701881408691406, 0.0, 0.0, 0.0, 0.0, 10.450813293457031, 29.143512725830078, 40.12506103515625, 0.0, 0.0, 0.048919677734375, 0.12334060668945312, 38.409202575683594, 0.0, 49.08588409423828, 0.0, 0.0, 0.1818389892578125, 69.49536514282227, 0.0, 0.0, -0.980255126953125, 0.0, -0.563873291015625, 0.0, 0.0, 0.02289581298828125, 51.322837829589844, 46.929481506347656, 0.0, 0.0, 0.0, 5.878456115722656, -0.2827911376953125, 48.65046691894531, 13.257575988769531, 10.385501861572266, 0.0, -0.0473785400390625, 0.0, 0.0, 0.0, 0.0, 0.0, 16.453903198242188, 12.41387939453125, 0.0, 18.39105224609375, 0.0247344970703125, 0.0, 4.4034423828125, 0.0, 9.77227783203125, 0.0, 0.0, 0.0, 0.0, 0.0, 2.747722625732422, -0.21197509765625, 3.9063262939453125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 463, 500, 500, 500, 457, 181, 500, 500, 500, 500, 500, 500, 500, 500, 314, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 265, 500, 500, 500, 500, 500, 500, 258, 276, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 487, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.598716561678058, "mean_inference_ms": 4.956674177399953, "mean_action_processing_ms": 7.578468012237255, "mean_env_wait_ms": 11.471950826681146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20562931, "num_agent_steps_trained": 20562931, "num_env_steps_sampled": 20562931, "num_env_steps_trained": 20562931, "num_env_steps_sampled_this_iter": 61577, "num_env_steps_trained_this_iter": 61577, "timesteps_total": 20562931, "num_steps_trained_this_iter": 61577, "agent_timesteps_total": 20562931, "timers": {"training_iteration_time_ms": 47415.616, "load_time_ms": 46.903, "load_throughput": 1295952.108, "learn_time_ms": 26784.291, "learn_throughput": 2269.405, "synch_weights_time_ms": 10.0}, "counters": {"num_env_steps_sampled": 20562931, "num_env_steps_trained": 20562931, "num_agent_steps_sampled": 20562931, "num_agent_steps_trained": 20562931}, "done": false, "episodes_total": 41639, "training_iteration": 339, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-37-02", "timestamp": 1735108622, "time_this_iter_s": 47.531479358673096, "time_total_s": 9732.088541030884, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEBBB0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C709D0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 874.958642244339, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.238805970149258, "ram_util_percent": 96.05522388059703}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6690783121775294, "mean_inference_ms": 3.3855713468262816, "mean_action_processing_ms": 0.47251881509349086, "mean_env_wait_ms": 5.642058431119218, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 9.679229197963592, "rewards/0_min": -0.7416534423828125, "rewards/0_max": 64.89169311523438, "rewards/1_mean": 9.679229197963592, "rewards/1_min": -0.7416534423828125, "rewards/1_max": 64.89169311523438, "rewards/2_mean": 9.679229197963592, "rewards/2_min": -0.7416534423828125, "rewards/2_max": 64.89169311523438, "rewards/3_mean": 9.679229197963592, "rewards/3_min": -0.7416534423828125, "rewards/3_max": 64.89169311523438, "rewards/4_mean": 9.679229197963592, "rewards/4_min": -0.7416534423828125, "rewards/4_max": 64.89169311523438}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.14662708003928104, "policy_loss": -0.008387203263913444, "vf_loss": 0.08837041862416155, "vf_explained_var": 0.9796023357482183, "kl": 0.01577864077038294, "entropy": 22.740909358433314, "entropy_coeff": 0.01, "grad_gnorm": 2.2449252394101924}, "model": {}, "num_grad_updates_lifetime": 11745.5, "diff_num_grad_updates_vs_sampler_policy": 11744.5}}, "num_env_steps_sampled": 20624010, "num_env_steps_trained": 20624010, "num_agent_steps_sampled": 20624010, "num_agent_steps_trained": 20624010}, "sampler_results": {"episode_reward_max": 64.89169311523438, "episode_reward_min": -0.7416534423828125, "episode_reward_mean": 9.679229197963592, "episode_len_mean": 492.5725806451613, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.679229197963592, "rewards/0_min": -0.7416534423828125, "rewards/0_max": 64.89169311523438, "rewards/1_mean": 9.679229197963592, "rewards/1_min": -0.7416534423828125, "rewards/1_max": 64.89169311523438, "rewards/2_mean": 9.679229197963592, "rewards/2_min": -0.7416534423828125, "rewards/2_max": 64.89169311523438, "rewards/3_mean": 9.679229197963592, "rewards/3_min": -0.7416534423828125, "rewards/3_max": 64.89169311523438, "rewards/4_mean": 9.679229197963592, "rewards/4_min": -0.7416534423828125, "rewards/4_max": 64.89169311523438}, "hist_stats": {"episode_reward": [30.852645874023438, 0.0, 32.34857940673828, 27.920185089111328, 0.0, 0.0, 53.27406692504883, 0.0, 0.0, -0.2999267578125, -0.0906219482421875, 25.08727264404297, 0.0, 0.0, 64.89169311523438, 45.822471618652344, 0.0, 0.0, 16.8382511138916, 30.36831283569336, 0.0, -0.018077850341796875, 19.964736938476562, 0.0, 0.0, 0.0, -0.00310516357421875, -0.4538536071777344, 0.0, 0.0, 0.13060760498046875, 6.7174224853515625, 0.0, 0.07300567626953125, 0.0, 0.0, 0.0, -0.2701377868652344, 0.19130706787109375, 0.0, 0.0, 0.0, 47.969295501708984, 39.251319885253906, -0.036529541015625, 27.35356903076172, -0.0854034423828125, -0.4350738525390625, -0.0055694580078125, 0.0, 37.979888916015625, 0.37677001953125, 3.2789459228515625, 0.0, 0.0, 0.12122344970703125, 0.2237396240234375, 0.0, 12.720855712890625, 0.07778549194335938, 0.0, 14.803932189941406, 0.0, -0.3908843994140625, 0.086029052734375, 0.10010528564453125, -0.6656341552734375, 0.0, -0.033206939697265625, 3.9314498901367188, 0.0, 0.5453262329101562, 62.99942207336426, 0.0, 32.469268798828125, 0.0, 61.35333442687988, 43.27345657348633, -0.7416534423828125, 0.0, 0.0, 0.0, 34.40003204345703, 0.0, 41.19028854370117, 3.9040603637695312, 0.0, 0.0, 0.2016143798828125, 0.0, 0.0, 30.58894920349121, 34.71563720703125, 0.0, 0.0, 0.0, 0.0, 59.83628845214844, 0.0, 52.63786315917969, 14.501754760742188, 0.0, 0.478515625, 0.17169189453125, 20.88500213623047, 2.480499267578125, 0.0, 0.0, -0.4780731201171875, 0.10076904296875, 0.0, 0.10680389404296875, 0.0, 0.0, 0.0, 22.46123695373535, 5.36712646484375, 38.81769561767578, 0.0, 0.0, 52.016143798828125, 0.0, 45.97392272949219, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 416, 500, 500, 500, 500, 500, 500, 500, 500, 500, 247, 500, 500, 500, 500, 500, 500, 500, 500, 474, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 163, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.596682688660932, "mean_inference_ms": 4.9587557886001425, "mean_action_processing_ms": 7.555476708667305, "mean_env_wait_ms": 11.465148053948507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 64.89169311523438, "episode_reward_min": -0.7416534423828125, "episode_reward_mean": 9.679229197963592, "episode_len_mean": 492.5725806451613, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [30.852645874023438, 0.0, 32.34857940673828, 27.920185089111328, 0.0, 0.0, 53.27406692504883, 0.0, 0.0, -0.2999267578125, -0.0906219482421875, 25.08727264404297, 0.0, 0.0, 64.89169311523438, 45.822471618652344, 0.0, 0.0, 16.8382511138916, 30.36831283569336, 0.0, -0.018077850341796875, 19.964736938476562, 0.0, 0.0, 0.0, -0.00310516357421875, -0.4538536071777344, 0.0, 0.0, 0.13060760498046875, 6.7174224853515625, 0.0, 0.07300567626953125, 0.0, 0.0, 0.0, -0.2701377868652344, 0.19130706787109375, 0.0, 0.0, 0.0, 47.969295501708984, 39.251319885253906, -0.036529541015625, 27.35356903076172, -0.0854034423828125, -0.4350738525390625, -0.0055694580078125, 0.0, 37.979888916015625, 0.37677001953125, 3.2789459228515625, 0.0, 0.0, 0.12122344970703125, 0.2237396240234375, 0.0, 12.720855712890625, 0.07778549194335938, 0.0, 14.803932189941406, 0.0, -0.3908843994140625, 0.086029052734375, 0.10010528564453125, -0.6656341552734375, 0.0, -0.033206939697265625, 3.9314498901367188, 0.0, 0.5453262329101562, 62.99942207336426, 0.0, 32.469268798828125, 0.0, 61.35333442687988, 43.27345657348633, -0.7416534423828125, 0.0, 0.0, 0.0, 34.40003204345703, 0.0, 41.19028854370117, 3.9040603637695312, 0.0, 0.0, 0.2016143798828125, 0.0, 0.0, 30.58894920349121, 34.71563720703125, 0.0, 0.0, 0.0, 0.0, 59.83628845214844, 0.0, 52.63786315917969, 14.501754760742188, 0.0, 0.478515625, 0.17169189453125, 20.88500213623047, 2.480499267578125, 0.0, 0.0, -0.4780731201171875, 0.10076904296875, 0.0, 0.10680389404296875, 0.0, 0.0, 0.0, 22.46123695373535, 5.36712646484375, 38.81769561767578, 0.0, 0.0, 52.016143798828125, 0.0, 45.97392272949219, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 416, 500, 500, 500, 500, 500, 500, 500, 500, 500, 247, 500, 500, 500, 500, 500, 500, 500, 500, 474, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 163, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.596682688660932, "mean_inference_ms": 4.9587557886001425, "mean_action_processing_ms": 7.555476708667305, "mean_env_wait_ms": 11.465148053948507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20624010, "num_agent_steps_trained": 20624010, "num_env_steps_sampled": 20624010, "num_env_steps_trained": 20624010, "num_env_steps_sampled_this_iter": 61079, "num_env_steps_trained_this_iter": 61079, "timesteps_total": 20624010, "num_steps_trained_this_iter": 61079, "agent_timesteps_total": 20624010, "timers": {"training_iteration_time_ms": 47305.53, "load_time_ms": 47.129, "load_throughput": 1291132.863, "learn_time_ms": 26722.24, "learn_throughput": 2277.144, "synch_weights_time_ms": 9.995}, "counters": {"num_env_steps_sampled": 20624010, "num_env_steps_trained": 20624010, "num_agent_steps_sampled": 20624010, "num_agent_steps_trained": 20624010}, "done": false, "episodes_total": 41763, "training_iteration": 340, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-37-49", "timestamp": 1735108669, "time_this_iter_s": 46.49502372741699, "time_total_s": 9778.5835647583, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A5B370>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3A67370>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 921.453665971756, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.07272727272727, "ram_util_percent": 95.92121212121212}}
{"custom_metrics": {"rewards/0_mean": 9.204537725060936, "rewards/0_min": -1.4954509735107422, "rewards/0_max": 86.92296981811523, "rewards/1_mean": 9.204537725060936, "rewards/1_min": -1.4954509735107422, "rewards/1_max": 86.92296981811523, "rewards/2_mean": 9.204537725060936, "rewards/2_min": -1.4954509735107422, "rewards/2_max": 86.92296981811523, "rewards/3_mean": 9.204537725060936, "rewards/3_min": -1.4954509735107422, "rewards/3_max": 86.92296981811523, "rewards/4_mean": 9.204537725060936, "rewards/4_min": -1.4954509735107422, "rewards/4_max": 86.92296981811523}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11038227903375787, "policy_loss": -0.0006470248384016847, "vf_loss": 0.10953862672405583, "vf_explained_var": 0.9884751823213366, "kl": 0.012389056745266157, "entropy": 21.990108173612565, "entropy_coeff": 0.01, "grad_gnorm": 1.385854377916881}, "model": {}, "num_grad_updates_lifetime": 12375.5, "diff_num_grad_updates_vs_sampler_policy": 12374.5}}, "num_env_steps_sampled": 20684859, "num_env_steps_trained": 20684859, "num_agent_steps_sampled": 20684859, "num_agent_steps_trained": 20684859}, "sampler_results": {"episode_reward_max": 86.92296981811523, "episode_reward_min": -1.4954509735107422, "episode_reward_mean": 9.204537725060936, "episode_len_mean": 494.7073170731707, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.204537725060936, "rewards/0_min": -1.4954509735107422, "rewards/0_max": 86.92296981811523, "rewards/1_mean": 9.204537725060936, "rewards/1_min": -1.4954509735107422, "rewards/1_max": 86.92296981811523, "rewards/2_mean": 9.204537725060936, "rewards/2_min": -1.4954509735107422, "rewards/2_max": 86.92296981811523, "rewards/3_mean": 9.204537725060936, "rewards/3_min": -1.4954509735107422, "rewards/3_max": 86.92296981811523, "rewards/4_mean": 9.204537725060936, "rewards/4_min": -1.4954509735107422, "rewards/4_max": 86.92296981811523}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 21.27790069580078, -0.22501754760742188, 0.0, 41.688751220703125, 38.8310604095459, 0.0, 0.0, 0.0, 6.273078918457031, 0.0, 0.0, 0.0, 11.719284057617188, 37.68427848815918, 1.5014495849609375, 0.0, 42.633018493652344, 0.0, 0.0, 0.0, 12.589836120605469, 34.78569030761719, 0.188720703125, 0.077880859375, 0.0, 29.368000030517578, 0.099517822265625, 10.99685287475586, 65.67442321777344, 6.076587677001953, 0.18680191040039062, 0.0, 0.0, 26.972640991210938, 0.01873016357421875, 50.66497039794922, 7.8807525634765625, 0.0, 22.887649536132812, 0.08040237426757812, -0.1031341552734375, 0.0, 0.0, 45.153472900390625, 0.0, 0.266143798828125, 77.92487335205078, 0.0, 28.931686401367188, -1.4954509735107422, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1877288818359375, 0.5836715698242188, 0.0, 0.0, 86.92296981811523, 0.52496337890625, 44.47552490234375, 0.15019989013671875, 0.0, 0.0, -0.134521484375, 57.9893913269043, 0.0, 0.348236083984375, 12.29046630859375, 24.608917236328125, 0.0, -0.4538116455078125, 0.0, 44.747802734375, 0.0, 0.01697540283203125, 0.0, 0.0, 27.47399139404297, 0.0, 0.0, 0.0, 11.627532958984375, 0.0, -0.66180419921875, 11.906402587890625, 0.0, 3.0261459350585938, 0.0, 0.0, 1.4522857666015625, -0.1681060791015625, 50.434574127197266, 0.0, -0.5685386657714844, 4.180549621582031, 17.184677124023438, -0.093719482421875, 0.0, -0.029510498046875, 3.6519393920898438, 0.0, -0.673126220703125, 0.0, 67.44512176513672, 0.0, 2.4126815795898438, 0.0, -0.5129241943359375, 39.84856414794922, 0.066650390625, -0.251312255859375, -0.058624267578125, 2.01617431640625, 0.0, 0.0, -0.0453948974609375], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 303, 500, 500, 500, 500, 500, 500, 500, 500, 421, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 337, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 288, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.612248091934413, "mean_inference_ms": 4.951389874750726, "mean_action_processing_ms": 7.5526529678437235, "mean_env_wait_ms": 11.456946757819562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 86.92296981811523, "episode_reward_min": -1.4954509735107422, "episode_reward_mean": 9.204537725060936, "episode_len_mean": 494.7073170731707, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 21.27790069580078, -0.22501754760742188, 0.0, 41.688751220703125, 38.8310604095459, 0.0, 0.0, 0.0, 6.273078918457031, 0.0, 0.0, 0.0, 11.719284057617188, 37.68427848815918, 1.5014495849609375, 0.0, 42.633018493652344, 0.0, 0.0, 0.0, 12.589836120605469, 34.78569030761719, 0.188720703125, 0.077880859375, 0.0, 29.368000030517578, 0.099517822265625, 10.99685287475586, 65.67442321777344, 6.076587677001953, 0.18680191040039062, 0.0, 0.0, 26.972640991210938, 0.01873016357421875, 50.66497039794922, 7.8807525634765625, 0.0, 22.887649536132812, 0.08040237426757812, -0.1031341552734375, 0.0, 0.0, 45.153472900390625, 0.0, 0.266143798828125, 77.92487335205078, 0.0, 28.931686401367188, -1.4954509735107422, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1877288818359375, 0.5836715698242188, 0.0, 0.0, 86.92296981811523, 0.52496337890625, 44.47552490234375, 0.15019989013671875, 0.0, 0.0, -0.134521484375, 57.9893913269043, 0.0, 0.348236083984375, 12.29046630859375, 24.608917236328125, 0.0, -0.4538116455078125, 0.0, 44.747802734375, 0.0, 0.01697540283203125, 0.0, 0.0, 27.47399139404297, 0.0, 0.0, 0.0, 11.627532958984375, 0.0, -0.66180419921875, 11.906402587890625, 0.0, 3.0261459350585938, 0.0, 0.0, 1.4522857666015625, -0.1681060791015625, 50.434574127197266, 0.0, -0.5685386657714844, 4.180549621582031, 17.184677124023438, -0.093719482421875, 0.0, -0.029510498046875, 3.6519393920898438, 0.0, -0.673126220703125, 0.0, 67.44512176513672, 0.0, 2.4126815795898438, 0.0, -0.5129241943359375, 39.84856414794922, 0.066650390625, -0.251312255859375, -0.058624267578125, 2.01617431640625, 0.0, 0.0, -0.0453948974609375], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 303, 500, 500, 500, 500, 500, 500, 500, 500, 421, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 337, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 288, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.612248091934413, "mean_inference_ms": 4.951389874750726, "mean_action_processing_ms": 7.5526529678437235, "mean_env_wait_ms": 11.456946757819562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20684859, "num_agent_steps_trained": 20684859, "num_env_steps_sampled": 20684859, "num_env_steps_trained": 20684859, "num_env_steps_sampled_this_iter": 60849, "num_env_steps_trained_this_iter": 60849, "timesteps_total": 20684859, "num_steps_trained_this_iter": 60849, "agent_timesteps_total": 20684859, "timers": {"training_iteration_time_ms": 46959.298, "load_time_ms": 47.931, "load_throughput": 1269444.223, "learn_time_ms": 26658.229, "learn_throughput": 2282.413, "synch_weights_time_ms": 9.995}, "counters": {"num_env_steps_sampled": 20684859, "num_env_steps_trained": 20684859, "num_agent_steps_sampled": 20684859, "num_agent_steps_trained": 20684859}, "done": false, "episodes_total": 41886, "training_iteration": 341, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-38-36", "timestamp": 1735108716, "time_this_iter_s": 46.380366563797, "time_total_s": 9824.963931322098, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEB340>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3959E10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 967.834032535553, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.99076923076923, "ram_util_percent": 95.85692307692307}}
{"custom_metrics": {"rewards/0_mean": 10.183751706154116, "rewards/0_min": -0.5662841796875, "rewards/0_max": 75.48485565185547, "rewards/1_mean": 10.183751706154116, "rewards/1_min": -0.5662841796875, "rewards/1_max": 75.48485565185547, "rewards/2_mean": 10.183751706154116, "rewards/2_min": -0.5662841796875, "rewards/2_max": 75.48485565185547, "rewards/3_mean": 10.183751706154116, "rewards/3_min": -0.5662841796875, "rewards/3_max": 75.48485565185547, "rewards/4_mean": 10.183751706154116, "rewards/4_min": -0.5662841796875, "rewards/4_max": 75.48485565185547}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10249888347166161, "policy_loss": -0.0016870490530350036, "vf_loss": 0.10628206828343016, "vf_explained_var": 0.9890273144320836, "kl": 0.014782048873085943, "entropy": 20.784224832625615, "entropy_coeff": 0.01, "grad_gnorm": 1.7937049138167547}, "model": {}, "num_grad_updates_lifetime": 13005.5, "diff_num_grad_updates_vs_sampler_policy": 13004.5}}, "num_env_steps_sampled": 20745635, "num_env_steps_trained": 20745635, "num_agent_steps_sampled": 20745635, "num_agent_steps_trained": 20745635}, "sampler_results": {"episode_reward_max": 75.48485565185547, "episode_reward_min": -0.5662841796875, "episode_reward_mean": 10.183751706154116, "episode_len_mean": 490.1290322580645, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.183751706154116, "rewards/0_min": -0.5662841796875, "rewards/0_max": 75.48485565185547, "rewards/1_mean": 10.183751706154116, "rewards/1_min": -0.5662841796875, "rewards/1_max": 75.48485565185547, "rewards/2_mean": 10.183751706154116, "rewards/2_min": -0.5662841796875, "rewards/2_max": 75.48485565185547, "rewards/3_mean": 10.183751706154116, "rewards/3_min": -0.5662841796875, "rewards/3_max": 75.48485565185547, "rewards/4_mean": 10.183751706154116, "rewards/4_min": -0.5662841796875, "rewards/4_max": 75.48485565185547}, "hist_stats": {"episode_reward": [0.0, 46.84623336791992, 2.2783775329589844, 0.0, 0.0, 0.0, 0.0, 0.0, 10.101341247558594, 30.713638305664062, 0.30966949462890625, 0.010335922241210938, 0.0, 0.3304443359375, 0.0372161865234375, 0.0, 0.217041015625, 42.56022644042969, 0.0, 0.0, 34.03208923339844, 8.917840957641602, 34.54654121398926, 75.48485565185547, 49.11517333984375, 0.30060577392578125, 48.285728454589844, 61.31196594238281, 0.0, -0.35324859619140625, 0.0, 20.79767608642578, 0.0, 0.0, 0.0, 22.71396827697754, -0.091339111328125, 0.0, 0.0, 0.0, 5.901906967163086, 0.0, 58.81580352783203, 0.0, 23.02463722229004, 0.3966827392578125, 0.354095458984375, 4.6850128173828125, 0.0, 50.82645034790039, 5.2854156494140625, -0.0294189453125, 19.4486083984375, -0.4730072021484375, 0.0, 0.0, 0.0, 2.284809112548828, 13.142745971679688, 0.698028564453125, 8.294425964355469, 0.0, 4.5336151123046875, 0.03618621826171875, 0.021564483642578125, 28.852401733398438, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8144702911376953, -0.07427978515625, 65.39319610595703, 0.0, 0.0, -0.0972442626953125, 0.0254058837890625, 0.0, 0.0, -0.07623291015625, 0.0, 39.21965026855469, 28.227401733398438, 0.0, -0.0199737548828125, 41.75543212890625, 0.17164230346679688, -0.112152099609375, 0.0, -0.4630126953125, -0.01546478271484375, 30.1934814453125, -0.1563873291015625, 51.87025833129883, -0.017059326171875, 7.660377502441406, 3.7435302734375, 55.93280029296875, -0.03485107421875, 1.30859375, -0.0104522705078125, 0.0, 0.0, 47.58271026611328, 34.08349609375, 4.425758361816406, 0.0, 34.928367614746094, 0.0, 0.21144866943359375, 38.184608459472656, 0.008514404296875, 0.0, 0.0, 0.0, 8.814956665039062, 2.0510101318359375, 9.648609161376953, -0.5662841796875, 0.24556350708007812, 0.0, 0.18399810791015625, 41.176979064941406], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 171, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 110, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 108, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.603513536398832, "mean_inference_ms": 4.948984872889346, "mean_action_processing_ms": 7.5340001725608765, "mean_env_wait_ms": 11.445552831244548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 75.48485565185547, "episode_reward_min": -0.5662841796875, "episode_reward_mean": 10.183751706154116, "episode_len_mean": 490.1290322580645, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 46.84623336791992, 2.2783775329589844, 0.0, 0.0, 0.0, 0.0, 0.0, 10.101341247558594, 30.713638305664062, 0.30966949462890625, 0.010335922241210938, 0.0, 0.3304443359375, 0.0372161865234375, 0.0, 0.217041015625, 42.56022644042969, 0.0, 0.0, 34.03208923339844, 8.917840957641602, 34.54654121398926, 75.48485565185547, 49.11517333984375, 0.30060577392578125, 48.285728454589844, 61.31196594238281, 0.0, -0.35324859619140625, 0.0, 20.79767608642578, 0.0, 0.0, 0.0, 22.71396827697754, -0.091339111328125, 0.0, 0.0, 0.0, 5.901906967163086, 0.0, 58.81580352783203, 0.0, 23.02463722229004, 0.3966827392578125, 0.354095458984375, 4.6850128173828125, 0.0, 50.82645034790039, 5.2854156494140625, -0.0294189453125, 19.4486083984375, -0.4730072021484375, 0.0, 0.0, 0.0, 2.284809112548828, 13.142745971679688, 0.698028564453125, 8.294425964355469, 0.0, 4.5336151123046875, 0.03618621826171875, 0.021564483642578125, 28.852401733398438, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8144702911376953, -0.07427978515625, 65.39319610595703, 0.0, 0.0, -0.0972442626953125, 0.0254058837890625, 0.0, 0.0, -0.07623291015625, 0.0, 39.21965026855469, 28.227401733398438, 0.0, -0.0199737548828125, 41.75543212890625, 0.17164230346679688, -0.112152099609375, 0.0, -0.4630126953125, -0.01546478271484375, 30.1934814453125, -0.1563873291015625, 51.87025833129883, -0.017059326171875, 7.660377502441406, 3.7435302734375, 55.93280029296875, -0.03485107421875, 1.30859375, -0.0104522705078125, 0.0, 0.0, 47.58271026611328, 34.08349609375, 4.425758361816406, 0.0, 34.928367614746094, 0.0, 0.21144866943359375, 38.184608459472656, 0.008514404296875, 0.0, 0.0, 0.0, 8.814956665039062, 2.0510101318359375, 9.648609161376953, -0.5662841796875, 0.24556350708007812, 0.0, 0.18399810791015625, 41.176979064941406], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 171, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 110, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 108, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.603513536398832, "mean_inference_ms": 4.948984872889346, "mean_action_processing_ms": 7.5340001725608765, "mean_env_wait_ms": 11.445552831244548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20745635, "num_agent_steps_trained": 20745635, "num_env_steps_sampled": 20745635, "num_env_steps_trained": 20745635, "num_env_steps_sampled_this_iter": 60776, "num_env_steps_trained_this_iter": 60776, "timesteps_total": 20745635, "num_steps_trained_this_iter": 60776, "agent_timesteps_total": 20745635, "timers": {"training_iteration_time_ms": 46976.005, "load_time_ms": 47.93, "load_throughput": 1269778.268, "learn_time_ms": 26730.117, "learn_throughput": 2276.829, "synch_weights_time_ms": 8.995}, "counters": {"num_env_steps_sampled": 20745635, "num_env_steps_trained": 20745635, "num_agent_steps_sampled": 20745635, "num_agent_steps_trained": 20745635}, "done": false, "episodes_total": 42010, "training_iteration": 342, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-39-22", "timestamp": 1735108762, "time_this_iter_s": 46.40285801887512, "time_total_s": 9871.366789340973, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A590>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3A67370>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1014.2368905544281, "timesteps_since_restore": 0, "iterations_since_restore": 21, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.51384615384615, "ram_util_percent": 95.83076923076923}}
{"custom_metrics": {"rewards/0_mean": 10.67003401448904, "rewards/0_min": -0.9361419677734375, "rewards/0_max": 78.02378463745117, "rewards/1_mean": 10.67003401448904, "rewards/1_min": -0.9361419677734375, "rewards/1_max": 78.02378463745117, "rewards/2_mean": 10.67003401448904, "rewards/2_min": -0.9361419677734375, "rewards/2_max": 78.02378463745117, "rewards/3_mean": 10.67003401448904, "rewards/3_min": -0.9361419677734375, "rewards/3_max": 78.02378463745117, "rewards/4_mean": 10.67003401448904, "rewards/4_min": -0.9361419677734375, "rewards/4_max": 78.02378463745117}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.06568637358127273, "policy_loss": -0.0005722995736591873, "vf_loss": 0.1411680485362128, "vf_explained_var": 0.98016950052882, "kl": 0.01206111483763726, "entropy": 20.68927198137556, "entropy_coeff": 0.01, "grad_gnorm": 1.2394603942121778}, "model": {}, "num_grad_updates_lifetime": 13635.5, "diff_num_grad_updates_vs_sampler_policy": 13634.5}}, "num_env_steps_sampled": 20806013, "num_env_steps_trained": 20806013, "num_agent_steps_sampled": 20806013, "num_agent_steps_trained": 20806013}, "sampler_results": {"episode_reward_max": 78.02378463745117, "episode_reward_min": -0.9361419677734375, "episode_reward_mean": 10.67003401448904, "episode_len_mean": 498.9917355371901, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.67003401448904, "rewards/0_min": -0.9361419677734375, "rewards/0_max": 78.02378463745117, "rewards/1_mean": 10.67003401448904, "rewards/1_min": -0.9361419677734375, "rewards/1_max": 78.02378463745117, "rewards/2_mean": 10.67003401448904, "rewards/2_min": -0.9361419677734375, "rewards/2_max": 78.02378463745117, "rewards/3_mean": 10.67003401448904, "rewards/3_min": -0.9361419677734375, "rewards/3_max": 78.02378463745117, "rewards/4_mean": 10.67003401448904, "rewards/4_min": -0.9361419677734375, "rewards/4_max": 78.02378463745117}, "hist_stats": {"episode_reward": [0.8734817504882812, 0.0, 44.964569091796875, 52.03310775756836, 50.43682861328125, 0.0, 8.956466674804688, -0.35882568359375, 0.11725616455078125, 0.2657318115234375, 0.0, 0.0, 0.0, -0.2723541259765625, -0.7036895751953125, 0.0, 0.0, 19.357757568359375, 0.3871955871582031, -0.4337310791015625, 0.0, 0.24517822265625, 0.0, 0.0, 0.0, -0.2340240478515625, -0.247802734375, -0.0618133544921875, 0.0, 0.0, 4.829475402832031, 0.0, 13.918838500976562, -0.3014984130859375, 19.840179443359375, 9.313995361328125, 78.02378463745117, 0.0, 0.0, 0.010040283203125, 0.0, 0.0, 0.0, 40.29161071777344, 0.0, 0.0, 0.0, 1.1236419677734375, 0.31443023681640625, 0.0, 52.17353057861328, 7.202308654785156, 0.0, 0.0, 0.0, -0.018585205078125, 0.0, 0.0, 29.921051025390625, 10.782367706298828, 0.0, 0.103057861328125, 23.248985290527344, 0.0, 0.0, 31.51324462890625, 0.0, 63.35662078857422, 0.0, 58.44282531738281, 0.0, 0.0, 49.562612533569336, 1.333953857421875, 0.0, 7.775505065917969, 7.995853424072266, 0.0, 0.0, 54.69036102294922, 40.1948299407959, -0.22188568115234375, 69.20330047607422, 11.553848266601562, 36.21497344970703, -0.9361419677734375, 0.0, 0.0, 33.34162902832031, 3.1354827880859375, 0.0, 29.839099884033203, 0.069000244140625, 0.0, 0.0, 0.0, 0.474639892578125, 0.0, 9.495635986328125, 40.28277587890625, 66.08442306518555, 75.96072769165039, 0.0, 0.9239425659179688, 0.0, 0.06345367431640625, 40.032081604003906, 0.0, 0.0, 0.0, 30.284408569335938, 1.4051132202148438, 62.552398681640625, -0.342315673828125, 0.0, 0.0, 0.0, -0.1025238037109375, -0.428375244140625, 0.8887710571289062, 0.331298828125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 450, 500, 500, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.600673387752053, "mean_inference_ms": 4.956333024700024, "mean_action_processing_ms": 7.517471760573389, "mean_env_wait_ms": 11.434094063539016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.02378463745117, "episode_reward_min": -0.9361419677734375, "episode_reward_mean": 10.67003401448904, "episode_len_mean": 498.9917355371901, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.8734817504882812, 0.0, 44.964569091796875, 52.03310775756836, 50.43682861328125, 0.0, 8.956466674804688, -0.35882568359375, 0.11725616455078125, 0.2657318115234375, 0.0, 0.0, 0.0, -0.2723541259765625, -0.7036895751953125, 0.0, 0.0, 19.357757568359375, 0.3871955871582031, -0.4337310791015625, 0.0, 0.24517822265625, 0.0, 0.0, 0.0, -0.2340240478515625, -0.247802734375, -0.0618133544921875, 0.0, 0.0, 4.829475402832031, 0.0, 13.918838500976562, -0.3014984130859375, 19.840179443359375, 9.313995361328125, 78.02378463745117, 0.0, 0.0, 0.010040283203125, 0.0, 0.0, 0.0, 40.29161071777344, 0.0, 0.0, 0.0, 1.1236419677734375, 0.31443023681640625, 0.0, 52.17353057861328, 7.202308654785156, 0.0, 0.0, 0.0, -0.018585205078125, 0.0, 0.0, 29.921051025390625, 10.782367706298828, 0.0, 0.103057861328125, 23.248985290527344, 0.0, 0.0, 31.51324462890625, 0.0, 63.35662078857422, 0.0, 58.44282531738281, 0.0, 0.0, 49.562612533569336, 1.333953857421875, 0.0, 7.775505065917969, 7.995853424072266, 0.0, 0.0, 54.69036102294922, 40.1948299407959, -0.22188568115234375, 69.20330047607422, 11.553848266601562, 36.21497344970703, -0.9361419677734375, 0.0, 0.0, 33.34162902832031, 3.1354827880859375, 0.0, 29.839099884033203, 0.069000244140625, 0.0, 0.0, 0.0, 0.474639892578125, 0.0, 9.495635986328125, 40.28277587890625, 66.08442306518555, 75.96072769165039, 0.0, 0.9239425659179688, 0.0, 0.06345367431640625, 40.032081604003906, 0.0, 0.0, 0.0, 30.284408569335938, 1.4051132202148438, 62.552398681640625, -0.342315673828125, 0.0, 0.0, 0.0, -0.1025238037109375, -0.428375244140625, 0.8887710571289062, 0.331298828125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 450, 500, 500, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.600673387752053, "mean_inference_ms": 4.956333024700024, "mean_action_processing_ms": 7.517471760573389, "mean_env_wait_ms": 11.434094063539016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20806013, "num_agent_steps_trained": 20806013, "num_env_steps_sampled": 20806013, "num_env_steps_trained": 20806013, "num_env_steps_sampled_this_iter": 60378, "num_env_steps_trained_this_iter": 60378, "timesteps_total": 20806013, "num_steps_trained_this_iter": 60378, "agent_timesteps_total": 20806013, "timers": {"training_iteration_time_ms": 46950.192, "load_time_ms": 47.947, "load_throughput": 1269354.693, "learn_time_ms": 26682.698, "learn_throughput": 2280.939, "synch_weights_time_ms": 9.009}, "counters": {"num_env_steps_sampled": 20806013, "num_env_steps_trained": 20806013, "num_agent_steps_sampled": 20806013, "num_agent_steps_trained": 20806013}, "done": false, "episodes_total": 42131, "training_iteration": 343, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-40-10", "timestamp": 1735108810, "time_this_iter_s": 47.30496907234192, "time_total_s": 9918.671758413315, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEA2F0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3755510>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1061.54185962677, "timesteps_since_restore": 0, "iterations_since_restore": 22, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.45820895522388, "ram_util_percent": 95.96119402985076}}
{"custom_metrics": {"rewards/0_mean": 11.834811404468567, "rewards/0_min": -2.2349090576171875, "rewards/0_max": 81.18725204467773, "rewards/1_mean": 11.834811404468567, "rewards/1_min": -2.2349090576171875, "rewards/1_max": 81.18725204467773, "rewards/2_mean": 11.834811404468567, "rewards/2_min": -2.2349090576171875, "rewards/2_max": 81.18725204467773, "rewards/3_mean": 11.834811404468567, "rewards/3_min": -2.2349090576171875, "rewards/3_max": 81.18725204467773, "rewards/4_mean": 11.834811404468567, "rewards/4_min": -2.2349090576171875, "rewards/4_max": 81.18725204467773}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.03400596825568567, "policy_loss": 0.00926704920887474, "vf_loss": 0.1589503174943347, "vf_explained_var": 0.9878389225119636, "kl": 0.012483947433804769, "entropy": 20.28553390048799, "entropy_coeff": 0.01, "grad_gnorm": 1.7149288892272918}, "model": {}, "num_grad_updates_lifetime": 14265.5, "diff_num_grad_updates_vs_sampler_policy": 14264.5}}, "num_env_steps_sampled": 20866492, "num_env_steps_trained": 20866492, "num_agent_steps_sampled": 20866492, "num_agent_steps_trained": 20866492}, "sampler_results": {"episode_reward_max": 81.18725204467773, "episode_reward_min": -2.2349090576171875, "episode_reward_mean": 11.834811404468567, "episode_len_mean": 491.6991869918699, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.834811404468567, "rewards/0_min": -2.2349090576171875, "rewards/0_max": 81.18725204467773, "rewards/1_mean": 11.834811404468567, "rewards/1_min": -2.2349090576171875, "rewards/1_max": 81.18725204467773, "rewards/2_mean": 11.834811404468567, "rewards/2_min": -2.2349090576171875, "rewards/2_max": 81.18725204467773, "rewards/3_mean": 11.834811404468567, "rewards/3_min": -2.2349090576171875, "rewards/3_max": 81.18725204467773, "rewards/4_mean": 11.834811404468567, "rewards/4_min": -2.2349090576171875, "rewards/4_max": 81.18725204467773}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.18725204467773, 0.0, 0.0, 0.0, 0.33954620361328125, 0.3280906677246094, 31.669322967529297, 0.0, -0.129974365234375, 6.2906036376953125, 14.296394348144531, 0.0, 16.639328002929688, 36.860565185546875, -0.3054046630859375, 44.216461181640625, -2.2349090576171875, 0.37530517578125, 38.93722724914551, 0.3412017822265625, 13.637847900390625, 63.126861572265625, 23.357852935791016, 60.07331848144531, 0.025238037109375, 0.0, 13.483978271484375, 0.0, 14.996734619140625, 0.0, 0.0, 0.0, 0.0, 37.966163635253906, 0.6820297241210938, 0.0, 0.1042938232421875, 0.0, 0.0, 58.02168083190918, 59.997915267944336, 25.81884765625, 0.01259613037109375, 0.0, 0.0, 0.0, 48.67271614074707, 19.756446838378906, 57.26377868652344, 0.0, 0.0, 0.0, 18.720115661621094, 0.0, 0.0, 43.18313217163086, 0.0, 0.3009490966796875, 6.630859375, 0.163421630859375, 51.49266052246094, 0.0, 0.00638580322265625, 0.0, 0.0203399658203125, 0.0, -0.2511138916015625, 32.531646728515625, 0.0, 0.0, -0.1010589599609375, 38.42742919921875, 0.0, 12.500442504882812, 20.874908447265625, 0.0, 29.114479064941406, 14.568166732788086, -0.34698486328125, 2.3754348754882812, 0.0, -0.02300262451171875, 0.0, 52.03590774536133, -0.277252197265625, 72.76660919189453, 0.0, 0.0, 0.0, 39.14630126953125, 2.0111541748046875, 0.0, 0.0, 37.81038284301758, 0.23848724365234375, 0.0, -0.472808837890625, 0.0, 13.224010467529297, 6.378700256347656, 0.0, 0.0, 0.4126434326171875, 0.0, 0.0, 9.421340942382812, 6.937465667724609, 0.0, 16.84784698486328, 51.14815139770508, 0.0, 0.0, 0.7251815795898438, 33.85023880004883, 77.47991943359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 226, 500, 500, 500, 500, 500, 500, 275, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.605848296768247, "mean_inference_ms": 4.954713354730624, "mean_action_processing_ms": 7.508781714914809, "mean_env_wait_ms": 11.435601319115879, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 81.18725204467773, "episode_reward_min": -2.2349090576171875, "episode_reward_mean": 11.834811404468567, "episode_len_mean": 491.6991869918699, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.18725204467773, 0.0, 0.0, 0.0, 0.33954620361328125, 0.3280906677246094, 31.669322967529297, 0.0, -0.129974365234375, 6.2906036376953125, 14.296394348144531, 0.0, 16.639328002929688, 36.860565185546875, -0.3054046630859375, 44.216461181640625, -2.2349090576171875, 0.37530517578125, 38.93722724914551, 0.3412017822265625, 13.637847900390625, 63.126861572265625, 23.357852935791016, 60.07331848144531, 0.025238037109375, 0.0, 13.483978271484375, 0.0, 14.996734619140625, 0.0, 0.0, 0.0, 0.0, 37.966163635253906, 0.6820297241210938, 0.0, 0.1042938232421875, 0.0, 0.0, 58.02168083190918, 59.997915267944336, 25.81884765625, 0.01259613037109375, 0.0, 0.0, 0.0, 48.67271614074707, 19.756446838378906, 57.26377868652344, 0.0, 0.0, 0.0, 18.720115661621094, 0.0, 0.0, 43.18313217163086, 0.0, 0.3009490966796875, 6.630859375, 0.163421630859375, 51.49266052246094, 0.0, 0.00638580322265625, 0.0, 0.0203399658203125, 0.0, -0.2511138916015625, 32.531646728515625, 0.0, 0.0, -0.1010589599609375, 38.42742919921875, 0.0, 12.500442504882812, 20.874908447265625, 0.0, 29.114479064941406, 14.568166732788086, -0.34698486328125, 2.3754348754882812, 0.0, -0.02300262451171875, 0.0, 52.03590774536133, -0.277252197265625, 72.76660919189453, 0.0, 0.0, 0.0, 39.14630126953125, 2.0111541748046875, 0.0, 0.0, 37.81038284301758, 0.23848724365234375, 0.0, -0.472808837890625, 0.0, 13.224010467529297, 6.378700256347656, 0.0, 0.0, 0.4126434326171875, 0.0, 0.0, 9.421340942382812, 6.937465667724609, 0.0, 16.84784698486328, 51.14815139770508, 0.0, 0.0, 0.7251815795898438, 33.85023880004883, 77.47991943359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 226, 500, 500, 500, 500, 500, 500, 275, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.605848296768247, "mean_inference_ms": 4.954713354730624, "mean_action_processing_ms": 7.508781714914809, "mean_env_wait_ms": 11.435601319115879, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20866492, "num_agent_steps_trained": 20866492, "num_env_steps_sampled": 20866492, "num_env_steps_trained": 20866492, "num_env_steps_sampled_this_iter": 60479, "num_env_steps_trained_this_iter": 60479, "timesteps_total": 20866492, "num_steps_trained_this_iter": 60479, "agent_timesteps_total": 20866492, "timers": {"training_iteration_time_ms": 47160.311, "load_time_ms": 48.032, "load_throughput": 1266464.518, "learn_time_ms": 26801.942, "learn_throughput": 2269.638, "synch_weights_time_ms": 9.008}, "counters": {"num_env_steps_sampled": 20866492, "num_env_steps_trained": 20866492, "num_agent_steps_sampled": 20866492, "num_agent_steps_trained": 20866492}, "done": false, "episodes_total": 42254, "training_iteration": 344, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-40-58", "timestamp": 1735108858, "time_this_iter_s": 48.31945991516113, "time_total_s": 9966.991218328476, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE9720>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3A67370>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1109.8613195419312, "timesteps_since_restore": 0, "iterations_since_restore": 23, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.79558823529412, "ram_util_percent": 96.1441176470588}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6523758637719229, "mean_inference_ms": 3.4125600515104018, "mean_action_processing_ms": 0.4645093637959855, "mean_env_wait_ms": 5.618073853527437, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 7.097213248896405, "rewards/0_min": -0.892822265625, "rewards/0_max": 82.49946022033691, "rewards/1_mean": 7.097213248896405, "rewards/1_min": -0.892822265625, "rewards/1_max": 82.49946022033691, "rewards/2_mean": 7.097213248896405, "rewards/2_min": -0.892822265625, "rewards/2_max": 82.49946022033691, "rewards/3_mean": 7.097213248896405, "rewards/3_min": -0.892822265625, "rewards/3_max": 82.49946022033691, "rewards/4_mean": 7.097213248896405, "rewards/4_min": -0.892822265625, "rewards/4_max": 82.49946022033691}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.15476595932610393, "policy_loss": -2.7001791900219693e-05, "vf_loss": 0.07071600957803191, "vf_explained_var": 0.9829457638755678, "kl": 0.01409409534156559, "entropy": 22.61684853992765, "entropy_coeff": 0.01, "grad_gnorm": 2.0655229816597607}, "model": {}, "num_grad_updates_lifetime": 14895.5, "diff_num_grad_updates_vs_sampler_policy": 14894.5}}, "num_env_steps_sampled": 20927016, "num_env_steps_trained": 20927016, "num_agent_steps_sampled": 20927016, "num_agent_steps_trained": 20927016}, "sampler_results": {"episode_reward_max": 82.49946022033691, "episode_reward_min": -0.892822265625, "episode_reward_mean": 7.097213248896405, "episode_len_mean": 492.0650406504065, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.097213248896405, "rewards/0_min": -0.892822265625, "rewards/0_max": 82.49946022033691, "rewards/1_mean": 7.097213248896405, "rewards/1_min": -0.892822265625, "rewards/1_max": 82.49946022033691, "rewards/2_mean": 7.097213248896405, "rewards/2_min": -0.892822265625, "rewards/2_max": 82.49946022033691, "rewards/3_mean": 7.097213248896405, "rewards/3_min": -0.892822265625, "rewards/3_max": 82.49946022033691, "rewards/4_mean": 7.097213248896405, "rewards/4_min": -0.892822265625, "rewards/4_max": 82.49946022033691}, "hist_stats": {"episode_reward": [17.681838989257812, 0.0, 0.0, 14.730823516845703, 0.0, 0.0, 4.5110321044921875, 13.548583984375, 29.441791534423828, 0.210784912109375, 41.963239669799805, 0.0, 0.0, 82.49946022033691, 66.51255798339844, 43.16321563720703, 0.0, 0.0, 0.0, 0.0, 6.022979736328125, 0.0, 0.0, 0.0, 0.0, 17.62682342529297, 0.0, 0.0, -0.18572998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4252471923828125, 0.0, 12.059440612792969, 0.0, 0.0, 0.0, -0.892822265625, 0.0, 0.0, 41.072601318359375, 0.1490020751953125, 0.0, 0.0, 0.8522872924804688, 18.952423095703125, 0.0, 21.07373046875, 0.24848175048828125, 6.48797607421875, 0.0, -0.043426513671875, 0.0, 0.0, 51.85444641113281, 1.6237030029296875, 0.0, 11.411880493164062, 1.2892837524414062, 19.21947479248047, -0.000213623046875, 0.13158416748046875, 0.0, -0.006317138671875, -0.052978515625, 4.079477310180664, 0.0, 0.0, -0.0332489013671875, -0.6444549560546875, 0.0, 0.0, 14.480464935302734, 0.0, 52.07681083679199, 0.6550102233886719, -0.44182586669921875, 18.829261779785156, 0.0, 0.1488800048828125, 34.45182418823242, 0.0, 0.0, 0.0, 13.326536178588867, 0.0, -0.16522598266601562, 0.0, 31.319732666015625, -0.0405426025390625, 0.0, 26.910629272460938, -0.00864410400390625, 0.0, 0.0, 8.633094787597656, 9.143020629882812, 0.0, -0.2967376708984375, 31.417062759399414, 1.579559326171875, 17.020362854003906, 19.543670654296875, 0.0, 0.0, 0.0, 0.0, 0.0, 39.32196044921875, 0.2802886962890625, 0.1458282470703125, 0.0, 0.0, 0.0, 0.0, 28.491722106933594], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 282, 500, 500, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 175, 500, 500, 500, 500, 500, 500, 500, 500, 335, 500, 500, 500, 500, 500, 500, 500, 500, 500, 268, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.621642432750592, "mean_inference_ms": 4.970441961966591, "mean_action_processing_ms": 7.504572784980588, "mean_env_wait_ms": 11.437715848529253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 82.49946022033691, "episode_reward_min": -0.892822265625, "episode_reward_mean": 7.097213248896405, "episode_len_mean": 492.0650406504065, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [17.681838989257812, 0.0, 0.0, 14.730823516845703, 0.0, 0.0, 4.5110321044921875, 13.548583984375, 29.441791534423828, 0.210784912109375, 41.963239669799805, 0.0, 0.0, 82.49946022033691, 66.51255798339844, 43.16321563720703, 0.0, 0.0, 0.0, 0.0, 6.022979736328125, 0.0, 0.0, 0.0, 0.0, 17.62682342529297, 0.0, 0.0, -0.18572998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4252471923828125, 0.0, 12.059440612792969, 0.0, 0.0, 0.0, -0.892822265625, 0.0, 0.0, 41.072601318359375, 0.1490020751953125, 0.0, 0.0, 0.8522872924804688, 18.952423095703125, 0.0, 21.07373046875, 0.24848175048828125, 6.48797607421875, 0.0, -0.043426513671875, 0.0, 0.0, 51.85444641113281, 1.6237030029296875, 0.0, 11.411880493164062, 1.2892837524414062, 19.21947479248047, -0.000213623046875, 0.13158416748046875, 0.0, -0.006317138671875, -0.052978515625, 4.079477310180664, 0.0, 0.0, -0.0332489013671875, -0.6444549560546875, 0.0, 0.0, 14.480464935302734, 0.0, 52.07681083679199, 0.6550102233886719, -0.44182586669921875, 18.829261779785156, 0.0, 0.1488800048828125, 34.45182418823242, 0.0, 0.0, 0.0, 13.326536178588867, 0.0, -0.16522598266601562, 0.0, 31.319732666015625, -0.0405426025390625, 0.0, 26.910629272460938, -0.00864410400390625, 0.0, 0.0, 8.633094787597656, 9.143020629882812, 0.0, -0.2967376708984375, 31.417062759399414, 1.579559326171875, 17.020362854003906, 19.543670654296875, 0.0, 0.0, 0.0, 0.0, 0.0, 39.32196044921875, 0.2802886962890625, 0.1458282470703125, 0.0, 0.0, 0.0, 0.0, 28.491722106933594], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 282, 500, 500, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 175, 500, 500, 500, 500, 500, 500, 500, 500, 335, 500, 500, 500, 500, 500, 500, 500, 500, 500, 268, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.621642432750592, "mean_inference_ms": 4.970441961966591, "mean_action_processing_ms": 7.504572784980588, "mean_env_wait_ms": 11.437715848529253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20927016, "num_agent_steps_trained": 20927016, "num_env_steps_sampled": 20927016, "num_env_steps_trained": 20927016, "num_env_steps_sampled_this_iter": 60524, "num_env_steps_trained_this_iter": 60524, "timesteps_total": 20927016, "num_steps_trained_this_iter": 60524, "agent_timesteps_total": 20927016, "timers": {"training_iteration_time_ms": 47334.912, "load_time_ms": 48.038, "load_throughput": 1266166.018, "learn_time_ms": 26891.352, "learn_throughput": 2261.842, "synch_weights_time_ms": 8.007}, "counters": {"num_env_steps_sampled": 20927016, "num_env_steps_trained": 20927016, "num_agent_steps_sampled": 20927016, "num_agent_steps_trained": 20927016}, "done": false, "episodes_total": 42377, "training_iteration": 345, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-41-46", "timestamp": 1735108906, "time_this_iter_s": 47.731242418289185, "time_total_s": 10014.722460746765, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A5AE00>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1157.5925619602203, "timesteps_since_restore": 0, "iterations_since_restore": 24, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.217910447761195, "ram_util_percent": 96.20149253731344}}
{"custom_metrics": {"rewards/0_mean": 9.949721561214789, "rewards/0_min": -1.396270751953125, "rewards/0_max": 85.42486953735352, "rewards/1_mean": 9.949721561214789, "rewards/1_min": -1.396270751953125, "rewards/1_max": 85.42486953735352, "rewards/2_mean": 9.949721561214789, "rewards/2_min": -1.396270751953125, "rewards/2_max": 85.42486953735352, "rewards/3_mean": 9.949721561214789, "rewards/3_min": -1.396270751953125, "rewards/3_max": 85.42486953735352, "rewards/4_mean": 9.949721561214789, "rewards/4_min": -1.396270751953125, "rewards/4_max": 85.42486953735352}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09899054322214354, "policy_loss": 0.003181674593083915, "vf_loss": 0.1162087556939306, "vf_explained_var": 0.9778326294724904, "kl": 0.012040457970625352, "entropy": 21.899052518511574, "entropy_coeff": 0.01, "grad_gnorm": 1.3420706261008506}, "model": {}, "num_grad_updates_lifetime": 15525.5, "diff_num_grad_updates_vs_sampler_policy": 15524.5}}, "num_env_steps_sampled": 20987430, "num_env_steps_trained": 20987430, "num_agent_steps_sampled": 20987430, "num_agent_steps_trained": 20987430}, "sampler_results": {"episode_reward_max": 85.42486953735352, "episode_reward_min": -1.396270751953125, "episode_reward_mean": 9.949721561214789, "episode_len_mean": 491.1707317073171, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.949721561214789, "rewards/0_min": -1.396270751953125, "rewards/0_max": 85.42486953735352, "rewards/1_mean": 9.949721561214789, "rewards/1_min": -1.396270751953125, "rewards/1_max": 85.42486953735352, "rewards/2_mean": 9.949721561214789, "rewards/2_min": -1.396270751953125, "rewards/2_max": 85.42486953735352, "rewards/3_mean": 9.949721561214789, "rewards/3_min": -1.396270751953125, "rewards/3_max": 85.42486953735352, "rewards/4_mean": 9.949721561214789, "rewards/4_min": -1.396270751953125, "rewards/4_max": 85.42486953735352}, "hist_stats": {"episode_reward": [0.0, -0.33405303955078125, 9.404102325439453, 19.545997619628906, 0.079833984375, 0.0, 0.9984855651855469, 0.0, 29.256481170654297, 33.390132904052734, 0.0, -0.1350860595703125, 0.0, 23.16490936279297, 0.0420684814453125, 51.97679138183594, 0.0, 0.0, 0.0, 0.0, 0.0, 12.006450653076172, 0.0, 6.081850051879883, 0.0, 0.0, 0.006103515625, -0.7193603515625, 0.0, 0.0, 0.951629638671875, 12.773029327392578, 0.0, 0.0, 0.6646499633789062, 67.82845306396484, 5.369956970214844, 0.0137176513671875, -1.396270751953125, 0.0, 0.8282012939453125, 52.999515533447266, 12.879409790039062, 0.0, 20.527694702148438, 8.897438049316406, 0.7048416137695312, 1.3299560546875, 0.34061431884765625, 0.0, 0.0, 0.0, 0.0, 23.224853515625, 0.0, 16.85950469970703, 0.04323577880859375, 0.5731124877929688, 0.0, -0.0651092529296875, 0.0, 0.08350753784179688, -0.027507781982421875, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3397254943847656, 0.0, 36.90037155151367, 0.0, 0.0, 45.467864990234375, 0.0, 3.8091659545898438, -0.1525115966796875, 0.0, 0.0, 0.3477020263671875, 30.894241333007812, 0.0, 30.179161071777344, 0.0, 0.0, 18.741012573242188, 0.16262054443359375, 42.12390327453613, 0.0, 4.63337516784668, 0.0, -0.3939056396484375, 0.3739166259765625, -0.0881195068359375, 52.222999572753906, 0.8228721618652344, 2.7438087463378906, -0.482269287109375, 5.5932464599609375, 85.42486953735352, 0.0, 9.17824935913086, 0.2599639892578125, -0.887420654296875, 0.0044708251953125, 84.36011505126953, 0.6289215087890625, -0.0418853759765625, 33.84376525878906, 82.82658004760742, 75.04789733886719, 23.7650146484375, 0.0, 0.2202911376953125, 63.58460998535156, 0.0, 0.0, 29.647842407226562, 51.38566589355469, -0.04943084716796875, -0.39288330078125, 0.0, 1.280242919921875], "episode_lengths": [500, 500, 500, 225, 500, 500, 500, 500, 500, 317, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 240, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 499, 500, 133, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.635749049048743, "mean_inference_ms": 4.962796834209777, "mean_action_processing_ms": 7.509398366781921, "mean_env_wait_ms": 11.429549070613932, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 85.42486953735352, "episode_reward_min": -1.396270751953125, "episode_reward_mean": 9.949721561214789, "episode_len_mean": 491.1707317073171, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, -0.33405303955078125, 9.404102325439453, 19.545997619628906, 0.079833984375, 0.0, 0.9984855651855469, 0.0, 29.256481170654297, 33.390132904052734, 0.0, -0.1350860595703125, 0.0, 23.16490936279297, 0.0420684814453125, 51.97679138183594, 0.0, 0.0, 0.0, 0.0, 0.0, 12.006450653076172, 0.0, 6.081850051879883, 0.0, 0.0, 0.006103515625, -0.7193603515625, 0.0, 0.0, 0.951629638671875, 12.773029327392578, 0.0, 0.0, 0.6646499633789062, 67.82845306396484, 5.369956970214844, 0.0137176513671875, -1.396270751953125, 0.0, 0.8282012939453125, 52.999515533447266, 12.879409790039062, 0.0, 20.527694702148438, 8.897438049316406, 0.7048416137695312, 1.3299560546875, 0.34061431884765625, 0.0, 0.0, 0.0, 0.0, 23.224853515625, 0.0, 16.85950469970703, 0.04323577880859375, 0.5731124877929688, 0.0, -0.0651092529296875, 0.0, 0.08350753784179688, -0.027507781982421875, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3397254943847656, 0.0, 36.90037155151367, 0.0, 0.0, 45.467864990234375, 0.0, 3.8091659545898438, -0.1525115966796875, 0.0, 0.0, 0.3477020263671875, 30.894241333007812, 0.0, 30.179161071777344, 0.0, 0.0, 18.741012573242188, 0.16262054443359375, 42.12390327453613, 0.0, 4.63337516784668, 0.0, -0.3939056396484375, 0.3739166259765625, -0.0881195068359375, 52.222999572753906, 0.8228721618652344, 2.7438087463378906, -0.482269287109375, 5.5932464599609375, 85.42486953735352, 0.0, 9.17824935913086, 0.2599639892578125, -0.887420654296875, 0.0044708251953125, 84.36011505126953, 0.6289215087890625, -0.0418853759765625, 33.84376525878906, 82.82658004760742, 75.04789733886719, 23.7650146484375, 0.0, 0.2202911376953125, 63.58460998535156, 0.0, 0.0, 29.647842407226562, 51.38566589355469, -0.04943084716796875, -0.39288330078125, 0.0, 1.280242919921875], "episode_lengths": [500, 500, 500, 225, 500, 500, 500, 500, 500, 317, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 240, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 499, 500, 133, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.635749049048743, "mean_inference_ms": 4.962796834209777, "mean_action_processing_ms": 7.509398366781921, "mean_env_wait_ms": 11.429549070613932, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20987430, "num_agent_steps_trained": 20987430, "num_env_steps_sampled": 20987430, "num_env_steps_trained": 20987430, "num_env_steps_sampled_this_iter": 60414, "num_env_steps_trained_this_iter": 60414, "timesteps_total": 20987430, "num_steps_trained_this_iter": 60414, "agent_timesteps_total": 20987430, "timers": {"training_iteration_time_ms": 47411.885, "load_time_ms": 48.039, "load_throughput": 1264977.242, "learn_time_ms": 26932.084, "learn_throughput": 2256.346, "synch_weights_time_ms": 7.999}, "counters": {"num_env_steps_sampled": 20987430, "num_env_steps_trained": 20987430, "num_agent_steps_sampled": 20987430, "num_agent_steps_trained": 20987430}, "done": false, "episodes_total": 42500, "training_iteration": 346, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-42-34", "timestamp": 1735108954, "time_this_iter_s": 47.58263969421387, "time_total_s": 10062.305100440979, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B50A30>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C703A0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1205.1752016544342, "timesteps_since_restore": 0, "iterations_since_restore": 25, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.876119402985076, "ram_util_percent": 96.08358208955224}}
{"custom_metrics": {"rewards/0_mean": 11.367297157164543, "rewards/0_min": -0.560394287109375, "rewards/0_max": 76.28662109375, "rewards/1_mean": 11.367297157164543, "rewards/1_min": -0.560394287109375, "rewards/1_max": 76.28662109375, "rewards/2_mean": 11.367297157164543, "rewards/2_min": -0.560394287109375, "rewards/2_max": 76.28662109375, "rewards/3_mean": 11.367297157164543, "rewards/3_min": -0.560394287109375, "rewards/3_max": 76.28662109375, "rewards/4_mean": 11.367297157164543, "rewards/4_min": -0.560394287109375, "rewards/4_max": 76.28662109375}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08881118584503715, "policy_loss": 0.004414878495015093, "vf_loss": 0.10981530061671659, "vf_explained_var": 0.9888268416836148, "kl": 0.013134974309258045, "entropy": 20.37063275443183, "entropy_coeff": 0.01, "grad_gnorm": 1.4254583313469849}, "model": {}, "num_grad_updates_lifetime": 16155.5, "diff_num_grad_updates_vs_sampler_policy": 16154.5}}, "num_env_steps_sampled": 21048350, "num_env_steps_trained": 21048350, "num_agent_steps_sampled": 21048350, "num_agent_steps_trained": 21048350}, "sampler_results": {"episode_reward_max": 76.28662109375, "episode_reward_min": -0.560394287109375, "episode_reward_mean": 11.367297157164543, "episode_len_mean": 491.2903225806452, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.367297157164543, "rewards/0_min": -0.560394287109375, "rewards/0_max": 76.28662109375, "rewards/1_mean": 11.367297157164543, "rewards/1_min": -0.560394287109375, "rewards/1_max": 76.28662109375, "rewards/2_mean": 11.367297157164543, "rewards/2_min": -0.560394287109375, "rewards/2_max": 76.28662109375, "rewards/3_mean": 11.367297157164543, "rewards/3_min": -0.560394287109375, "rewards/3_max": 76.28662109375, "rewards/4_mean": 11.367297157164543, "rewards/4_min": -0.560394287109375, "rewards/4_max": 76.28662109375}, "hist_stats": {"episode_reward": [0.1341552734375, 0.0, 0.0, 0.0, 2.521453857421875, 0.0, -0.07561492919921875, 0.0, 0.0, 0.0, 41.874603271484375, 36.26435852050781, 19.212718963623047, 0.0, 0.0, 32.61284255981445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.193450927734375, 40.88292121887207, 0.0, 0.0, 39.07579040527344, 32.90172576904297, 32.367374420166016, 65.537841796875, 0.833831787109375, -0.00337982177734375, -0.18033599853515625, 36.932281494140625, 6.5923614501953125, 0.5836868286132812, 69.0655746459961, 0.0, 0.0, 34.47620391845703, 0.0, 0.0, 0.0, -0.5433597564697266, 30.89520263671875, 0.0, 16.551403045654297, 11.5008544921875, 42.640892028808594, -0.28765106201171875, 0.0, 0.0, 0.0, 0.0, 5.288749694824219, 0.48857879638671875, 0.0, 0.0, 24.154830932617188, 0.0, 0.0, 28.245384216308594, 0.0, 0.0, 0.0, -0.1568145751953125, -0.560394287109375, 0.0, 19.13937759399414, 0.0, 0.0, 0.0, 0.8490447998046875, 23.381607055664062, 0.0, 59.276031494140625, 0.07382965087890625, 0.0, 0.0, 0.0, 27.91301727294922, 48.88642501831055, 0.0, 0.84014892578125, 0.0, 47.18650817871094, 16.522912979125977, 0.0, 27.777359008789062, 0.031707763671875, 2.045135498046875, 10.2574462890625, 61.58235168457031, 0.0, 69.29299926757812, 0.0, 16.17937469482422, 0.29296875, -0.022796630859375, 36.13047790527344, 0.0, 35.428558349609375, 0.0, 7.764354705810547, -0.06732940673828125, 7.999114990234375, 56.8869514465332, 0.0, -0.1461334228515625, 0.0, 42.12104797363281, -0.0074310302734375, 0.0936279296875, 39.46986389160156, 0.012939453125, -0.167694091796875, 0.0, 0.0, 0.0348663330078125, 76.28662109375, -0.1397705078125, 0.0, 0.0, -0.08148193359375, 26.3992919921875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 390, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 472, 500, 500, 500, 500, 500, 500, 302, 500, 331, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 201, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 224, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.613424127487436, "mean_inference_ms": 4.96119772138568, "mean_action_processing_ms": 7.501003371063961, "mean_env_wait_ms": 11.403595199919419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.28662109375, "episode_reward_min": -0.560394287109375, "episode_reward_mean": 11.367297157164543, "episode_len_mean": 491.2903225806452, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.1341552734375, 0.0, 0.0, 0.0, 2.521453857421875, 0.0, -0.07561492919921875, 0.0, 0.0, 0.0, 41.874603271484375, 36.26435852050781, 19.212718963623047, 0.0, 0.0, 32.61284255981445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.193450927734375, 40.88292121887207, 0.0, 0.0, 39.07579040527344, 32.90172576904297, 32.367374420166016, 65.537841796875, 0.833831787109375, -0.00337982177734375, -0.18033599853515625, 36.932281494140625, 6.5923614501953125, 0.5836868286132812, 69.0655746459961, 0.0, 0.0, 34.47620391845703, 0.0, 0.0, 0.0, -0.5433597564697266, 30.89520263671875, 0.0, 16.551403045654297, 11.5008544921875, 42.640892028808594, -0.28765106201171875, 0.0, 0.0, 0.0, 0.0, 5.288749694824219, 0.48857879638671875, 0.0, 0.0, 24.154830932617188, 0.0, 0.0, 28.245384216308594, 0.0, 0.0, 0.0, -0.1568145751953125, -0.560394287109375, 0.0, 19.13937759399414, 0.0, 0.0, 0.0, 0.8490447998046875, 23.381607055664062, 0.0, 59.276031494140625, 0.07382965087890625, 0.0, 0.0, 0.0, 27.91301727294922, 48.88642501831055, 0.0, 0.84014892578125, 0.0, 47.18650817871094, 16.522912979125977, 0.0, 27.777359008789062, 0.031707763671875, 2.045135498046875, 10.2574462890625, 61.58235168457031, 0.0, 69.29299926757812, 0.0, 16.17937469482422, 0.29296875, -0.022796630859375, 36.13047790527344, 0.0, 35.428558349609375, 0.0, 7.764354705810547, -0.06732940673828125, 7.999114990234375, 56.8869514465332, 0.0, -0.1461334228515625, 0.0, 42.12104797363281, -0.0074310302734375, 0.0936279296875, 39.46986389160156, 0.012939453125, -0.167694091796875, 0.0, 0.0, 0.0348663330078125, 76.28662109375, -0.1397705078125, 0.0, 0.0, -0.08148193359375, 26.3992919921875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 390, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 472, 500, 500, 500, 500, 500, 500, 302, 500, 331, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 201, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 224, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.613424127487436, "mean_inference_ms": 4.96119772138568, "mean_action_processing_ms": 7.501003371063961, "mean_env_wait_ms": 11.403595199919419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21048350, "num_agent_steps_trained": 21048350, "num_env_steps_sampled": 21048350, "num_env_steps_trained": 21048350, "num_env_steps_sampled_this_iter": 60920, "num_env_steps_trained_this_iter": 60920, "timesteps_total": 21048350, "num_steps_trained_this_iter": 60920, "agent_timesteps_total": 21048350, "timers": {"training_iteration_time_ms": 47132.618, "load_time_ms": 46.922, "load_throughput": 1295356.617, "learn_time_ms": 26951.791, "learn_throughput": 2255.186, "synch_weights_time_ms": 7.986}, "counters": {"num_env_steps_sampled": 21048350, "num_env_steps_trained": 21048350, "num_agent_steps_sampled": 21048350, "num_agent_steps_trained": 21048350}, "done": false, "episodes_total": 42624, "training_iteration": 347, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-43-20", "timestamp": 1735109000, "time_this_iter_s": 45.90802764892578, "time_total_s": 10108.213128089905, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A830>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3B9B5B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1251.08322930336, "timesteps_since_restore": 0, "iterations_since_restore": 26, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.6265625, "ram_util_percent": 96.00781250000001}}
{"custom_metrics": {"rewards/0_mean": 12.157856440934978, "rewards/0_min": -0.8682327270507812, "rewards/0_max": 73.88366317749023, "rewards/1_mean": 12.157856440934978, "rewards/1_min": -0.8682327270507812, "rewards/1_max": 73.88366317749023, "rewards/2_mean": 12.157856440934978, "rewards/2_min": -0.8682327270507812, "rewards/2_max": 73.88366317749023, "rewards/3_mean": 12.157856440934978, "rewards/3_min": -0.8682327270507812, "rewards/3_max": 73.88366317749023, "rewards/4_mean": 12.157856440934978, "rewards/4_min": -0.8682327270507812, "rewards/4_max": 73.88366317749023}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.0635801569292588, "policy_loss": 0.0016698518592406005, "vf_loss": 0.1500582953242378, "vf_explained_var": 0.988383438284435, "kl": 0.0136544080502871, "entropy": 21.599956312633697, "entropy_coeff": 0.01, "grad_gnorm": 1.5829054691015727}, "model": {}, "num_grad_updates_lifetime": 16785.5, "diff_num_grad_updates_vs_sampler_policy": 16784.5}}, "num_env_steps_sampled": 21108969, "num_env_steps_trained": 21108969, "num_agent_steps_sampled": 21108969, "num_agent_steps_trained": 21108969}, "sampler_results": {"episode_reward_max": 73.88366317749023, "episode_reward_min": -0.8682327270507812, "episode_reward_mean": 12.157856440934978, "episode_len_mean": 496.87704918032784, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 12.157856440934978, "rewards/0_min": -0.8682327270507812, "rewards/0_max": 73.88366317749023, "rewards/1_mean": 12.157856440934978, "rewards/1_min": -0.8682327270507812, "rewards/1_max": 73.88366317749023, "rewards/2_mean": 12.157856440934978, "rewards/2_min": -0.8682327270507812, "rewards/2_max": 73.88366317749023, "rewards/3_mean": 12.157856440934978, "rewards/3_min": -0.8682327270507812, "rewards/3_max": 73.88366317749023, "rewards/4_mean": 12.157856440934978, "rewards/4_min": -0.8682327270507812, "rewards/4_max": 73.88366317749023}, "hist_stats": {"episode_reward": [17.23426055908203, 0.41851043701171875, 0.0, 23.774154663085938, 0.0, 2.80706787109375, 0.0, 0.0, 0.0, 47.191558837890625, 0.0, 50.41844177246094, 60.03540802001953, 0.0, 0.0, -0.7937469482421875, 0.0, 29.32465362548828, 22.165374755859375, 0.0, 67.36992645263672, -0.19019317626953125, 0.0, 0.0, 0.0, 0.0, -0.0615234375, 0.0, -0.06172943115234375, 0.2603912353515625, 0.0, 23.92839813232422, 0.0, 6.0289154052734375, 63.49916076660156, 0.05315399169921875, 0.2503814697265625, 0.0, 17.10595703125, -0.33414459228515625, 0.9096527099609375, 0.0, 4.0076141357421875, 0.0, 0.093841552734375, 14.602935791015625, -0.3020591735839844, 0.0, 0.0, 38.43646240234375, -0.0257568359375, 0.3171424865722656, -0.6035995483398438, 0.0, 55.46437072753906, 0.0, 0.0, 0.36827850341796875, 62.825767517089844, 0.0, 0.0, -0.1109619140625, 28.540191650390625, 45.73670959472656, 0.0, -0.26627349853515625, 7.6025848388671875, 47.29274368286133, 67.18830871582031, 65.00369262695312, 0.0, 59.32247352600098, 37.634490966796875, 0.0, 37.78074264526367, -0.3353424072265625, 51.013336181640625, 0.122589111328125, 23.640243530273438, 0.0, 0.0, 0.0, 0.2628326416015625, 0.0, -0.20086669921875, -0.3676300048828125, 27.806346893310547, 33.838478088378906, -0.8682327270507812, 0.0, -0.10939788818359375, 32.41345977783203, 0.0, 0.0, 0.0, 46.05554962158203, 0.0, 36.824188232421875, 0.0, -0.5811614990234375, 0.0, 0.0, 0.0, 9.434326171875, 0.7682456970214844, 0.0, 0.0, 0.0, 73.88366317749023, 24.056900024414062, 25.341232299804688, 18.86627960205078, -0.4182777404785156, 0.0, 29.42288589477539, 0.0, 11.790321350097656, 0.0, 0.0, 38.35478591918945, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 347, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 350, 500, 500, 500, 422, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.627707147078215, "mean_inference_ms": 4.961273809555659, "mean_action_processing_ms": 7.488893305363948, "mean_env_wait_ms": 11.415410506984397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 73.88366317749023, "episode_reward_min": -0.8682327270507812, "episode_reward_mean": 12.157856440934978, "episode_len_mean": 496.87704918032784, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [17.23426055908203, 0.41851043701171875, 0.0, 23.774154663085938, 0.0, 2.80706787109375, 0.0, 0.0, 0.0, 47.191558837890625, 0.0, 50.41844177246094, 60.03540802001953, 0.0, 0.0, -0.7937469482421875, 0.0, 29.32465362548828, 22.165374755859375, 0.0, 67.36992645263672, -0.19019317626953125, 0.0, 0.0, 0.0, 0.0, -0.0615234375, 0.0, -0.06172943115234375, 0.2603912353515625, 0.0, 23.92839813232422, 0.0, 6.0289154052734375, 63.49916076660156, 0.05315399169921875, 0.2503814697265625, 0.0, 17.10595703125, -0.33414459228515625, 0.9096527099609375, 0.0, 4.0076141357421875, 0.0, 0.093841552734375, 14.602935791015625, -0.3020591735839844, 0.0, 0.0, 38.43646240234375, -0.0257568359375, 0.3171424865722656, -0.6035995483398438, 0.0, 55.46437072753906, 0.0, 0.0, 0.36827850341796875, 62.825767517089844, 0.0, 0.0, -0.1109619140625, 28.540191650390625, 45.73670959472656, 0.0, -0.26627349853515625, 7.6025848388671875, 47.29274368286133, 67.18830871582031, 65.00369262695312, 0.0, 59.32247352600098, 37.634490966796875, 0.0, 37.78074264526367, -0.3353424072265625, 51.013336181640625, 0.122589111328125, 23.640243530273438, 0.0, 0.0, 0.0, 0.2628326416015625, 0.0, -0.20086669921875, -0.3676300048828125, 27.806346893310547, 33.838478088378906, -0.8682327270507812, 0.0, -0.10939788818359375, 32.41345977783203, 0.0, 0.0, 0.0, 46.05554962158203, 0.0, 36.824188232421875, 0.0, -0.5811614990234375, 0.0, 0.0, 0.0, 9.434326171875, 0.7682456970214844, 0.0, 0.0, 0.0, 73.88366317749023, 24.056900024414062, 25.341232299804688, 18.86627960205078, -0.4182777404785156, 0.0, 29.42288589477539, 0.0, 11.790321350097656, 0.0, 0.0, 38.35478591918945, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 347, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 350, 500, 500, 500, 422, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.627707147078215, "mean_inference_ms": 4.961273809555659, "mean_action_processing_ms": 7.488893305363948, "mean_env_wait_ms": 11.415410506984397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21108969, "num_agent_steps_trained": 21108969, "num_env_steps_sampled": 21108969, "num_env_steps_trained": 21108969, "num_env_steps_sampled_this_iter": 60619, "num_env_steps_trained_this_iter": 60619, "timesteps_total": 21108969, "num_steps_trained_this_iter": 60619, "agent_timesteps_total": 21108969, "timers": {"training_iteration_time_ms": 47093.777, "load_time_ms": 46.922, "load_throughput": 1294937.934, "learn_time_ms": 26919.9, "learn_throughput": 2257.122, "synch_weights_time_ms": 7.989}, "counters": {"num_env_steps_sampled": 21108969, "num_env_steps_trained": 21108969, "num_agent_steps_sampled": 21108969, "num_agent_steps_trained": 21108969}, "done": false, "episodes_total": 42746, "training_iteration": 348, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-44-07", "timestamp": 1735109047, "time_this_iter_s": 47.382283449172974, "time_total_s": 10155.595411539078, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B50340>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C703A0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1298.465512752533, "timesteps_since_restore": 0, "iterations_since_restore": 27, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.72537313432836, "ram_util_percent": 96.07164179104475}}
{"custom_metrics": {"rewards/0_mean": 7.011276057509125, "rewards/0_min": -0.343109130859375, "rewards/0_max": 73.9123477935791, "rewards/1_mean": 7.011276057509125, "rewards/1_min": -0.343109130859375, "rewards/1_max": 73.9123477935791, "rewards/2_mean": 7.011276057509125, "rewards/2_min": -0.343109130859375, "rewards/2_max": 73.9123477935791, "rewards/3_mean": 7.011276057509125, "rewards/3_min": -0.343109130859375, "rewards/3_max": 73.9123477935791, "rewards/4_mean": 7.011276057509125, "rewards/4_min": -0.343109130859375, "rewards/4_max": 73.9123477935791}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.12944068718878995, "policy_loss": 0.005138745150017914, "vf_loss": 0.10139801833549485, "vf_explained_var": 0.9701658541247958, "kl": 0.010538484434789372, "entropy": 23.65109659830729, "entropy_coeff": 0.01, "grad_gnorm": 1.3701382377791027}, "model": {}, "num_grad_updates_lifetime": 17415.5, "diff_num_grad_updates_vs_sampler_policy": 17414.5}}, "num_env_steps_sampled": 21169418, "num_env_steps_trained": 21169418, "num_agent_steps_sampled": 21169418, "num_agent_steps_trained": 21169418}, "sampler_results": {"episode_reward_max": 73.9123477935791, "episode_reward_min": -0.343109130859375, "episode_reward_mean": 7.011276057509125, "episode_len_mean": 495.4836065573771, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.011276057509125, "rewards/0_min": -0.343109130859375, "rewards/0_max": 73.9123477935791, "rewards/1_mean": 7.011276057509125, "rewards/1_min": -0.343109130859375, "rewards/1_max": 73.9123477935791, "rewards/2_mean": 7.011276057509125, "rewards/2_min": -0.343109130859375, "rewards/2_max": 73.9123477935791, "rewards/3_mean": 7.011276057509125, "rewards/3_min": -0.343109130859375, "rewards/3_max": 73.9123477935791, "rewards/4_mean": 7.011276057509125, "rewards/4_min": -0.343109130859375, "rewards/4_max": 73.9123477935791}, "hist_stats": {"episode_reward": [0.0, 4.773231506347656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4412384033203125, 0.0, -0.01454925537109375, -0.296966552734375, 0.0, 13.514808654785156, 0.0, 0.0, 0.0, 0.0, 0.0, -0.32940673828125, 0.0, 0.0, 0.0, 0.0, -0.0043621063232421875, 0.0, 0.0, 0.0, 0.0, 0.15008544921875, 0.0, 49.49317169189453, 20.233810424804688, 73.9123477935791, 0.0, 36.413330078125, 0.0, 0.0, 6.614574432373047, 0.0, 1.53900146484375, 0.0, 60.77882385253906, -0.343109130859375, 12.532550811767578, 24.913497924804688, 0.0, 41.19953155517578, 0.08892822265625, 0.7498550415039062, 0.0, 13.980758666992188, -0.1763916015625, 0.0, -0.064788818359375, 73.58379364013672, 0.0, -0.2801513671875, 0.6438255310058594, 0.0, 0.0, 49.20090103149414, 0.0, 40.047332763671875, -0.195709228515625, 0.0, 5.3392181396484375, -0.039794921875, 0.1540374755859375, 2.84039306640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3175048828125, 0.0, 0.0, 0.2584686279296875, 0.0, 21.938735961914062, 3.7077178955078125, 0.0, 20.20262908935547, 40.24555969238281, 0.0, 0.0, -0.0850372314453125, 36.84019470214844, 0.0, -0.087890625, 0.0, 0.0, 0.0, 13.545806884765625, 0.0, -0.09476089477539062, 0.0, 25.67937469482422, -0.08233642578125, -0.0454864501953125, 55.821529388427734, 0.0, 0.0, 0.0, 47.77207374572754, 0.0, 0.8664054870605469, 0.0, 0.0, 0.0, 0.5650177001953125, 25.092313766479492, 0.0, -0.27679443359375, 0.0, 31.80083465576172, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 427, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 371, 500, 500, 500, 500, 500, 500, 342, 500, 500, 500, 309, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.667310903100525, "mean_inference_ms": 4.9695821629332935, "mean_action_processing_ms": 7.4992243081485475, "mean_env_wait_ms": 11.420173988926758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 73.9123477935791, "episode_reward_min": -0.343109130859375, "episode_reward_mean": 7.011276057509125, "episode_len_mean": 495.4836065573771, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 4.773231506347656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4412384033203125, 0.0, -0.01454925537109375, -0.296966552734375, 0.0, 13.514808654785156, 0.0, 0.0, 0.0, 0.0, 0.0, -0.32940673828125, 0.0, 0.0, 0.0, 0.0, -0.0043621063232421875, 0.0, 0.0, 0.0, 0.0, 0.15008544921875, 0.0, 49.49317169189453, 20.233810424804688, 73.9123477935791, 0.0, 36.413330078125, 0.0, 0.0, 6.614574432373047, 0.0, 1.53900146484375, 0.0, 60.77882385253906, -0.343109130859375, 12.532550811767578, 24.913497924804688, 0.0, 41.19953155517578, 0.08892822265625, 0.7498550415039062, 0.0, 13.980758666992188, -0.1763916015625, 0.0, -0.064788818359375, 73.58379364013672, 0.0, -0.2801513671875, 0.6438255310058594, 0.0, 0.0, 49.20090103149414, 0.0, 40.047332763671875, -0.195709228515625, 0.0, 5.3392181396484375, -0.039794921875, 0.1540374755859375, 2.84039306640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3175048828125, 0.0, 0.0, 0.2584686279296875, 0.0, 21.938735961914062, 3.7077178955078125, 0.0, 20.20262908935547, 40.24555969238281, 0.0, 0.0, -0.0850372314453125, 36.84019470214844, 0.0, -0.087890625, 0.0, 0.0, 0.0, 13.545806884765625, 0.0, -0.09476089477539062, 0.0, 25.67937469482422, -0.08233642578125, -0.0454864501953125, 55.821529388427734, 0.0, 0.0, 0.0, 47.77207374572754, 0.0, 0.8664054870605469, 0.0, 0.0, 0.0, 0.5650177001953125, 25.092313766479492, 0.0, -0.27679443359375, 0.0, 31.80083465576172, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 427, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 371, 500, 500, 500, 500, 500, 500, 342, 500, 500, 500, 309, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.667310903100525, "mean_inference_ms": 4.9695821629332935, "mean_action_processing_ms": 7.4992243081485475, "mean_env_wait_ms": 11.420173988926758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21169418, "num_agent_steps_trained": 21169418, "num_env_steps_sampled": 21169418, "num_env_steps_trained": 21169418, "num_env_steps_sampled_this_iter": 60449, "num_env_steps_trained_this_iter": 60449, "timesteps_total": 21169418, "num_steps_trained_this_iter": 60449, "agent_timesteps_total": 21169418, "timers": {"training_iteration_time_ms": 47316.603, "load_time_ms": 47.317, "load_throughput": 1281743.057, "learn_time_ms": 26894.94, "learn_throughput": 2255.023, "synch_weights_time_ms": 7.981}, "counters": {"num_env_steps_sampled": 21169418, "num_env_steps_trained": 21169418, "num_agent_steps_sampled": 21169418, "num_agent_steps_trained": 21169418}, "done": false, "episodes_total": 42868, "training_iteration": 349, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-44-57", "timestamp": 1735109097, "time_this_iter_s": 49.74973511695862, "time_total_s": 10205.345146656036, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A58DC0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1348.2152478694916, "timesteps_since_restore": 0, "iterations_since_restore": 28, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.667142857142863, "ram_util_percent": 96.19714285714285}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6712711242706288, "mean_inference_ms": 3.437785933868601, "mean_action_processing_ms": 0.4609141974241008, "mean_env_wait_ms": 5.5562092121026385, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 10.044501695476594, "rewards/0_min": -0.702392578125, "rewards/0_max": 68.78036689758301, "rewards/1_mean": 10.044501695476594, "rewards/1_min": -0.702392578125, "rewards/1_max": 68.78036689758301, "rewards/2_mean": 10.044501695476594, "rewards/2_min": -0.702392578125, "rewards/2_max": 68.78036689758301, "rewards/3_mean": 10.044501695476594, "rewards/3_min": -0.702392578125, "rewards/3_max": 68.78036689758301, "rewards/4_mean": 10.044501695476594, "rewards/4_min": -0.702392578125, "rewards/4_max": 68.78036689758301}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.12753178828233291, "policy_loss": -0.007433126575594384, "vf_loss": 0.09675262006783178, "vf_explained_var": 0.9838150738723694, "kl": 0.01141607520569648, "entropy": 21.742922543722486, "entropy_coeff": 0.01, "grad_gnorm": 1.253182294988443}, "model": {}, "num_grad_updates_lifetime": 18045.5, "diff_num_grad_updates_vs_sampler_policy": 18044.5}}, "num_env_steps_sampled": 21230253, "num_env_steps_trained": 21230253, "num_agent_steps_sampled": 21230253, "num_agent_steps_trained": 21230253}, "sampler_results": {"episode_reward_max": 68.78036689758301, "episode_reward_min": -0.702392578125, "episode_reward_mean": 10.044501695476594, "episode_len_mean": 498.6475409836066, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.044501695476594, "rewards/0_min": -0.702392578125, "rewards/0_max": 68.78036689758301, "rewards/1_mean": 10.044501695476594, "rewards/1_min": -0.702392578125, "rewards/1_max": 68.78036689758301, "rewards/2_mean": 10.044501695476594, "rewards/2_min": -0.702392578125, "rewards/2_max": 68.78036689758301, "rewards/3_mean": 10.044501695476594, "rewards/3_min": -0.702392578125, "rewards/3_max": 68.78036689758301, "rewards/4_mean": 10.044501695476594, "rewards/4_min": -0.702392578125, "rewards/4_max": 68.78036689758301}, "hist_stats": {"episode_reward": [0.0, 18.04559326171875, 0.20489501953125, 0.0, 0.0, 44.659751892089844, -0.04706573486328125, -0.0518035888671875, -0.0375823974609375, 42.90654373168945, 34.48790740966797, 0.0, 39.90781211853027, 2.8993377685546875, 0.15893173217773438, 0.0, 57.84149169921875, 24.731849670410156, 0.0, 0.0, 0.0, 0.0, 0.0, 2.26348876953125, 0.0, 0.0, -0.017059326171875, 0.0, 17.242950439453125, 0.0, -0.2272796630859375, 45.67494201660156, 56.813751220703125, -0.201690673828125, 0.0, 12.516319274902344, 0.0, 35.283668518066406, 1.9809112548828125, 0.1522674560546875, 0.0, -0.25621795654296875, 0.0, 0.0, 0.0, -0.702392578125, 0.14823150634765625, 11.133441925048828, 0.3513336181640625, -0.128570556640625, 0.0, 0.0148773193359375, 0.0, 33.61106872558594, 7.923961639404297, 0.0, 0.0, 45.03910827636719, 42.50602149963379, 0.0, 47.09049987792969, 18.13654327392578, -0.0897369384765625, 0.0, 0.0, 0.28619384765625, -0.00252532958984375, -0.08990478515625, -0.1278228759765625, 0.0, 4.3886260986328125, 0.0, 0.8987579345703125, 0.0, 0.0, 57.93410110473633, 0.0, 0.0, 0.2564239501953125, 0.0, 0.0, 30.482696533203125, 60.93782997131348, 23.90142822265625, 0.0, 23.41168975830078, 0.0, 5.4088897705078125, 45.922828674316406, 0.0, 4.9320068359375, 56.57121276855469, 0.0, 0.10759735107421875, 2.6721343994140625, 0.01434326171875, 47.763824462890625, 0.0, 0.0, 0.12647628784179688, 0.36244964599609375, 19.564788818359375, 0.0, 11.730201721191406, 0.0, 16.0531005859375, 0.0, 4.8881683349609375, 0.0, 0.0, -0.30861663818359375, 14.761383056640625, 35.717037200927734, 0.0, -0.2273101806640625, 0.0, 20.001670837402344, 0.0, 0.0, 0.0, 68.78036689758301, 26.34105682373047], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 425, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 410, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.680660594050355, "mean_inference_ms": 4.969721617059602, "mean_action_processing_ms": 7.5091215266903495, "mean_env_wait_ms": 11.427972916405302, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 68.78036689758301, "episode_reward_min": -0.702392578125, "episode_reward_mean": 10.044501695476594, "episode_len_mean": 498.6475409836066, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 18.04559326171875, 0.20489501953125, 0.0, 0.0, 44.659751892089844, -0.04706573486328125, -0.0518035888671875, -0.0375823974609375, 42.90654373168945, 34.48790740966797, 0.0, 39.90781211853027, 2.8993377685546875, 0.15893173217773438, 0.0, 57.84149169921875, 24.731849670410156, 0.0, 0.0, 0.0, 0.0, 0.0, 2.26348876953125, 0.0, 0.0, -0.017059326171875, 0.0, 17.242950439453125, 0.0, -0.2272796630859375, 45.67494201660156, 56.813751220703125, -0.201690673828125, 0.0, 12.516319274902344, 0.0, 35.283668518066406, 1.9809112548828125, 0.1522674560546875, 0.0, -0.25621795654296875, 0.0, 0.0, 0.0, -0.702392578125, 0.14823150634765625, 11.133441925048828, 0.3513336181640625, -0.128570556640625, 0.0, 0.0148773193359375, 0.0, 33.61106872558594, 7.923961639404297, 0.0, 0.0, 45.03910827636719, 42.50602149963379, 0.0, 47.09049987792969, 18.13654327392578, -0.0897369384765625, 0.0, 0.0, 0.28619384765625, -0.00252532958984375, -0.08990478515625, -0.1278228759765625, 0.0, 4.3886260986328125, 0.0, 0.8987579345703125, 0.0, 0.0, 57.93410110473633, 0.0, 0.0, 0.2564239501953125, 0.0, 0.0, 30.482696533203125, 60.93782997131348, 23.90142822265625, 0.0, 23.41168975830078, 0.0, 5.4088897705078125, 45.922828674316406, 0.0, 4.9320068359375, 56.57121276855469, 0.0, 0.10759735107421875, 2.6721343994140625, 0.01434326171875, 47.763824462890625, 0.0, 0.0, 0.12647628784179688, 0.36244964599609375, 19.564788818359375, 0.0, 11.730201721191406, 0.0, 16.0531005859375, 0.0, 4.8881683349609375, 0.0, 0.0, -0.30861663818359375, 14.761383056640625, 35.717037200927734, 0.0, -0.2273101806640625, 0.0, 20.001670837402344, 0.0, 0.0, 0.0, 68.78036689758301, 26.34105682373047], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 425, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 410, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.680660594050355, "mean_inference_ms": 4.969721617059602, "mean_action_processing_ms": 7.5091215266903495, "mean_env_wait_ms": 11.427972916405302, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21230253, "num_agent_steps_trained": 21230253, "num_env_steps_sampled": 21230253, "num_env_steps_trained": 21230253, "num_env_steps_sampled_this_iter": 60835, "num_env_steps_trained_this_iter": 60835, "timesteps_total": 21230253, "num_steps_trained_this_iter": 60835, "agent_timesteps_total": 21230253, "timers": {"training_iteration_time_ms": 47389.334, "load_time_ms": 49.031, "load_throughput": 1236441.271, "learn_time_ms": 26882.37, "learn_throughput": 2255.17, "synch_weights_time_ms": 7.98}, "counters": {"num_env_steps_sampled": 21230253, "num_env_steps_trained": 21230253, "num_agent_steps_sampled": 21230253, "num_agent_steps_trained": 21230253}, "done": false, "episodes_total": 42990, "training_iteration": 350, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-45-44", "timestamp": 1735109144, "time_this_iter_s": 47.23233389854431, "time_total_s": 10252.57748055458, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B51030>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C703A0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1395.447581768036, "timesteps_since_restore": 0, "iterations_since_restore": 29, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.50909090909091, "ram_util_percent": 96.00454545454545}}
{"custom_metrics": {"rewards/0_mean": 10.536593129557948, "rewards/0_min": -0.61151123046875, "rewards/0_max": 78.5230484008789, "rewards/1_mean": 10.536593129557948, "rewards/1_min": -0.61151123046875, "rewards/1_max": 78.5230484008789, "rewards/2_mean": 10.536593129557948, "rewards/2_min": -0.61151123046875, "rewards/2_max": 78.5230484008789, "rewards/3_mean": 10.536593129557948, "rewards/3_min": -0.61151123046875, "rewards/3_max": 78.5230484008789, "rewards/4_mean": 10.536593129557948, "rewards/4_min": -0.61151123046875, "rewards/4_max": 78.5230484008789}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.052915584782345426, "policy_loss": 0.00023103070534056142, "vf_loss": 0.16053567074298386, "vf_explained_var": 0.9862836903995937, "kl": 0.010886610595745937, "entropy": 21.423342530689542, "entropy_coeff": 0.01, "grad_gnorm": 1.5201001381590253}, "model": {}, "num_grad_updates_lifetime": 18675.5, "diff_num_grad_updates_vs_sampler_policy": 18674.5}}, "num_env_steps_sampled": 21291244, "num_env_steps_trained": 21291244, "num_agent_steps_sampled": 21291244, "num_agent_steps_trained": 21291244}, "sampler_results": {"episode_reward_max": 78.5230484008789, "episode_reward_min": -0.61151123046875, "episode_reward_mean": 10.536593129557948, "episode_len_mean": 491.86290322580646, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.536593129557948, "rewards/0_min": -0.61151123046875, "rewards/0_max": 78.5230484008789, "rewards/1_mean": 10.536593129557948, "rewards/1_min": -0.61151123046875, "rewards/1_max": 78.5230484008789, "rewards/2_mean": 10.536593129557948, "rewards/2_min": -0.61151123046875, "rewards/2_max": 78.5230484008789, "rewards/3_mean": 10.536593129557948, "rewards/3_min": -0.61151123046875, "rewards/3_max": 78.5230484008789, "rewards/4_mean": 10.536593129557948, "rewards/4_min": -0.61151123046875, "rewards/4_max": 78.5230484008789}, "hist_stats": {"episode_reward": [78.5230484008789, 3.8592529296875, 0.0, 0.0, 0.0, 1.0414581298828125, 4.183174133300781, 38.3748779296875, 0.0, 4.512725830078125, 1.3874664306640625, -0.61151123046875, 0.0, 0.0, 29.57801055908203, 65.3931655883789, -0.0361785888671875, 0.0, 10.128166198730469, 0.301361083984375, 18.204490661621094, 0.0, 44.4532585144043, 75.45663452148438, 20.35361099243164, 0.091949462890625, 16.23122787475586, -0.097015380859375, 5.097862243652344, 0.0, 0.0, 52.838918685913086, 0.0, 0.0, 15.39154052734375, 0.0, 0.6880111694335938, -0.13601303100585938, 0.0, 0.0, 0.0030670166015625, 0.0, 0.0, 38.98844909667969, 14.574951171875, 0.4501495361328125, 62.63263702392578, 18.80010223388672, 0.0, 0.0, 0.21612548828125, 0.0, 0.0, -0.08687591552734375, 0.00081634521484375, 0.0, 32.534162521362305, -0.3238677978515625, 0.0, 6.5957794189453125, 44.895599365234375, -0.193756103515625, 0.0, -0.11469268798828125, 0.045623779296875, 0.0, -0.4677886962890625, -0.40444183349609375, 0.0, 0.0, 0.3684196472167969, 21.49010467529297, 25.450340270996094, 0.0, -0.36527252197265625, 21.994796752929688, 0.0, 0.0, 0.0, -0.06278610229492188, 32.48688507080078, 37.4810791015625, 14.726943969726562, 0.0, 0.0, 0.0, 35.32820129394531, 0.014934539794921875, 0.0, 0.0, -0.0936279296875, 0.0, 0.0, 7.362586975097656, 4.458620071411133, 0.0, 19.06816864013672, 0.0, 55.04055976867676, 0.0, 26.648765563964844, -0.1073150634765625, 11.305252075195312, 33.99291229248047, 33.81078338623047, 0.0, 24.6585693359375, 0.3623542785644531, 0.0, 0.0, 45.41656494140625, 62.63493347167969, 0.11920166015625, 34.690399169921875, 55.18679428100586, 0.0, -0.2871551513671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 485, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 411, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 233, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 108, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.675010890991661, "mean_inference_ms": 4.965050880917762, "mean_action_processing_ms": 7.495666282763504, "mean_env_wait_ms": 11.42686632319008, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.5230484008789, "episode_reward_min": -0.61151123046875, "episode_reward_mean": 10.536593129557948, "episode_len_mean": 491.86290322580646, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [78.5230484008789, 3.8592529296875, 0.0, 0.0, 0.0, 1.0414581298828125, 4.183174133300781, 38.3748779296875, 0.0, 4.512725830078125, 1.3874664306640625, -0.61151123046875, 0.0, 0.0, 29.57801055908203, 65.3931655883789, -0.0361785888671875, 0.0, 10.128166198730469, 0.301361083984375, 18.204490661621094, 0.0, 44.4532585144043, 75.45663452148438, 20.35361099243164, 0.091949462890625, 16.23122787475586, -0.097015380859375, 5.097862243652344, 0.0, 0.0, 52.838918685913086, 0.0, 0.0, 15.39154052734375, 0.0, 0.6880111694335938, -0.13601303100585938, 0.0, 0.0, 0.0030670166015625, 0.0, 0.0, 38.98844909667969, 14.574951171875, 0.4501495361328125, 62.63263702392578, 18.80010223388672, 0.0, 0.0, 0.21612548828125, 0.0, 0.0, -0.08687591552734375, 0.00081634521484375, 0.0, 32.534162521362305, -0.3238677978515625, 0.0, 6.5957794189453125, 44.895599365234375, -0.193756103515625, 0.0, -0.11469268798828125, 0.045623779296875, 0.0, -0.4677886962890625, -0.40444183349609375, 0.0, 0.0, 0.3684196472167969, 21.49010467529297, 25.450340270996094, 0.0, -0.36527252197265625, 21.994796752929688, 0.0, 0.0, 0.0, -0.06278610229492188, 32.48688507080078, 37.4810791015625, 14.726943969726562, 0.0, 0.0, 0.0, 35.32820129394531, 0.014934539794921875, 0.0, 0.0, -0.0936279296875, 0.0, 0.0, 7.362586975097656, 4.458620071411133, 0.0, 19.06816864013672, 0.0, 55.04055976867676, 0.0, 26.648765563964844, -0.1073150634765625, 11.305252075195312, 33.99291229248047, 33.81078338623047, 0.0, 24.6585693359375, 0.3623542785644531, 0.0, 0.0, 45.41656494140625, 62.63493347167969, 0.11920166015625, 34.690399169921875, 55.18679428100586, 0.0, -0.2871551513671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 485, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 411, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 233, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 108, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.675010890991661, "mean_inference_ms": 4.965050880917762, "mean_action_processing_ms": 7.495666282763504, "mean_env_wait_ms": 11.42686632319008, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21291244, "num_agent_steps_trained": 21291244, "num_env_steps_sampled": 21291244, "num_env_steps_trained": 21291244, "num_env_steps_sampled_this_iter": 60991, "num_env_steps_trained_this_iter": 60991, "timesteps_total": 21291244, "num_steps_trained_this_iter": 60991, "agent_timesteps_total": 21291244, "timers": {"training_iteration_time_ms": 47266.746, "load_time_ms": 48.231, "load_throughput": 1257258.87, "learn_time_ms": 26744.108, "learn_throughput": 2267.359, "synch_weights_time_ms": 7.979}, "counters": {"num_env_steps_sampled": 21291244, "num_env_steps_trained": 21291244, "num_agent_steps_sampled": 21291244, "num_agent_steps_trained": 21291244}, "done": false, "episodes_total": 43114, "training_iteration": 351, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-46-30", "timestamp": 1735109190, "time_this_iter_s": 45.15389394760132, "time_total_s": 10297.731374502182, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A59300>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1440.6014757156372, "timesteps_since_restore": 0, "iterations_since_restore": 30, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 19.9140625, "ram_util_percent": 95.7046875}}
{"custom_metrics": {"rewards/0_mean": 11.275563930108294, "rewards/0_min": -0.6441497802734375, "rewards/0_max": 83.73494338989258, "rewards/1_mean": 11.275563930108294, "rewards/1_min": -0.6441497802734375, "rewards/1_max": 83.73494338989258, "rewards/2_mean": 11.275563930108294, "rewards/2_min": -0.6441497802734375, "rewards/2_max": 83.73494338989258, "rewards/3_mean": 11.275563930108294, "rewards/3_min": -0.6441497802734375, "rewards/3_max": 83.73494338989258, "rewards/4_mean": 11.275563930108294, "rewards/4_min": -0.6441497802734375, "rewards/4_max": 83.73494338989258}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08011959546083022, "policy_loss": -0.008930168042905511, "vf_loss": 0.13623643094112003, "vf_explained_var": 0.9908453599801139, "kl": 0.013196879666897336, "entropy": 20.809395402575294, "entropy_coeff": 0.01, "grad_gnorm": 1.474775202170251}, "model": {}, "num_grad_updates_lifetime": 19305.5, "diff_num_grad_updates_vs_sampler_policy": 19304.5}}, "num_env_steps_sampled": 21352089, "num_env_steps_trained": 21352089, "num_agent_steps_sampled": 21352089, "num_agent_steps_trained": 21352089}, "sampler_results": {"episode_reward_max": 83.73494338989258, "episode_reward_min": -0.6441497802734375, "episode_reward_mean": 11.275563930108294, "episode_len_mean": 494.6747967479675, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.275563930108294, "rewards/0_min": -0.6441497802734375, "rewards/0_max": 83.73494338989258, "rewards/1_mean": 11.275563930108294, "rewards/1_min": -0.6441497802734375, "rewards/1_max": 83.73494338989258, "rewards/2_mean": 11.275563930108294, "rewards/2_min": -0.6441497802734375, "rewards/2_max": 83.73494338989258, "rewards/3_mean": 11.275563930108294, "rewards/3_min": -0.6441497802734375, "rewards/3_max": 83.73494338989258, "rewards/4_mean": 11.275563930108294, "rewards/4_min": -0.6441497802734375, "rewards/4_max": 83.73494338989258}, "hist_stats": {"episode_reward": [0.0, 0.0, 47.673118591308594, 0.0, 36.963134765625, -0.41121673583984375, 0.0, 18.494178771972656, 0.0, 0.0, -0.0003662109375, 0.0, 12.061164855957031, 70.71295928955078, 15.6484375, 0.0, 0.0, 3.2504119873046875, 0.0, 0.0, -0.203857421875, 0.0, 0.0, -0.2042694091796875, 59.83937072753906, 24.386680603027344, 0.0, 0.0, 0.0, -0.13055419921875, 0.0, -0.3225555419921875, 0.06461334228515625, 65.38766860961914, 22.366378784179688, 32.787811279296875, 0.0, 0.0, 0.46915435791015625, -0.11226654052734375, 41.533042907714844, 56.16620635986328, 0.0457305908203125, 0.144927978515625, 0.0, 7.860687255859375, 0.0, 0.0, 59.53533172607422, 1.8723526000976562, 12.752174377441406, 0.0, 0.0, 66.54668807983398, -0.0294036865234375, 7.365896224975586, 0.0, 35.95603561401367, 74.14608764648438, 0.0, 0.0, 0.222412109375, 0.11304473876953125, 42.92460250854492, -0.289093017578125, 1.5325546264648438, 51.12192153930664, 0.7029647827148438, 28.959741592407227, 0.0, 0.6515350341796875, -0.01422119140625, 0.0, 0.0, 22.63690185546875, 0.0, 0.0, 27.774322509765625, 40.88008117675781, 54.00611877441406, 0.0, 0.0, 9.169570922851562, 0.0, -0.4741363525390625, 0.0, 0.0, -0.0527801513671875, 20.619308471679688, 29.904464721679688, -0.6441497802734375, 0.0, 0.29315185546875, -0.2824134826660156, 4.080352783203125, 0.0, 54.134521484375, 44.188819885253906, -0.01416015625, -0.3092803955078125, 0.0, 0.0, 0.0, 6.8182373046875, 0.0, 83.73494338989258, 0.0, 0.0, -0.166534423828125, 0.22670745849609375, 0.6680068969726562, 0.592742919921875, 21.37256622314453, 25.88219451904297, 0.0, 10.608257293701172, 13.726505279541016, 18.978824615478516, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 444, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 170, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 231, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.658292921981408, "mean_inference_ms": 4.967406843597201, "mean_action_processing_ms": 7.476646381133082, "mean_env_wait_ms": 11.421151415520907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 83.73494338989258, "episode_reward_min": -0.6441497802734375, "episode_reward_mean": 11.275563930108294, "episode_len_mean": 494.6747967479675, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 47.673118591308594, 0.0, 36.963134765625, -0.41121673583984375, 0.0, 18.494178771972656, 0.0, 0.0, -0.0003662109375, 0.0, 12.061164855957031, 70.71295928955078, 15.6484375, 0.0, 0.0, 3.2504119873046875, 0.0, 0.0, -0.203857421875, 0.0, 0.0, -0.2042694091796875, 59.83937072753906, 24.386680603027344, 0.0, 0.0, 0.0, -0.13055419921875, 0.0, -0.3225555419921875, 0.06461334228515625, 65.38766860961914, 22.366378784179688, 32.787811279296875, 0.0, 0.0, 0.46915435791015625, -0.11226654052734375, 41.533042907714844, 56.16620635986328, 0.0457305908203125, 0.144927978515625, 0.0, 7.860687255859375, 0.0, 0.0, 59.53533172607422, 1.8723526000976562, 12.752174377441406, 0.0, 0.0, 66.54668807983398, -0.0294036865234375, 7.365896224975586, 0.0, 35.95603561401367, 74.14608764648438, 0.0, 0.0, 0.222412109375, 0.11304473876953125, 42.92460250854492, -0.289093017578125, 1.5325546264648438, 51.12192153930664, 0.7029647827148438, 28.959741592407227, 0.0, 0.6515350341796875, -0.01422119140625, 0.0, 0.0, 22.63690185546875, 0.0, 0.0, 27.774322509765625, 40.88008117675781, 54.00611877441406, 0.0, 0.0, 9.169570922851562, 0.0, -0.4741363525390625, 0.0, 0.0, -0.0527801513671875, 20.619308471679688, 29.904464721679688, -0.6441497802734375, 0.0, 0.29315185546875, -0.2824134826660156, 4.080352783203125, 0.0, 54.134521484375, 44.188819885253906, -0.01416015625, -0.3092803955078125, 0.0, 0.0, 0.0, 6.8182373046875, 0.0, 83.73494338989258, 0.0, 0.0, -0.166534423828125, 0.22670745849609375, 0.6680068969726562, 0.592742919921875, 21.37256622314453, 25.88219451904297, 0.0, 10.608257293701172, 13.726505279541016, 18.978824615478516, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 444, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 170, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 231, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.658292921981408, "mean_inference_ms": 4.967406843597201, "mean_action_processing_ms": 7.476646381133082, "mean_env_wait_ms": 11.421151415520907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21352089, "num_agent_steps_trained": 21352089, "num_env_steps_sampled": 21352089, "num_env_steps_trained": 21352089, "num_env_steps_sampled_this_iter": 60845, "num_env_steps_trained_this_iter": 60845, "timesteps_total": 21352089, "num_steps_trained_this_iter": 60845, "agent_timesteps_total": 21352089, "timers": {"training_iteration_time_ms": 47332.62, "load_time_ms": 48.224, "load_throughput": 1257579.105, "learn_time_ms": 26754.808, "learn_throughput": 2266.71, "synch_weights_time_ms": 9.065}, "counters": {"num_env_steps_sampled": 21352089, "num_env_steps_trained": 21352089, "num_agent_steps_sampled": 21352089, "num_agent_steps_trained": 21352089}, "done": false, "episodes_total": 43237, "training_iteration": 352, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-47-17", "timestamp": 1735109237, "time_this_iter_s": 47.06163311004639, "time_total_s": 10344.793007612228, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE5330>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C73910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1487.6631088256836, "timesteps_since_restore": 0, "iterations_since_restore": 31, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.954545454545457, "ram_util_percent": 96.0}}
{"custom_metrics": {"rewards/0_mean": 8.120858900008663, "rewards/0_min": -1.3061676025390625, "rewards/0_max": 68.27364540100098, "rewards/1_mean": 8.120858900008663, "rewards/1_min": -1.3061676025390625, "rewards/1_max": 68.27364540100098, "rewards/2_mean": 8.120858900008663, "rewards/2_min": -1.3061676025390625, "rewards/2_max": 68.27364540100098, "rewards/3_mean": 8.120858900008663, "rewards/3_min": -1.3061676025390625, "rewards/3_max": 68.27364540100098, "rewards/4_mean": 8.120858900008663, "rewards/4_min": -1.3061676025390625, "rewards/4_max": 68.27364540100098}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11966295886507844, "policy_loss": -0.01005793743691082, "vf_loss": 0.12309885106626012, "vf_explained_var": 0.9646330926862974, "kl": 0.010785010635911946, "entropy": 23.32498667580741, "entropy_coeff": 0.01, "grad_gnorm": 1.3676297574762315}, "model": {}, "num_grad_updates_lifetime": 19935.5, "diff_num_grad_updates_vs_sampler_policy": 19934.5}}, "num_env_steps_sampled": 21413010, "num_env_steps_trained": 21413010, "num_agent_steps_sampled": 21413010, "num_agent_steps_trained": 21413010}, "sampler_results": {"episode_reward_max": 68.27364540100098, "episode_reward_min": -1.3061676025390625, "episode_reward_mean": 8.120858900008663, "episode_len_mean": 491.2983870967742, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.120858900008663, "rewards/0_min": -1.3061676025390625, "rewards/0_max": 68.27364540100098, "rewards/1_mean": 8.120858900008663, "rewards/1_min": -1.3061676025390625, "rewards/1_max": 68.27364540100098, "rewards/2_mean": 8.120858900008663, "rewards/2_min": -1.3061676025390625, "rewards/2_max": 68.27364540100098, "rewards/3_mean": 8.120858900008663, "rewards/3_min": -1.3061676025390625, "rewards/3_max": 68.27364540100098, "rewards/4_mean": 8.120858900008663, "rewards/4_min": -1.3061676025390625, "rewards/4_max": 68.27364540100098}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 22.847915649414062, -0.18967437744140625, 61.09906768798828, -0.07940673828125, 0.089141845703125, 2.7303314208984375, 0.0, 23.155757904052734, 0.0, 0.0, 0.0, 28.302322387695312, 24.330902099609375, 12.03428840637207, 0.0, 9.765899658203125, 0.0, 3.868988037109375, -0.1360015869140625, 7.887678146362305, -0.661407470703125, 0.0, 56.34333801269531, -0.1763458251953125, 0.0, 0.0, -0.4211883544921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012603759765625, -1.282501220703125, 0.0, 0.0, 0.0, 0.0, 0.45035552978515625, 0.0, 0.0, 36.03107452392578, 0.0, 0.0, 0.0, 9.81484603881836, 0.1301727294921875, 3.4024295806884766, 9.93069839477539, 35.47343444824219, -0.04145050048828125, 0.0, 23.044883728027344, -0.027130126953125, -0.37792205810546875, 49.84645080566406, 0.0, 0.7517852783203125, 0.0, 0.0, 9.641525268554688, 0.0211029052734375, 0.0, -1.3061676025390625, 0.0, 0.0, 56.85932159423828, 0.0, 15.648521423339844, 0.0, 0.0, -0.26171875, 5.806861877441406, -0.15770721435546875, 0.1193695068359375, 0.0, 4.86883544921875, 0.0, 0.0, 35.79133224487305, -0.131072998046875, 0.0, 34.26123809814453, 0.0, 0.0, 2.1824073791503906, 60.46532440185547, 68.27364540100098, 0.0, 58.46288299560547, 62.66188049316406, 0.0, 0.0, 0.0, 3.90899658203125, 0.0, -0.3074798583984375, 33.74864959716797, 0.0, -0.186859130859375, 9.411056518554688, -0.0358734130859375, 13.412147521972656, 17.94426727294922, 0.0, 0.0, 0.0, 43.64723205566406, 0.26590728759765625, 0.0, 0.0, 0.0, 0.0, -0.167938232421875, 40.1839599609375, 0.0, 14.003517150878906], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 190, 500, 500, 500, 500, 500, 199, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 269, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 484, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.64968963014692, "mean_inference_ms": 4.968352754075883, "mean_action_processing_ms": 7.466957492319631, "mean_env_wait_ms": 11.415211340680951, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 68.27364540100098, "episode_reward_min": -1.3061676025390625, "episode_reward_mean": 8.120858900008663, "episode_len_mean": 491.2983870967742, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 22.847915649414062, -0.18967437744140625, 61.09906768798828, -0.07940673828125, 0.089141845703125, 2.7303314208984375, 0.0, 23.155757904052734, 0.0, 0.0, 0.0, 28.302322387695312, 24.330902099609375, 12.03428840637207, 0.0, 9.765899658203125, 0.0, 3.868988037109375, -0.1360015869140625, 7.887678146362305, -0.661407470703125, 0.0, 56.34333801269531, -0.1763458251953125, 0.0, 0.0, -0.4211883544921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012603759765625, -1.282501220703125, 0.0, 0.0, 0.0, 0.0, 0.45035552978515625, 0.0, 0.0, 36.03107452392578, 0.0, 0.0, 0.0, 9.81484603881836, 0.1301727294921875, 3.4024295806884766, 9.93069839477539, 35.47343444824219, -0.04145050048828125, 0.0, 23.044883728027344, -0.027130126953125, -0.37792205810546875, 49.84645080566406, 0.0, 0.7517852783203125, 0.0, 0.0, 9.641525268554688, 0.0211029052734375, 0.0, -1.3061676025390625, 0.0, 0.0, 56.85932159423828, 0.0, 15.648521423339844, 0.0, 0.0, -0.26171875, 5.806861877441406, -0.15770721435546875, 0.1193695068359375, 0.0, 4.86883544921875, 0.0, 0.0, 35.79133224487305, -0.131072998046875, 0.0, 34.26123809814453, 0.0, 0.0, 2.1824073791503906, 60.46532440185547, 68.27364540100098, 0.0, 58.46288299560547, 62.66188049316406, 0.0, 0.0, 0.0, 3.90899658203125, 0.0, -0.3074798583984375, 33.74864959716797, 0.0, -0.186859130859375, 9.411056518554688, -0.0358734130859375, 13.412147521972656, 17.94426727294922, 0.0, 0.0, 0.0, 43.64723205566406, 0.26590728759765625, 0.0, 0.0, 0.0, 0.0, -0.167938232421875, 40.1839599609375, 0.0, 14.003517150878906], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 190, 500, 500, 500, 500, 500, 199, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 269, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 484, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.64968963014692, "mean_inference_ms": 4.968352754075883, "mean_action_processing_ms": 7.466957492319631, "mean_env_wait_ms": 11.415211340680951, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21413010, "num_agent_steps_trained": 21413010, "num_env_steps_sampled": 21413010, "num_env_steps_trained": 21413010, "num_env_steps_sampled_this_iter": 60921, "num_env_steps_trained_this_iter": 60921, "timesteps_total": 21413010, "num_steps_trained_this_iter": 60921, "agent_timesteps_total": 21413010, "timers": {"training_iteration_time_ms": 47186.664, "load_time_ms": 48.218, "load_throughput": 1258863.81, "learn_time_ms": 26729.684, "learn_throughput": 2270.872, "synch_weights_time_ms": 9.057}, "counters": {"num_env_steps_sampled": 21413010, "num_env_steps_trained": 21413010, "num_agent_steps_sampled": 21413010, "num_agent_steps_trained": 21413010}, "done": false, "episodes_total": 43361, "training_iteration": 353, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-48-03", "timestamp": 1735109283, "time_this_iter_s": 45.845428705215454, "time_total_s": 10390.638436317444, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B53D30>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1533.508537530899, "timesteps_since_restore": 0, "iterations_since_restore": 32, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.478461538461538, "ram_util_percent": 96.78923076923077}}
{"custom_metrics": {"rewards/0_mean": 9.739236831665039, "rewards/0_min": -1.124420166015625, "rewards/0_max": 78.67010498046875, "rewards/1_mean": 9.739236831665039, "rewards/1_min": -1.124420166015625, "rewards/1_max": 78.67010498046875, "rewards/2_mean": 9.739236831665039, "rewards/2_min": -1.124420166015625, "rewards/2_max": 78.67010498046875, "rewards/3_mean": 9.739236831665039, "rewards/3_min": -1.124420166015625, "rewards/3_max": 78.67010498046875, "rewards/4_mean": 9.739236831665039, "rewards/4_min": -1.124420166015625, "rewards/4_max": 78.67010498046875}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.07852564347390499, "policy_loss": 5.945918978088432e-05, "vf_loss": 0.13741685728645986, "vf_explained_var": 0.9763241506505895, "kl": 0.011406120508909226, "entropy": 21.65794000696253, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.5387471125523249}, "model": {}, "num_grad_updates_lifetime": 20588.0, "diff_num_grad_updates_vs_sampler_policy": 20587.0}}, "num_env_steps_sampled": 21474469, "num_env_steps_trained": 21474469, "num_agent_steps_sampled": 21474469, "num_agent_steps_trained": 21474469}, "sampler_results": {"episode_reward_max": 78.67010498046875, "episode_reward_min": -1.124420166015625, "episode_reward_mean": 9.739236831665039, "episode_len_mean": 491.672, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.739236831665039, "rewards/0_min": -1.124420166015625, "rewards/0_max": 78.67010498046875, "rewards/1_mean": 9.739236831665039, "rewards/1_min": -1.124420166015625, "rewards/1_max": 78.67010498046875, "rewards/2_mean": 9.739236831665039, "rewards/2_min": -1.124420166015625, "rewards/2_max": 78.67010498046875, "rewards/3_mean": 9.739236831665039, "rewards/3_min": -1.124420166015625, "rewards/3_max": 78.67010498046875, "rewards/4_mean": 9.739236831665039, "rewards/4_min": -1.124420166015625, "rewards/4_max": 78.67010498046875}, "hist_stats": {"episode_reward": [0.0, 38.80479431152344, 0.055450439453125, -0.1676788330078125, 0.0, 23.296096801757812, 0.0, -0.0680389404296875, -0.11614227294921875, 0.0, 0.0, 0.0, 0.0, 0.0, 45.959218978881836, -0.28371429443359375, 0.0, 5.390224456787109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6465301513671875, 52.16844177246094, 0.0, 0.0, 25.340576171875, 0.0, 56.52851104736328, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4387664794921875, 0.0, 0.0, 0.0, -0.16666412353515625, -0.3076019287109375, 0.0, 29.76543426513672, 0.46588134765625, 0.0, 23.577289581298828, 57.27098083496094, 15.15615463256836, 0.0, 0.0, 1.0202255249023438, 5.73065185546875, 35.85806655883789, 34.71190643310547, 27.757986068725586, 0.0, 0.0, 4.4598846435546875, 15.629074096679688, 0.695159912109375, 0.0, 20.89971160888672, 28.22983169555664, 0.0, 19.858776092529297, 0.0, 72.7811279296875, 0.0, -0.0670928955078125, 0.06005859375, 0.0, 0.0, -0.29022216796875, -0.03787994384765625, 23.01806640625, 9.580154418945312, 0.4769287109375, 5.595703125, 4.205604553222656, 0.0, 0.0, 0.0, 34.502838134765625, 55.33293914794922, -0.2981719970703125, 0.0, 0.0, -0.5246734619140625, 1.590362548828125, 0.9837570190429688, -0.0380096435546875, 0.0, 45.64274597167969, 6.101112365722656, 0.0, 0.0, 0.0, 25.234817504882812, -0.7779541015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.39361572265625, 0.0, 42.79405975341797, 43.23523712158203, -1.124420166015625, 78.67010498046875, 18.99559211730957, 0.0, 31.345237731933594, 27.104862213134766, -0.576690673828125, 0.0, 31.892662048339844, 0.0, 0.0, 25.170120239257812, 2.6709823608398438, 28.325836181640625, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 467, 500, 500, 500, 500, 500, 500, 500, 500, 316, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 95, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.643623331299827, "mean_inference_ms": 4.967864552236551, "mean_action_processing_ms": 7.457943259270247, "mean_env_wait_ms": 11.405289737179872, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.67010498046875, "episode_reward_min": -1.124420166015625, "episode_reward_mean": 9.739236831665039, "episode_len_mean": 491.672, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 38.80479431152344, 0.055450439453125, -0.1676788330078125, 0.0, 23.296096801757812, 0.0, -0.0680389404296875, -0.11614227294921875, 0.0, 0.0, 0.0, 0.0, 0.0, 45.959218978881836, -0.28371429443359375, 0.0, 5.390224456787109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6465301513671875, 52.16844177246094, 0.0, 0.0, 25.340576171875, 0.0, 56.52851104736328, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4387664794921875, 0.0, 0.0, 0.0, -0.16666412353515625, -0.3076019287109375, 0.0, 29.76543426513672, 0.46588134765625, 0.0, 23.577289581298828, 57.27098083496094, 15.15615463256836, 0.0, 0.0, 1.0202255249023438, 5.73065185546875, 35.85806655883789, 34.71190643310547, 27.757986068725586, 0.0, 0.0, 4.4598846435546875, 15.629074096679688, 0.695159912109375, 0.0, 20.89971160888672, 28.22983169555664, 0.0, 19.858776092529297, 0.0, 72.7811279296875, 0.0, -0.0670928955078125, 0.06005859375, 0.0, 0.0, -0.29022216796875, -0.03787994384765625, 23.01806640625, 9.580154418945312, 0.4769287109375, 5.595703125, 4.205604553222656, 0.0, 0.0, 0.0, 34.502838134765625, 55.33293914794922, -0.2981719970703125, 0.0, 0.0, -0.5246734619140625, 1.590362548828125, 0.9837570190429688, -0.0380096435546875, 0.0, 45.64274597167969, 6.101112365722656, 0.0, 0.0, 0.0, 25.234817504882812, -0.7779541015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.39361572265625, 0.0, 42.79405975341797, 43.23523712158203, -1.124420166015625, 78.67010498046875, 18.99559211730957, 0.0, 31.345237731933594, 27.104862213134766, -0.576690673828125, 0.0, 31.892662048339844, 0.0, 0.0, 25.170120239257812, 2.6709823608398438, 28.325836181640625, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 467, 500, 500, 500, 500, 500, 500, 500, 500, 316, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 95, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.643623331299827, "mean_inference_ms": 4.967864552236551, "mean_action_processing_ms": 7.457943259270247, "mean_env_wait_ms": 11.405289737179872, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21474469, "num_agent_steps_trained": 21474469, "num_env_steps_sampled": 21474469, "num_env_steps_trained": 21474469, "num_env_steps_sampled_this_iter": 61459, "num_env_steps_trained_this_iter": 61459, "timesteps_total": 21474469, "num_steps_trained_this_iter": 61459, "agent_timesteps_total": 21474469, "timers": {"training_iteration_time_ms": 47098.574, "load_time_ms": 47.879, "load_throughput": 1269818.371, "learn_time_ms": 26813.976, "learn_throughput": 2267.389, "synch_weights_time_ms": 9.06}, "counters": {"num_env_steps_sampled": 21474469, "num_env_steps_trained": 21474469, "num_agent_steps_sampled": 21474469, "num_agent_steps_trained": 21474469}, "done": false, "episodes_total": 43486, "training_iteration": 354, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-48-50", "timestamp": 1735109330, "time_this_iter_s": 47.43857145309448, "time_total_s": 10438.077007770538, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0AF20>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C703A0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1580.9471089839935, "timesteps_since_restore": 0, "iterations_since_restore": 33, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.714925373134328, "ram_util_percent": 96.39402985074628}}
{"evaluation": {"episode_reward_max": 7.510520935058594, "episode_reward_min": 7.510520935058594, "episode_reward_mean": 7.510520935058594, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.510520935058594, "rewards/0_min": 7.510520935058594, "rewards/0_max": 7.510520935058594, "rewards/1_mean": 7.510520935058594, "rewards/1_min": 7.510520935058594, "rewards/1_max": 7.510520935058594, "rewards/2_mean": 7.510520935058594, "rewards/2_min": 7.510520935058594, "rewards/2_max": 7.510520935058594, "rewards/3_mean": 7.510520935058594, "rewards/3_min": 7.510520935058594, "rewards/3_max": 7.510520935058594, "rewards/4_mean": 7.510520935058594, "rewards/4_min": 7.510520935058594, "rewards/4_max": 7.510520935058594}, "hist_stats": {"episode_reward": [7.510520935058594], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.654855819131197, "mean_inference_ms": 3.46326174241616, "mean_action_processing_ms": 0.45468016577870196, "mean_env_wait_ms": 5.649549352955867, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 10.569992065429688, "rewards/0_min": -0.9888458251953125, "rewards/0_max": 85.92159652709961, "rewards/1_mean": 10.569992065429688, "rewards/1_min": -0.9888458251953125, "rewards/1_max": 85.92159652709961, "rewards/2_mean": 10.569992065429688, "rewards/2_min": -0.9888458251953125, "rewards/2_max": 85.92159652709961, "rewards/3_mean": 10.569992065429688, "rewards/3_min": -0.9888458251953125, "rewards/3_max": 85.92159652709961, "rewards/4_mean": 10.569992065429688, "rewards/4_min": -0.9888458251953125, "rewards/4_max": 85.92159652709961}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.058046797515144424, "policy_loss": 0.00035304706303461913, "vf_loss": 0.16638861942485655, "vf_explained_var": 0.9767071009628356, "kl": 0.012176072226452922, "entropy": 22.540488270350863, "entropy_coeff": 0.01, "grad_gnorm": 1.4033370076309122}, "model": {}, "num_grad_updates_lifetime": 21240.5, "diff_num_grad_updates_vs_sampler_policy": 21239.5}}, "num_env_steps_sampled": 21535343, "num_env_steps_trained": 21535343, "num_agent_steps_sampled": 21535343, "num_agent_steps_trained": 21535343}, "sampler_results": {"episode_reward_max": 85.92159652709961, "episode_reward_min": -0.9888458251953125, "episode_reward_mean": 10.569992065429688, "episode_len_mean": 494.9105691056911, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.569992065429688, "rewards/0_min": -0.9888458251953125, "rewards/0_max": 85.92159652709961, "rewards/1_mean": 10.569992065429688, "rewards/1_min": -0.9888458251953125, "rewards/1_max": 85.92159652709961, "rewards/2_mean": 10.569992065429688, "rewards/2_min": -0.9888458251953125, "rewards/2_max": 85.92159652709961, "rewards/3_mean": 10.569992065429688, "rewards/3_min": -0.9888458251953125, "rewards/3_max": 85.92159652709961, "rewards/4_mean": 10.569992065429688, "rewards/4_min": -0.9888458251953125, "rewards/4_max": 85.92159652709961}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 11.160293579101562, 74.5074462890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 62.12820053100586, 34.59996032714844, 0.0, 4.0974578857421875, 0.6261787414550781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.25330352783203, -0.5673370361328125, 48.88822937011719, 61.016822814941406, 57.09730529785156, 0.26727294921875, -0.6534576416015625, 19.519088745117188, 17.163360595703125, 0.0, 13.033737182617188, 45.32342529296875, 0.0, 0.01959228515625, 0.0, 0.12981414794921875, 5.2523345947265625, 0.00083160400390625, 0.368804931640625, 36.16487121582031, 24.158546447753906, -0.12945556640625, 0.0, 0.0, 46.95756530761719, 85.92159652709961, 27.761795043945312, 0.01639556884765625, 0.0, 0.0, 0.0, 0.0, 0.0, 10.100128173828125, 2.9155502319335938, 36.84989929199219, 0.0, 10.343673706054688, 0.0, 0.0, 0.02689361572265625, 0.0, 0.0, 4.735790252685547, 11.516571044921875, 0.0, -0.6945915222167969, 0.0, 23.167083740234375, 16.703323364257812, 0.0, 15.729072570800781, 15.300262451171875, 0.14650726318359375, 0.0356597900390625, 0.0, 58.1539306640625, 0.2148590087890625, 15.645843505859375, 0.0, -0.116729736328125, 47.7224235534668, 0.2620735168457031, 0.0, 0.0, -0.0720367431640625, 0.32044219970703125, 0.0, 0.0, 15.693069458007812, 19.631427764892578, 13.342788696289062, 0.0, 0.0, 53.39361572265625, 61.739532470703125, 0.0, 0.0, 14.021713256835938, 0.0, 0.0, 0.0, 24.811054229736328, 0.0, 0.0, 23.876327514648438, 10.716835021972656, 50.60471725463867, -0.9888458251953125, 0.06728744506835938, 0.0, 0.0, -0.1088409423828125, 0.0, 16.467182159423828, -0.24945068359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 319, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 450, 500, 500, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 486, 500, 500, 500, 500, 500, 500, 500, 500, 287, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.634605604885904, "mean_inference_ms": 4.9648179761511395, "mean_action_processing_ms": 7.451580820844528, "mean_env_wait_ms": 11.399655098384258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 85.92159652709961, "episode_reward_min": -0.9888458251953125, "episode_reward_mean": 10.569992065429688, "episode_len_mean": 494.9105691056911, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 11.160293579101562, 74.5074462890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 62.12820053100586, 34.59996032714844, 0.0, 4.0974578857421875, 0.6261787414550781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 53.25330352783203, -0.5673370361328125, 48.88822937011719, 61.016822814941406, 57.09730529785156, 0.26727294921875, -0.6534576416015625, 19.519088745117188, 17.163360595703125, 0.0, 13.033737182617188, 45.32342529296875, 0.0, 0.01959228515625, 0.0, 0.12981414794921875, 5.2523345947265625, 0.00083160400390625, 0.368804931640625, 36.16487121582031, 24.158546447753906, -0.12945556640625, 0.0, 0.0, 46.95756530761719, 85.92159652709961, 27.761795043945312, 0.01639556884765625, 0.0, 0.0, 0.0, 0.0, 0.0, 10.100128173828125, 2.9155502319335938, 36.84989929199219, 0.0, 10.343673706054688, 0.0, 0.0, 0.02689361572265625, 0.0, 0.0, 4.735790252685547, 11.516571044921875, 0.0, -0.6945915222167969, 0.0, 23.167083740234375, 16.703323364257812, 0.0, 15.729072570800781, 15.300262451171875, 0.14650726318359375, 0.0356597900390625, 0.0, 58.1539306640625, 0.2148590087890625, 15.645843505859375, 0.0, -0.116729736328125, 47.7224235534668, 0.2620735168457031, 0.0, 0.0, -0.0720367431640625, 0.32044219970703125, 0.0, 0.0, 15.693069458007812, 19.631427764892578, 13.342788696289062, 0.0, 0.0, 53.39361572265625, 61.739532470703125, 0.0, 0.0, 14.021713256835938, 0.0, 0.0, 0.0, 24.811054229736328, 0.0, 0.0, 23.876327514648438, 10.716835021972656, 50.60471725463867, -0.9888458251953125, 0.06728744506835938, 0.0, 0.0, -0.1088409423828125, 0.0, 16.467182159423828, -0.24945068359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 319, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 450, 500, 500, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 486, 500, 500, 500, 500, 500, 500, 500, 500, 287, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.634605604885904, "mean_inference_ms": 4.9648179761511395, "mean_action_processing_ms": 7.451580820844528, "mean_env_wait_ms": 11.399655098384258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21535343, "num_agent_steps_trained": 21535343, "num_env_steps_sampled": 21535343, "num_env_steps_trained": 21535343, "num_env_steps_sampled_this_iter": 60874, "num_env_steps_trained_this_iter": 60874, "timesteps_total": 21535343, "num_steps_trained_this_iter": 60874, "agent_timesteps_total": 21535343, "timers": {"training_iteration_time_ms": 46878.558, "load_time_ms": 47.87, "load_throughput": 1270798.072, "learn_time_ms": 26725.625, "learn_throughput": 2276.194, "synch_weights_time_ms": 10.454}, "counters": {"num_env_steps_sampled": 21535343, "num_env_steps_trained": 21535343, "num_agent_steps_sampled": 21535343, "num_agent_steps_trained": 21535343}, "done": false, "episodes_total": 43609, "training_iteration": 355, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-49-36", "timestamp": 1735109376, "time_this_iter_s": 45.531094789505005, "time_total_s": 10483.608102560043, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE4A00>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1626.4782037734985, "timesteps_since_restore": 0, "iterations_since_restore": 34, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.8140625, "ram_util_percent": 96.1}}
{"custom_metrics": {"rewards/0_mean": 7.0689940338134765, "rewards/0_min": -1.0283355712890625, "rewards/0_max": 68.55183410644531, "rewards/1_mean": 7.0689940338134765, "rewards/1_min": -1.0283355712890625, "rewards/1_max": 68.55183410644531, "rewards/2_mean": 7.0689940338134765, "rewards/2_min": -1.0283355712890625, "rewards/2_max": 68.55183410644531, "rewards/3_mean": 7.0689940338134765, "rewards/3_min": -1.0283355712890625, "rewards/3_max": 68.55183410644531, "rewards/4_mean": 7.0689940338134765, "rewards/4_min": -1.0283355712890625, "rewards/4_max": 68.55183410644531}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.17954840464616798, "policy_loss": -0.005913011086661191, "vf_loss": 0.06712638350122327, "vf_explained_var": 0.960703990099922, "kl": 0.013713382573850038, "entropy": 24.145602138458738, "entropy_coeff": 0.01, "grad_gnorm": 1.3136874905299574}, "model": {}, "num_grad_updates_lifetime": 21870.5, "diff_num_grad_updates_vs_sampler_policy": 21869.5}}, "num_env_steps_sampled": 21596446, "num_env_steps_trained": 21596446, "num_agent_steps_sampled": 21596446, "num_agent_steps_trained": 21596446}, "sampler_results": {"episode_reward_max": 68.55183410644531, "episode_reward_min": -1.0283355712890625, "episode_reward_mean": 7.0689940338134765, "episode_len_mean": 488.824, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.0689940338134765, "rewards/0_min": -1.0283355712890625, "rewards/0_max": 68.55183410644531, "rewards/1_mean": 7.0689940338134765, "rewards/1_min": -1.0283355712890625, "rewards/1_max": 68.55183410644531, "rewards/2_mean": 7.0689940338134765, "rewards/2_min": -1.0283355712890625, "rewards/2_max": 68.55183410644531, "rewards/3_mean": 7.0689940338134765, "rewards/3_min": -1.0283355712890625, "rewards/3_max": 68.55183410644531, "rewards/4_mean": 7.0689940338134765, "rewards/4_min": -1.0283355712890625, "rewards/4_max": 68.55183410644531}, "hist_stats": {"episode_reward": [0.0, 46.792999267578125, 27.810752868652344, -0.1854400634765625, 0.0, -0.6363754272460938, 0.0, 0.0, 0.0, 0.0, 0.0, 23.128143310546875, -0.02971649169921875, 0.0, 0.00830841064453125, 0.0, 0.03253173828125, 17.27989959716797, 25.913665771484375, 12.95928955078125, 31.899795532226562, 1.35498046875, 0.0, 0.15048980712890625, 10.7220458984375, 0.0, -0.13129425048828125, 0.0, 0.0, 0.08602142333984375, 0.0, 0.6011505126953125, 0.0, 39.20222091674805, 0.0, -0.032073974609375, 0.0, 35.95332336425781, 23.082427978515625, 0.0, 0.0, 0.0, 57.98694610595703, 0.0, -0.7352676391601562, 0.9862403869628906, 0.0, -1.0283355712890625, 0.0, 13.028793334960938, 0.0, 0.0, 1.22552490234375, 41.19999694824219, 10.529006958007812, 0.0, 16.833370208740234, 0.5908966064453125, 42.82232666015625, 0.1448211669921875, 1.0706634521484375, 0.0, 0.0, 0.0, 0.0, 63.052589416503906, 0.0, -0.27202606201171875, 0.0, 0.0, 0.0, 0.1137237548828125, 0.0, 0.0, 0.4207916259765625, 0.0, 17.35357666015625, -0.04627227783203125, 0.0, 0.0, 0.0, 0.0, -0.6469573974609375, 0.0, 0.33278656005859375, 0.0, 0.0, 0.0, 0.0713958740234375, 0.2252044677734375, 0.0, 1.7971954345703125, 0.10695648193359375, 0.0, 3.7622756958007812, -0.1493988037109375, 25.599510192871094, 0.0, 0.0968475341796875, 68.55183410644531, 0.0, 0.0, 16.58852767944336, 59.013092041015625, 0.0, -0.174407958984375, -0.0020599365234375, 0.0, 0.0, 0.0, -0.0121307373046875, 0.0, 0.0, 0.0, 6.99262809753418, 0.0, 13.014373779296875, -0.5848846435546875, 0.02085113525390625, 51.83733367919922, 9.932601928710938, 65.93431854248047, 0.0, 0.07584762573242188, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 414, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 287, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 60, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 175, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.631191638713211, "mean_inference_ms": 4.966654473692501, "mean_action_processing_ms": 7.450774957667352, "mean_env_wait_ms": 11.403252123594351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 68.55183410644531, "episode_reward_min": -1.0283355712890625, "episode_reward_mean": 7.0689940338134765, "episode_len_mean": 488.824, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 46.792999267578125, 27.810752868652344, -0.1854400634765625, 0.0, -0.6363754272460938, 0.0, 0.0, 0.0, 0.0, 0.0, 23.128143310546875, -0.02971649169921875, 0.0, 0.00830841064453125, 0.0, 0.03253173828125, 17.27989959716797, 25.913665771484375, 12.95928955078125, 31.899795532226562, 1.35498046875, 0.0, 0.15048980712890625, 10.7220458984375, 0.0, -0.13129425048828125, 0.0, 0.0, 0.08602142333984375, 0.0, 0.6011505126953125, 0.0, 39.20222091674805, 0.0, -0.032073974609375, 0.0, 35.95332336425781, 23.082427978515625, 0.0, 0.0, 0.0, 57.98694610595703, 0.0, -0.7352676391601562, 0.9862403869628906, 0.0, -1.0283355712890625, 0.0, 13.028793334960938, 0.0, 0.0, 1.22552490234375, 41.19999694824219, 10.529006958007812, 0.0, 16.833370208740234, 0.5908966064453125, 42.82232666015625, 0.1448211669921875, 1.0706634521484375, 0.0, 0.0, 0.0, 0.0, 63.052589416503906, 0.0, -0.27202606201171875, 0.0, 0.0, 0.0, 0.1137237548828125, 0.0, 0.0, 0.4207916259765625, 0.0, 17.35357666015625, -0.04627227783203125, 0.0, 0.0, 0.0, 0.0, -0.6469573974609375, 0.0, 0.33278656005859375, 0.0, 0.0, 0.0, 0.0713958740234375, 0.2252044677734375, 0.0, 1.7971954345703125, 0.10695648193359375, 0.0, 3.7622756958007812, -0.1493988037109375, 25.599510192871094, 0.0, 0.0968475341796875, 68.55183410644531, 0.0, 0.0, 16.58852767944336, 59.013092041015625, 0.0, -0.174407958984375, -0.0020599365234375, 0.0, 0.0, 0.0, -0.0121307373046875, 0.0, 0.0, 0.0, 6.99262809753418, 0.0, 13.014373779296875, -0.5848846435546875, 0.02085113525390625, 51.83733367919922, 9.932601928710938, 65.93431854248047, 0.0, 0.07584762573242188, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 414, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 287, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 60, 500, 500, 500, 500, 500, 500, 500, 500, 167, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 175, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.631191638713211, "mean_inference_ms": 4.966654473692501, "mean_action_processing_ms": 7.450774957667352, "mean_env_wait_ms": 11.403252123594351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21596446, "num_agent_steps_trained": 21596446, "num_env_steps_sampled": 21596446, "num_env_steps_trained": 21596446, "num_env_steps_sampled_this_iter": 61103, "num_env_steps_trained_this_iter": 61103, "timesteps_total": 21596446, "num_steps_trained_this_iter": 61103, "agent_timesteps_total": 21596446, "timers": {"training_iteration_time_ms": 46819.963, "load_time_ms": 47.878, "load_throughput": 1272011.225, "learn_time_ms": 26810.276, "learn_throughput": 2271.577, "synch_weights_time_ms": 10.469}, "counters": {"num_env_steps_sampled": 21596446, "num_env_steps_trained": 21596446, "num_agent_steps_sampled": 21596446, "num_agent_steps_trained": 21596446}, "done": false, "episodes_total": 43734, "training_iteration": 356, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-50-23", "timestamp": 1735109423, "time_this_iter_s": 46.99669122695923, "time_total_s": 10530.604793787003, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B08580>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C73910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1673.4748950004578, "timesteps_since_restore": 0, "iterations_since_restore": 35, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.419696969696968, "ram_util_percent": 96.31666666666666}}
{"custom_metrics": {"rewards/0_mean": 10.60614748698909, "rewards/0_min": -0.83428955078125, "rewards/0_max": 83.90655517578125, "rewards/1_mean": 10.60614748698909, "rewards/1_min": -0.83428955078125, "rewards/1_max": 83.90655517578125, "rewards/2_mean": 10.60614748698909, "rewards/2_min": -0.83428955078125, "rewards/2_max": 83.90655517578125, "rewards/3_mean": 10.60614748698909, "rewards/3_min": -0.83428955078125, "rewards/3_max": 83.90655517578125, "rewards/4_mean": 10.60614748698909, "rewards/4_min": -0.83428955078125, "rewards/4_max": 83.90655517578125}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09116665175077374, "policy_loss": -0.0027015682641557226, "vf_loss": 0.13015062588799212, "vf_explained_var": 0.9828409749364097, "kl": 0.01329820768442005, "entropy": 21.92889357824174, "entropy_coeff": 0.01, "grad_gnorm": 1.3074117586016656}, "model": {}, "num_grad_updates_lifetime": 22500.5, "diff_num_grad_updates_vs_sampler_policy": 22499.5}}, "num_env_steps_sampled": 21657016, "num_env_steps_trained": 21657016, "num_agent_steps_sampled": 21657016, "num_agent_steps_trained": 21657016}, "sampler_results": {"episode_reward_max": 83.90655517578125, "episode_reward_min": -0.83428955078125, "episode_reward_mean": 10.60614748698909, "episode_len_mean": 492.4390243902439, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.60614748698909, "rewards/0_min": -0.83428955078125, "rewards/0_max": 83.90655517578125, "rewards/1_mean": 10.60614748698909, "rewards/1_min": -0.83428955078125, "rewards/1_max": 83.90655517578125, "rewards/2_mean": 10.60614748698909, "rewards/2_min": -0.83428955078125, "rewards/2_max": 83.90655517578125, "rewards/3_mean": 10.60614748698909, "rewards/3_min": -0.83428955078125, "rewards/3_max": 83.90655517578125, "rewards/4_mean": 10.60614748698909, "rewards/4_min": -0.83428955078125, "rewards/4_max": 83.90655517578125}, "hist_stats": {"episode_reward": [0.0, 0.4506378173828125, 0.0, 0.0177001953125, 39.3369140625, 0.0, 39.80052185058594, 0.0, 0.0, 8.420166015625, 0.0, 0.0, 0.0, 28.352325439453125, 0.0, 83.90655517578125, 52.628719329833984, 0.0304412841796875, -0.83428955078125, 44.010459899902344, 0.2685394287109375, 0.0, 0.0, 0.0, 0.0, 0.0, 9.5494384765625, 0.0, -0.0972900390625, 13.67376708984375, 0.0, 0.0, 17.939971923828125, 0.711029052734375, 0.300384521484375, 28.405832290649414, -0.131561279296875, -0.05899238586425781, 0.0, 0.196746826171875, 0.0, 0.0, 10.246200561523438, 0.0675201416015625, 0.0, 0.0, 0.0, 16.251205444335938, 7.1952667236328125, 0.0, -0.0418548583984375, 58.635833740234375, 0.0, 0.0, 1.0758590698242188, 41.95075988769531, 11.393569946289062, 0.0, 0.0, 0.0, 36.329524993896484, 24.22770118713379, 0.0, 69.69188690185547, -0.1531219482421875, -0.00218963623046875, 37.0185546875, 0.3278961181640625, -0.5247802734375, 0.451416015625, 0.0, 67.12033081054688, 50.70672607421875, 0.0, 0.0, -0.1604156494140625, 2.1853694915771484, -0.1654510498046875, 65.28692626953125, 3.4965972900390625, 24.820838928222656, 74.1854476928711, 0.0, 6.57215690612793, -0.0120086669921875, 0.11127471923828125, 0.0, -0.021968841552734375, 0.0, 4.7963104248046875, 0.0, 0.0, 56.249961853027344, 0.0, 0.0, 12.164276123046875, 0.0, 0.0, 68.3969497680664, 0.0, 0.0, 0.0, 64.32237434387207, 0.0, 0.0, 0.0, -0.49773406982421875, 0.0, 0.0, 0.0, 0.0, 25.649612426757812, 0.0, 20.120880126953125, 0.0, 0.0, 20.342056274414062, -0.3958587646484375, 0.0, 58.415771484375, 0.0, -0.1535491943359375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 233, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 231, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 106, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.610155361839352, "mean_inference_ms": 4.967086050702579, "mean_action_processing_ms": 7.444334833318949, "mean_env_wait_ms": 11.407509468560013, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 83.90655517578125, "episode_reward_min": -0.83428955078125, "episode_reward_mean": 10.60614748698909, "episode_len_mean": 492.4390243902439, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.4506378173828125, 0.0, 0.0177001953125, 39.3369140625, 0.0, 39.80052185058594, 0.0, 0.0, 8.420166015625, 0.0, 0.0, 0.0, 28.352325439453125, 0.0, 83.90655517578125, 52.628719329833984, 0.0304412841796875, -0.83428955078125, 44.010459899902344, 0.2685394287109375, 0.0, 0.0, 0.0, 0.0, 0.0, 9.5494384765625, 0.0, -0.0972900390625, 13.67376708984375, 0.0, 0.0, 17.939971923828125, 0.711029052734375, 0.300384521484375, 28.405832290649414, -0.131561279296875, -0.05899238586425781, 0.0, 0.196746826171875, 0.0, 0.0, 10.246200561523438, 0.0675201416015625, 0.0, 0.0, 0.0, 16.251205444335938, 7.1952667236328125, 0.0, -0.0418548583984375, 58.635833740234375, 0.0, 0.0, 1.0758590698242188, 41.95075988769531, 11.393569946289062, 0.0, 0.0, 0.0, 36.329524993896484, 24.22770118713379, 0.0, 69.69188690185547, -0.1531219482421875, -0.00218963623046875, 37.0185546875, 0.3278961181640625, -0.5247802734375, 0.451416015625, 0.0, 67.12033081054688, 50.70672607421875, 0.0, 0.0, -0.1604156494140625, 2.1853694915771484, -0.1654510498046875, 65.28692626953125, 3.4965972900390625, 24.820838928222656, 74.1854476928711, 0.0, 6.57215690612793, -0.0120086669921875, 0.11127471923828125, 0.0, -0.021968841552734375, 0.0, 4.7963104248046875, 0.0, 0.0, 56.249961853027344, 0.0, 0.0, 12.164276123046875, 0.0, 0.0, 68.3969497680664, 0.0, 0.0, 0.0, 64.32237434387207, 0.0, 0.0, 0.0, -0.49773406982421875, 0.0, 0.0, 0.0, 0.0, 25.649612426757812, 0.0, 20.120880126953125, 0.0, 0.0, 20.342056274414062, -0.3958587646484375, 0.0, 58.415771484375, 0.0, -0.1535491943359375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 233, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 231, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 106, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.610155361839352, "mean_inference_ms": 4.967086050702579, "mean_action_processing_ms": 7.444334833318949, "mean_env_wait_ms": 11.407509468560013, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21657016, "num_agent_steps_trained": 21657016, "num_env_steps_sampled": 21657016, "num_env_steps_trained": 21657016, "num_env_steps_sampled_this_iter": 60570, "num_env_steps_trained_this_iter": 60570, "timesteps_total": 21657016, "num_steps_trained_this_iter": 60570, "agent_timesteps_total": 21657016, "timers": {"training_iteration_time_ms": 46949.366, "load_time_ms": 48.995, "load_throughput": 1242290.938, "learn_time_ms": 26769.025, "learn_throughput": 2273.77, "synch_weights_time_ms": 10.475}, "counters": {"num_env_steps_sampled": 21657016, "num_env_steps_trained": 21657016, "num_agent_steps_sampled": 21657016, "num_agent_steps_trained": 21657016}, "done": false, "episodes_total": 43857, "training_iteration": 357, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-51-11", "timestamp": 1735109471, "time_this_iter_s": 47.202056884765625, "time_total_s": 10577.806850671768, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEBEE0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C723B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1720.6769518852234, "timesteps_since_restore": 0, "iterations_since_restore": 36, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.11060606060606, "ram_util_percent": 96.2439393939394}}
{"custom_metrics": {"rewards/0_mean": 13.732388916015625, "rewards/0_min": -0.6884002685546875, "rewards/0_max": 83.20719909667969, "rewards/1_mean": 13.732388916015625, "rewards/1_min": -0.6884002685546875, "rewards/1_max": 83.20719909667969, "rewards/2_mean": 13.732388916015625, "rewards/2_min": -0.6884002685546875, "rewards/2_max": 83.20719909667969, "rewards/3_mean": 13.732388916015625, "rewards/3_min": -0.6884002685546875, "rewards/3_max": 83.20719909667969, "rewards/4_mean": 13.732388916015625, "rewards/4_min": -0.6884002685546875, "rewards/4_max": 83.20719909667969}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.029761360112636807, "policy_loss": 0.0002134579582277169, "vf_loss": 0.16370953261142684, "vf_explained_var": 0.9853497861869751, "kl": 0.011136833589250546, "entropy": 19.424815821269203, "entropy_coeff": 0.01, "grad_gnorm": 1.4466836733004405}, "model": {}, "num_grad_updates_lifetime": 23130.5, "diff_num_grad_updates_vs_sampler_policy": 23129.5}}, "num_env_steps_sampled": 21717903, "num_env_steps_trained": 21717903, "num_agent_steps_sampled": 21717903, "num_agent_steps_trained": 21717903}, "sampler_results": {"episode_reward_max": 83.20719909667969, "episode_reward_min": -0.6884002685546875, "episode_reward_mean": 13.732388916015625, "episode_len_mean": 487.096, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 13.732388916015625, "rewards/0_min": -0.6884002685546875, "rewards/0_max": 83.20719909667969, "rewards/1_mean": 13.732388916015625, "rewards/1_min": -0.6884002685546875, "rewards/1_max": 83.20719909667969, "rewards/2_mean": 13.732388916015625, "rewards/2_min": -0.6884002685546875, "rewards/2_max": 83.20719909667969, "rewards/3_mean": 13.732388916015625, "rewards/3_min": -0.6884002685546875, "rewards/3_max": 83.20719909667969, "rewards/4_mean": 13.732388916015625, "rewards/4_min": -0.6884002685546875, "rewards/4_max": 83.20719909667969}, "hist_stats": {"episode_reward": [0.0, -0.0059051513671875, 15.636238098144531, 0.0, 0.9437599182128906, 0.0, -0.31728363037109375, 15.033332824707031, 0.0, 0.31507110595703125, 29.938690185546875, 64.96647644042969, -0.11284637451171875, 0.0, 24.374595642089844, 0.0, 29.157470703125, 3.641815185546875, 0.0, 0.0, 0.0, 54.478973388671875, 0.0038299560546875, 59.072898864746094, 0.012725830078125, 0.0, 23.615951538085938, 0.0, 0.0, 0.0, -0.07436370849609375, 60.95988464355469, -0.4888763427734375, 0.0, 31.25738525390625, 1.1766510009765625, 58.32893371582031, 9.829246520996094, 0.0, 0.0, 50.73728942871094, 2.3543434143066406, -0.153717041015625, 4.01080322265625, 16.76025390625, 44.55620574951172, 0.0, 0.018482208251953125, 39.508174896240234, -0.2426605224609375, 20.58401107788086, 63.78242111206055, 0.0, -0.40610504150390625, 16.733993530273438, -0.03469085693359375, 0.0, 1.3534393310546875, 0.0, 0.0, 0.0, 0.0, 75.4093246459961, 19.12570571899414, 14.560928344726562, 0.0, 41.768821716308594, -0.0385894775390625, 0.0, -0.252655029296875, 0.0, 0.0, 0.0, 0.0, 16.366376876831055, 48.021270751953125, 5.29217529296875, 0.01004791259765625, 0.0, -0.2747001647949219, 0.1732940673828125, 0.0, 19.22100830078125, 55.96347618103027, 29.353179931640625, 0.0, 0.0, 32.00227355957031, 0.0, 0.0, 27.261884689331055, 18.315948486328125, 34.26348876953125, 36.283958435058594, 0.0, 0.0, 83.20719909667969, 31.798954010009766, 9.413246154785156, 0.1084747314453125, 0.0, 30.505279541015625, 0.0, 0.1553955078125, 33.871002197265625, 0.0, 0.17723846435546875, 21.259628295898438, 0.0, -0.11669158935546875, 0.0, 18.269798278808594, 13.628032684326172, 44.45555114746094, 15.531885147094727, 18.25970458984375, 50.66822814941406, -0.3741912841796875, 0.0, 56.355106353759766, 0.0, 44.37706756591797, 25.451675415039062, 6.100311279296875, -0.6884002685546875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 281, 397, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 181, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 426, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 245, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 150, 500, 207, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599833062464354, "mean_inference_ms": 4.966529583588093, "mean_action_processing_ms": 7.434443405136867, "mean_env_wait_ms": 11.401662524281097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 83.20719909667969, "episode_reward_min": -0.6884002685546875, "episode_reward_mean": 13.732388916015625, "episode_len_mean": 487.096, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, -0.0059051513671875, 15.636238098144531, 0.0, 0.9437599182128906, 0.0, -0.31728363037109375, 15.033332824707031, 0.0, 0.31507110595703125, 29.938690185546875, 64.96647644042969, -0.11284637451171875, 0.0, 24.374595642089844, 0.0, 29.157470703125, 3.641815185546875, 0.0, 0.0, 0.0, 54.478973388671875, 0.0038299560546875, 59.072898864746094, 0.012725830078125, 0.0, 23.615951538085938, 0.0, 0.0, 0.0, -0.07436370849609375, 60.95988464355469, -0.4888763427734375, 0.0, 31.25738525390625, 1.1766510009765625, 58.32893371582031, 9.829246520996094, 0.0, 0.0, 50.73728942871094, 2.3543434143066406, -0.153717041015625, 4.01080322265625, 16.76025390625, 44.55620574951172, 0.0, 0.018482208251953125, 39.508174896240234, -0.2426605224609375, 20.58401107788086, 63.78242111206055, 0.0, -0.40610504150390625, 16.733993530273438, -0.03469085693359375, 0.0, 1.3534393310546875, 0.0, 0.0, 0.0, 0.0, 75.4093246459961, 19.12570571899414, 14.560928344726562, 0.0, 41.768821716308594, -0.0385894775390625, 0.0, -0.252655029296875, 0.0, 0.0, 0.0, 0.0, 16.366376876831055, 48.021270751953125, 5.29217529296875, 0.01004791259765625, 0.0, -0.2747001647949219, 0.1732940673828125, 0.0, 19.22100830078125, 55.96347618103027, 29.353179931640625, 0.0, 0.0, 32.00227355957031, 0.0, 0.0, 27.261884689331055, 18.315948486328125, 34.26348876953125, 36.283958435058594, 0.0, 0.0, 83.20719909667969, 31.798954010009766, 9.413246154785156, 0.1084747314453125, 0.0, 30.505279541015625, 0.0, 0.1553955078125, 33.871002197265625, 0.0, 0.17723846435546875, 21.259628295898438, 0.0, -0.11669158935546875, 0.0, 18.269798278808594, 13.628032684326172, 44.45555114746094, 15.531885147094727, 18.25970458984375, 50.66822814941406, -0.3741912841796875, 0.0, 56.355106353759766, 0.0, 44.37706756591797, 25.451675415039062, 6.100311279296875, -0.6884002685546875], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 281, 397, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 181, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 426, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 245, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 150, 500, 207, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599833062464354, "mean_inference_ms": 4.966529583588093, "mean_action_processing_ms": 7.434443405136867, "mean_env_wait_ms": 11.401662524281097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21717903, "num_agent_steps_trained": 21717903, "num_env_steps_sampled": 21717903, "num_env_steps_trained": 21717903, "num_env_steps_sampled_this_iter": 60887, "num_env_steps_trained_this_iter": 60887, "timesteps_total": 21717903, "num_steps_trained_this_iter": 60887, "agent_timesteps_total": 21717903, "timers": {"training_iteration_time_ms": 46768.248, "load_time_ms": 49.879, "load_throughput": 1220811.824, "learn_time_ms": 26744.039, "learn_throughput": 2276.896, "synch_weights_time_ms": 10.473}, "counters": {"num_env_steps_sampled": 21717903, "num_env_steps_trained": 21717903, "num_agent_steps_sampled": 21717903, "num_agent_steps_trained": 21717903}, "done": false, "episodes_total": 43982, "training_iteration": 358, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-51-56", "timestamp": 1735109516, "time_this_iter_s": 45.57104158401489, "time_total_s": 10623.377892255783, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A93790>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C73910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1766.2479934692383, "timesteps_since_restore": 0, "iterations_since_restore": 37, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.8609375, "ram_util_percent": 96.05625}}
{"custom_metrics": {"rewards/0_mean": 12.069730133306784, "rewards/0_min": -0.66192626953125, "rewards/0_max": 76.14104843139648, "rewards/1_mean": 12.069730133306784, "rewards/1_min": -0.66192626953125, "rewards/1_max": 76.14104843139648, "rewards/2_mean": 12.069730133306784, "rewards/2_min": -0.66192626953125, "rewards/2_max": 76.14104843139648, "rewards/3_mean": 12.069730133306784, "rewards/3_min": -0.66192626953125, "rewards/3_max": 76.14104843139648, "rewards/4_mean": 12.069730133306784, "rewards/4_min": -0.66192626953125, "rewards/4_max": 76.14104843139648}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07644581930150116, "policy_loss": 0.001840313749701073, "vf_loss": 0.14033105941637167, "vf_explained_var": 0.9649573231736819, "kl": 0.012519043598634502, "entropy": 21.925097347441174, "entropy_coeff": 0.01, "grad_gnorm": 1.4637172842427852}, "model": {}, "num_grad_updates_lifetime": 23760.5, "diff_num_grad_updates_vs_sampler_policy": 23759.5}}, "num_env_steps_sampled": 21778301, "num_env_steps_trained": 21778301, "num_agent_steps_sampled": 21778301, "num_agent_steps_trained": 21778301}, "sampler_results": {"episode_reward_max": 76.14104843139648, "episode_reward_min": -0.66192626953125, "episode_reward_mean": 12.069730133306784, "episode_len_mean": 495.0655737704918, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 12.069730133306784, "rewards/0_min": -0.66192626953125, "rewards/0_max": 76.14104843139648, "rewards/1_mean": 12.069730133306784, "rewards/1_min": -0.66192626953125, "rewards/1_max": 76.14104843139648, "rewards/2_mean": 12.069730133306784, "rewards/2_min": -0.66192626953125, "rewards/2_max": 76.14104843139648, "rewards/3_mean": 12.069730133306784, "rewards/3_min": -0.66192626953125, "rewards/3_max": 76.14104843139648, "rewards/4_mean": 12.069730133306784, "rewards/4_min": -0.66192626953125, "rewards/4_max": 76.14104843139648}, "hist_stats": {"episode_reward": [0.0, 0.0, 15.584014892578125, 55.31938171386719, -0.23416900634765625, 0.0, 0.0, 61.79438018798828, 42.584747314453125, 0.0, 60.87571716308594, 0.0, 0.0, 24.283157348632812, 0.1131439208984375, 0.0, 29.124568939208984, 43.42376708984375, -0.66192626953125, 20.70083999633789, 0.0, 15.237342834472656, 0.0, 0.0, 0.0, 0.0, -0.0372314453125, 0.0, -0.27199554443359375, 0.0, 0.0, 0.0, 0.0, 21.159198760986328, 0.0, 0.0, 0.0, 0.0, 0.0, 9.83456802368164, 0.0, 6.287445068359375, 53.48334503173828, 0.0, 1.5062713623046875, 49.259986877441406, -0.6056289672851562, 0.0, 0.0, 0.0, 8.468708038330078, 0.0, 18.162412643432617, 0.0, 0.33873748779296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.24488067626953125, 0.0, 0.0763702392578125, 28.140640258789062, 23.733470916748047, 0.14214324951171875, 0.0, 56.24944305419922, 0.0, -0.28841400146484375, 70.3022575378418, 0.0, 27.85321044921875, 0.0, -0.2010650634765625, 47.89116668701172, 24.858760833740234, 26.567264556884766, 34.52191925048828, 0.0, 0.0, 0.0, 48.308353424072266, 0.0, 56.72196578979492, 33.062570571899414, 0.0, 0.0, 36.67963790893555, 47.08422088623047, 2.821819305419922, -0.37343597412109375, 0.0, 31.494674682617188, 0.0, 0.0, 76.14104843139648, 0.0, 0.23869705200195312, 3.43084716796875, 0.0, 27.345428466796875, 0.0, 6.606300354003906, -0.0458831787109375, 35.46965408325195, 29.041152954101562, 6.6566162109375, 5.8412017822265625, 0.1451416015625, 0.295562744140625, 0.1876983642578125, 46.8552360534668, 0.0, 0.0, 23.473548889160156, 0.1460113525390625, 68.44438171386719, 11.101554870605469, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 193, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 342, 500, 500, 363, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.594215596076092, "mean_inference_ms": 4.96248869145941, "mean_action_processing_ms": 7.434691967408349, "mean_env_wait_ms": 11.39811190790766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.14104843139648, "episode_reward_min": -0.66192626953125, "episode_reward_mean": 12.069730133306784, "episode_len_mean": 495.0655737704918, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 15.584014892578125, 55.31938171386719, -0.23416900634765625, 0.0, 0.0, 61.79438018798828, 42.584747314453125, 0.0, 60.87571716308594, 0.0, 0.0, 24.283157348632812, 0.1131439208984375, 0.0, 29.124568939208984, 43.42376708984375, -0.66192626953125, 20.70083999633789, 0.0, 15.237342834472656, 0.0, 0.0, 0.0, 0.0, -0.0372314453125, 0.0, -0.27199554443359375, 0.0, 0.0, 0.0, 0.0, 21.159198760986328, 0.0, 0.0, 0.0, 0.0, 0.0, 9.83456802368164, 0.0, 6.287445068359375, 53.48334503173828, 0.0, 1.5062713623046875, 49.259986877441406, -0.6056289672851562, 0.0, 0.0, 0.0, 8.468708038330078, 0.0, 18.162412643432617, 0.0, 0.33873748779296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.24488067626953125, 0.0, 0.0763702392578125, 28.140640258789062, 23.733470916748047, 0.14214324951171875, 0.0, 56.24944305419922, 0.0, -0.28841400146484375, 70.3022575378418, 0.0, 27.85321044921875, 0.0, -0.2010650634765625, 47.89116668701172, 24.858760833740234, 26.567264556884766, 34.52191925048828, 0.0, 0.0, 0.0, 48.308353424072266, 0.0, 56.72196578979492, 33.062570571899414, 0.0, 0.0, 36.67963790893555, 47.08422088623047, 2.821819305419922, -0.37343597412109375, 0.0, 31.494674682617188, 0.0, 0.0, 76.14104843139648, 0.0, 0.23869705200195312, 3.43084716796875, 0.0, 27.345428466796875, 0.0, 6.606300354003906, -0.0458831787109375, 35.46965408325195, 29.041152954101562, 6.6566162109375, 5.8412017822265625, 0.1451416015625, 0.295562744140625, 0.1876983642578125, 46.8552360534668, 0.0, 0.0, 23.473548889160156, 0.1460113525390625, 68.44438171386719, 11.101554870605469, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 193, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 342, 500, 500, 363, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.594215596076092, "mean_inference_ms": 4.96248869145941, "mean_action_processing_ms": 7.434691967408349, "mean_env_wait_ms": 11.39811190790766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21778301, "num_agent_steps_trained": 21778301, "num_env_steps_sampled": 21778301, "num_env_steps_trained": 21778301, "num_env_steps_sampled_this_iter": 60398, "num_env_steps_trained_this_iter": 60398, "timesteps_total": 21778301, "num_steps_trained_this_iter": 60398, "agent_timesteps_total": 21778301, "timers": {"training_iteration_time_ms": 46319.136, "load_time_ms": 49.482, "load_throughput": 1230516.798, "learn_time_ms": 26581.381, "learn_throughput": 2290.637, "synch_weights_time_ms": 10.473}, "counters": {"num_env_steps_sampled": 21778301, "num_env_steps_trained": 21778301, "num_agent_steps_sampled": 21778301, "num_agent_steps_trained": 21778301}, "done": false, "episodes_total": 44104, "training_iteration": 359, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-52-42", "timestamp": 1735109562, "time_this_iter_s": 45.268635272979736, "time_total_s": 10668.646527528763, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A5BD90>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE170>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1811.516628742218, "timesteps_since_restore": 0, "iterations_since_restore": 38, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.2125, "ram_util_percent": 95.90312499999999}}
{"evaluation": {"episode_reward_max": 37.36199188232422, "episode_reward_min": 37.36199188232422, "episode_reward_mean": 37.36199188232422, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 37.36199188232422, "rewards/0_min": 37.36199188232422, "rewards/0_max": 37.36199188232422, "rewards/1_mean": 37.36199188232422, "rewards/1_min": 37.36199188232422, "rewards/1_max": 37.36199188232422, "rewards/2_mean": 37.36199188232422, "rewards/2_min": 37.36199188232422, "rewards/2_max": 37.36199188232422, "rewards/3_mean": 37.36199188232422, "rewards/3_min": 37.36199188232422, "rewards/3_max": 37.36199188232422, "rewards/4_mean": 37.36199188232422, "rewards/4_min": 37.36199188232422, "rewards/4_max": 37.36199188232422}, "hist_stats": {"episode_reward": [37.36199188232422], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.669724283978749, "mean_inference_ms": 3.4264384791482185, "mean_action_processing_ms": 0.4550873175527834, "mean_env_wait_ms": 5.828158136189982, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 8.57822917175293, "rewards/0_min": -1.1990814208984375, "rewards/0_max": 79.94697189331055, "rewards/1_mean": 8.57822917175293, "rewards/1_min": -1.1990814208984375, "rewards/1_max": 79.94697189331055, "rewards/2_mean": 8.57822917175293, "rewards/2_min": -1.1990814208984375, "rewards/2_max": 79.94697189331055, "rewards/3_mean": 8.57822917175293, "rewards/3_min": -1.1990814208984375, "rewards/3_max": 79.94697189331055, "rewards/4_mean": 8.57822917175293, "rewards/4_min": -1.1990814208984375, "rewards/4_max": 79.94697189331055}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.14214832288040607, "policy_loss": 0.00421306397696888, "vf_loss": 0.08427676964206277, "vf_explained_var": 0.989118363239147, "kl": 0.012948495459535884, "entropy": 23.129367821304886, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.1366146606096514}, "model": {}, "num_grad_updates_lifetime": 24413.0, "diff_num_grad_updates_vs_sampler_policy": 24412.0}}, "num_env_steps_sampled": 21840015, "num_env_steps_trained": 21840015, "num_agent_steps_sampled": 21840015, "num_agent_steps_trained": 21840015}, "sampler_results": {"episode_reward_max": 79.94697189331055, "episode_reward_min": -1.1990814208984375, "episode_reward_mean": 8.57822917175293, "episode_len_mean": 493.712, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.57822917175293, "rewards/0_min": -1.1990814208984375, "rewards/0_max": 79.94697189331055, "rewards/1_mean": 8.57822917175293, "rewards/1_min": -1.1990814208984375, "rewards/1_max": 79.94697189331055, "rewards/2_mean": 8.57822917175293, "rewards/2_min": -1.1990814208984375, "rewards/2_max": 79.94697189331055, "rewards/3_mean": 8.57822917175293, "rewards/3_min": -1.1990814208984375, "rewards/3_max": 79.94697189331055, "rewards/4_mean": 8.57822917175293, "rewards/4_min": -1.1990814208984375, "rewards/4_max": 79.94697189331055}, "hist_stats": {"episode_reward": [61.64656448364258, 0.0, 19.328567504882812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0290374755859375, -0.215789794921875, 1.6126861572265625, 34.48040008544922, 0.0, -0.07073593139648438, 0.0, 0.0, -0.015705108642578125, 30.396873474121094, 0.38018035888671875, 4.759376525878906, 23.65743064880371, -0.2726593017578125, 0.0, 0.0, -0.11801910400390625, 0.0, 11.899349212646484, -0.1807403564453125, 0.87371826171875, 0.0, 70.1361083984375, 0.034149169921875, 15.957071304321289, 5.925380706787109, 15.312271118164062, 10.880767822265625, 0.0, 24.27435302734375, 0.0, 42.95240020751953, 0.0, 29.78262710571289, 0.0, 0.0, 0.0, 0.0, 0.0, -0.18839263916015625, 0.0, 63.34101486206055, 0.0, -0.42559814453125, 0.0, 5.6963348388671875, 2.4269638061523438, -0.20532608032226562, 0.0, -0.42125701904296875, 27.60467529296875, 0.0, 0.38217926025390625, 0.6709518432617188, 49.840362548828125, 0.0, 0.0, 0.0, 0.0, 0.0, 26.77716064453125, 0.017314910888671875, 0.0, 0.0, -1.1319961547851562, 0.0, 0.0, 8.01141357421875, 4.9759674072265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.685264587402344, 0.0, 0.0, 69.47088623046875, 0.068359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08624267578125, 0.0, 0.0, 0.0, 0.0, 8.302661895751953, 0.0, 0.0, -1.1990814208984375, 0.0, -0.173004150390625, 0.0, 43.6741943359375, 0.0, 45.91776084899902, 41.253517150878906, 0.0, 0.0, 5.4354248046875, 0.1210784912109375, 0.0, 5.5788116455078125, 59.77635192871094, 79.94697189331055, 1.9129295349121094, 6.38641357421875, -0.2823944091796875, -0.3343048095703125, 34.00524139404297, 0.0, 55.82788848876953], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 408, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 127, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 497, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 446, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.600637723294849, "mean_inference_ms": 4.959894057216493, "mean_action_processing_ms": 7.438706377554644, "mean_env_wait_ms": 11.399878140833787, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 79.94697189331055, "episode_reward_min": -1.1990814208984375, "episode_reward_mean": 8.57822917175293, "episode_len_mean": 493.712, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [61.64656448364258, 0.0, 19.328567504882812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0290374755859375, -0.215789794921875, 1.6126861572265625, 34.48040008544922, 0.0, -0.07073593139648438, 0.0, 0.0, -0.015705108642578125, 30.396873474121094, 0.38018035888671875, 4.759376525878906, 23.65743064880371, -0.2726593017578125, 0.0, 0.0, -0.11801910400390625, 0.0, 11.899349212646484, -0.1807403564453125, 0.87371826171875, 0.0, 70.1361083984375, 0.034149169921875, 15.957071304321289, 5.925380706787109, 15.312271118164062, 10.880767822265625, 0.0, 24.27435302734375, 0.0, 42.95240020751953, 0.0, 29.78262710571289, 0.0, 0.0, 0.0, 0.0, 0.0, -0.18839263916015625, 0.0, 63.34101486206055, 0.0, -0.42559814453125, 0.0, 5.6963348388671875, 2.4269638061523438, -0.20532608032226562, 0.0, -0.42125701904296875, 27.60467529296875, 0.0, 0.38217926025390625, 0.6709518432617188, 49.840362548828125, 0.0, 0.0, 0.0, 0.0, 0.0, 26.77716064453125, 0.017314910888671875, 0.0, 0.0, -1.1319961547851562, 0.0, 0.0, 8.01141357421875, 4.9759674072265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.685264587402344, 0.0, 0.0, 69.47088623046875, 0.068359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08624267578125, 0.0, 0.0, 0.0, 0.0, 8.302661895751953, 0.0, 0.0, -1.1990814208984375, 0.0, -0.173004150390625, 0.0, 43.6741943359375, 0.0, 45.91776084899902, 41.253517150878906, 0.0, 0.0, 5.4354248046875, 0.1210784912109375, 0.0, 5.5788116455078125, 59.77635192871094, 79.94697189331055, 1.9129295349121094, 6.38641357421875, -0.2823944091796875, -0.3343048095703125, 34.00524139404297, 0.0, 55.82788848876953], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 236, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 408, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 127, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 497, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 446, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.600637723294849, "mean_inference_ms": 4.959894057216493, "mean_action_processing_ms": 7.438706377554644, "mean_env_wait_ms": 11.399878140833787, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21840015, "num_agent_steps_trained": 21840015, "num_env_steps_sampled": 21840015, "num_env_steps_trained": 21840015, "num_env_steps_sampled_this_iter": 61714, "num_env_steps_trained_this_iter": 61714, "timesteps_total": 21840015, "num_steps_trained_this_iter": 61714, "agent_timesteps_total": 21840015, "timers": {"training_iteration_time_ms": 46421.778, "load_time_ms": 47.766, "load_throughput": 1276548.786, "learn_time_ms": 26695.964, "learn_throughput": 2284.098, "synch_weights_time_ms": 10.473}, "counters": {"num_env_steps_sampled": 21840015, "num_env_steps_trained": 21840015, "num_agent_steps_sampled": 21840015, "num_agent_steps_trained": 21840015}, "done": false, "episodes_total": 44229, "training_iteration": 360, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-53-30", "timestamp": 1735109610, "time_this_iter_s": 48.256754875183105, "time_total_s": 10716.903282403946, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE9510>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1859.7733836174011, "timesteps_since_restore": 0, "iterations_since_restore": 39, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.06029411764706, "ram_util_percent": 95.95441176470587}}
{"custom_metrics": {"rewards/0_mean": 8.920868535195627, "rewards/0_min": -0.7779045104980469, "rewards/0_max": 69.90653228759766, "rewards/1_mean": 8.920868535195627, "rewards/1_min": -0.7779045104980469, "rewards/1_max": 69.90653228759766, "rewards/2_mean": 8.920868535195627, "rewards/2_min": -0.7779045104980469, "rewards/2_max": 69.90653228759766, "rewards/3_mean": 8.920868535195627, "rewards/3_min": -0.7779045104980469, "rewards/3_max": 69.90653228759766, "rewards/4_mean": 8.920868535195627, "rewards/4_min": -0.7779045104980469, "rewards/4_max": 69.90653228759766}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13640737770095704, "policy_loss": 0.006936092814546086, "vf_loss": 0.08378465292561385, "vf_explained_var": 0.987894435439791, "kl": 0.013045664663456144, "entropy": 22.778856462145608, "entropy_coeff": 0.01, "grad_gnorm": 1.1934004677193506}, "model": {}, "num_grad_updates_lifetime": 25065.5, "diff_num_grad_updates_vs_sampler_policy": 25064.5}}, "num_env_steps_sampled": 21900741, "num_env_steps_trained": 21900741, "num_agent_steps_sampled": 21900741, "num_agent_steps_trained": 21900741}, "sampler_results": {"episode_reward_max": 69.90653228759766, "episode_reward_min": -0.7779045104980469, "episode_reward_mean": 8.920868535195627, "episode_len_mean": 489.7258064516129, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.920868535195627, "rewards/0_min": -0.7779045104980469, "rewards/0_max": 69.90653228759766, "rewards/1_mean": 8.920868535195627, "rewards/1_min": -0.7779045104980469, "rewards/1_max": 69.90653228759766, "rewards/2_mean": 8.920868535195627, "rewards/2_min": -0.7779045104980469, "rewards/2_max": 69.90653228759766, "rewards/3_mean": 8.920868535195627, "rewards/3_min": -0.7779045104980469, "rewards/3_max": 69.90653228759766, "rewards/4_mean": 8.920868535195627, "rewards/4_min": -0.7779045104980469, "rewards/4_max": 69.90653228759766}, "hist_stats": {"episode_reward": [-0.32465362548828125, 4.781093597412109, 0.0, 0.7615432739257812, 0.1665191650390625, 26.37079620361328, 0.0, 0.0244293212890625, 28.577133178710938, 0.0, 0.0, 0.0, 0.0, -0.38636016845703125, 0.0, 0.0, 53.91966247558594, 0.0, 0.0, 13.081588745117188, 64.75247955322266, 5.103904724121094, 3.3534679412841797, 0.15689849853515625, 0.0, 0.0, 5.879020690917969, 0.0, 33.24909973144531, 0.5793037414550781, 0.0, 0.0, 0.0, 36.57191467285156, 0.0, 32.354549407958984, 10.25604248046875, 36.217674255371094, 0.09648704528808594, 0.0, 1.9379653930664062, 0.0, 0.0, 0.0, 0.0, 23.66485595703125, -0.08953857421875, 0.0, 0.0, -0.7173080444335938, 0.0, 0.0, 0.0, 0.28342437744140625, 0.0, 0.0996551513671875, 0.20313262939453125, 11.624176025390625, 0.0, 0.15059661865234375, 0.0, 3.44482421875, 0.0, 0.0, 53.197052001953125, 0.0, -0.4301910400390625, 44.12858581542969, -0.01282501220703125, 0.0606231689453125, -0.3242645263671875, 0.0, -0.08541488647460938, 69.90653228759766, 17.739364624023438, 0.0, 0.0, 0.0, 47.8184814453125, 3.406656265258789, 55.52490234375, 11.060859680175781, 0.0, 37.697601318359375, 0.0, 0.999542236328125, -0.7779045104980469, 0.0, 0.0, 0.0800323486328125, 0.0, 0.0, -0.34171295166015625, 0.06993865966796875, 0.0, -0.4828033447265625, 0.0, 0.0, 15.096519470214844, 14.066627502441406, 0.0, 44.58013916015625, 0.0, -0.00034332275390625, 43.16499328613281, 19.34758186340332, 0.165252685546875, 41.309844970703125, -0.5891876220703125, 18.054302215576172, 0.0, 0.0, 0.0, 0.30057525634765625, 25.22673797607422, -0.39525604248046875, 47.102943420410156, 0.029327392578125, 8.10811996459961, 0.0, 11.689273834228516, 54.36860656738281, 0.0, 29.182205200195312], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 205, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 75, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 227, 500, 500, 500, 219, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.597695743066724, "mean_inference_ms": 4.957520646023881, "mean_action_processing_ms": 7.43244982991295, "mean_env_wait_ms": 11.392675495485461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 69.90653228759766, "episode_reward_min": -0.7779045104980469, "episode_reward_mean": 8.920868535195627, "episode_len_mean": 489.7258064516129, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.32465362548828125, 4.781093597412109, 0.0, 0.7615432739257812, 0.1665191650390625, 26.37079620361328, 0.0, 0.0244293212890625, 28.577133178710938, 0.0, 0.0, 0.0, 0.0, -0.38636016845703125, 0.0, 0.0, 53.91966247558594, 0.0, 0.0, 13.081588745117188, 64.75247955322266, 5.103904724121094, 3.3534679412841797, 0.15689849853515625, 0.0, 0.0, 5.879020690917969, 0.0, 33.24909973144531, 0.5793037414550781, 0.0, 0.0, 0.0, 36.57191467285156, 0.0, 32.354549407958984, 10.25604248046875, 36.217674255371094, 0.09648704528808594, 0.0, 1.9379653930664062, 0.0, 0.0, 0.0, 0.0, 23.66485595703125, -0.08953857421875, 0.0, 0.0, -0.7173080444335938, 0.0, 0.0, 0.0, 0.28342437744140625, 0.0, 0.0996551513671875, 0.20313262939453125, 11.624176025390625, 0.0, 0.15059661865234375, 0.0, 3.44482421875, 0.0, 0.0, 53.197052001953125, 0.0, -0.4301910400390625, 44.12858581542969, -0.01282501220703125, 0.0606231689453125, -0.3242645263671875, 0.0, -0.08541488647460938, 69.90653228759766, 17.739364624023438, 0.0, 0.0, 0.0, 47.8184814453125, 3.406656265258789, 55.52490234375, 11.060859680175781, 0.0, 37.697601318359375, 0.0, 0.999542236328125, -0.7779045104980469, 0.0, 0.0, 0.0800323486328125, 0.0, 0.0, -0.34171295166015625, 0.06993865966796875, 0.0, -0.4828033447265625, 0.0, 0.0, 15.096519470214844, 14.066627502441406, 0.0, 44.58013916015625, 0.0, -0.00034332275390625, 43.16499328613281, 19.34758186340332, 0.165252685546875, 41.309844970703125, -0.5891876220703125, 18.054302215576172, 0.0, 0.0, 0.0, 0.30057525634765625, 25.22673797607422, -0.39525604248046875, 47.102943420410156, 0.029327392578125, 8.10811996459961, 0.0, 11.689273834228516, 54.36860656738281, 0.0, 29.182205200195312], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 205, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 75, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 227, 500, 500, 500, 219, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.597695743066724, "mean_inference_ms": 4.957520646023881, "mean_action_processing_ms": 7.43244982991295, "mean_env_wait_ms": 11.392675495485461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21900741, "num_agent_steps_trained": 21900741, "num_env_steps_sampled": 21900741, "num_env_steps_trained": 21900741, "num_env_steps_sampled_this_iter": 60726, "num_env_steps_trained_this_iter": 60726, "timesteps_total": 21900741, "num_steps_trained_this_iter": 60726, "agent_timesteps_total": 21900741, "timers": {"training_iteration_time_ms": 46369.167, "load_time_ms": 47.765, "load_throughput": 1276021.39, "learn_time_ms": 26717.124, "learn_throughput": 2281.297, "synch_weights_time_ms": 9.474}, "counters": {"num_env_steps_sampled": 21900741, "num_env_steps_trained": 21900741, "num_agent_steps_sampled": 21900741, "num_agent_steps_trained": 21900741}, "done": false, "episodes_total": 44353, "training_iteration": 361, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-54-15", "timestamp": 1735109655, "time_this_iter_s": 44.62778162956238, "time_total_s": 10761.531064033508, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE7A30>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1904.4011652469635, "timesteps_since_restore": 0, "iterations_since_restore": 40, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.30634920634921, "ram_util_percent": 95.79365079365084}}
{"custom_metrics": {"rewards/0_mean": 9.613387472261259, "rewards/0_min": -0.5322647094726562, "rewards/0_max": 76.33532333374023, "rewards/1_mean": 9.613387472261259, "rewards/1_min": -0.5322647094726562, "rewards/1_max": 76.33532333374023, "rewards/2_mean": 9.613387472261259, "rewards/2_min": -0.5322647094726562, "rewards/2_max": 76.33532333374023, "rewards/3_mean": 9.613387472261259, "rewards/3_min": -0.5322647094726562, "rewards/3_max": 76.33532333374023, "rewards/4_mean": 9.613387472261259, "rewards/4_min": -0.5322647094726562, "rewards/4_max": 76.33532333374023}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11631567447505418, "policy_loss": -0.010968778112400619, "vf_loss": 0.12741524961496156, "vf_explained_var": 0.9872489528996604, "kl": 0.012721008071601982, "entropy": 23.340615157475547, "entropy_coeff": 0.01, "grad_gnorm": 1.6020329053203264}, "model": {}, "num_grad_updates_lifetime": 25695.5, "diff_num_grad_updates_vs_sampler_policy": 25694.5}}, "num_env_steps_sampled": 21961512, "num_env_steps_trained": 21961512, "num_agent_steps_sampled": 21961512, "num_agent_steps_trained": 21961512}, "sampler_results": {"episode_reward_max": 76.33532333374023, "episode_reward_min": -0.5322647094726562, "episode_reward_mean": 9.613387472261259, "episode_len_mean": 494.0731707317073, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.613387472261259, "rewards/0_min": -0.5322647094726562, "rewards/0_max": 76.33532333374023, "rewards/1_mean": 9.613387472261259, "rewards/1_min": -0.5322647094726562, "rewards/1_max": 76.33532333374023, "rewards/2_mean": 9.613387472261259, "rewards/2_min": -0.5322647094726562, "rewards/2_max": 76.33532333374023, "rewards/3_mean": 9.613387472261259, "rewards/3_min": -0.5322647094726562, "rewards/3_max": 76.33532333374023, "rewards/4_mean": 9.613387472261259, "rewards/4_min": -0.5322647094726562, "rewards/4_max": 76.33532333374023}, "hist_stats": {"episode_reward": [0.0, 13.092910766601562, 0.0, 0.0, 61.74903678894043, 13.562667846679688, -0.18679046630859375, 64.01724243164062, 0.0, 65.92784118652344, 52.236711502075195, 0.0, 0.1120147705078125, 0.0, 0.0, 0.0, 0.13568878173828125, 38.25673294067383, 0.5092315673828125, 41.15043640136719, 0.0, -0.13458251953125, 0.0, 0.0, 42.86199951171875, 0.0, 0.0, 0.0, 0.03284454345703125, 2.0296554565429688, 0.0, 0.0, 0.5456867218017578, 20.49695587158203, -0.033966064453125, 0.0, 0.0, -0.5080718994140625, 0.0, -0.5322647094726562, 0.0, 76.33532333374023, 0.0, 0.0, 0.1887359619140625, 0.0, 0.052276611328125, 0.175933837890625, 0.0, 0.0, 20.727981567382812, 64.75790786743164, 0.0, 6.863277435302734, 0.8122634887695312, 0.0, 20.589447021484375, 0.0, 0.6849365234375, 0.08942413330078125, 0.0, 49.34891891479492, 0.0, 70.9267692565918, 0.0, 61.602264404296875, -0.10182952880859375, 56.862884521484375, 0.0, 0.0, 7.884647369384766, 0.0, 0.0, 46.166221618652344, 1.868062973022461, 0.0555572509765625, 31.48283576965332, 0.200103759765625, 0.15767669677734375, -0.1631317138671875, 12.333656311035156, 0.0, 0.0, 10.805908203125, 0.01019287109375, 0.0, -0.14542388916015625, 0.1317138671875, 22.8050537109375, 0.0, 0.0, 22.805519104003906, 0.0, 0.0, 0.0, 24.00092315673828, 6.704795837402344, 0.0, 0.20006561279296875, 0.0, 0.0193939208984375, 0.0, 2.4671173095703125, 0.0, 0.00140380859375, 26.140708923339844, 0.7573738098144531, -0.12384033203125, 70.34158325195312, 0.0, 0.24997329711914062, 0.0, 0.0, 7.585906982421875, 0.0, 8.643804550170898, 0.0, 0.008392333984375, 0.0, 33.81196594238281, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 417, 500, 500, 500, 500, 500, 500, 500, 327, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 327, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 200, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.603740152256885, "mean_inference_ms": 4.95208078098845, "mean_action_processing_ms": 7.432973186649325, "mean_env_wait_ms": 11.389075315269638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.33532333374023, "episode_reward_min": -0.5322647094726562, "episode_reward_mean": 9.613387472261259, "episode_len_mean": 494.0731707317073, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 13.092910766601562, 0.0, 0.0, 61.74903678894043, 13.562667846679688, -0.18679046630859375, 64.01724243164062, 0.0, 65.92784118652344, 52.236711502075195, 0.0, 0.1120147705078125, 0.0, 0.0, 0.0, 0.13568878173828125, 38.25673294067383, 0.5092315673828125, 41.15043640136719, 0.0, -0.13458251953125, 0.0, 0.0, 42.86199951171875, 0.0, 0.0, 0.0, 0.03284454345703125, 2.0296554565429688, 0.0, 0.0, 0.5456867218017578, 20.49695587158203, -0.033966064453125, 0.0, 0.0, -0.5080718994140625, 0.0, -0.5322647094726562, 0.0, 76.33532333374023, 0.0, 0.0, 0.1887359619140625, 0.0, 0.052276611328125, 0.175933837890625, 0.0, 0.0, 20.727981567382812, 64.75790786743164, 0.0, 6.863277435302734, 0.8122634887695312, 0.0, 20.589447021484375, 0.0, 0.6849365234375, 0.08942413330078125, 0.0, 49.34891891479492, 0.0, 70.9267692565918, 0.0, 61.602264404296875, -0.10182952880859375, 56.862884521484375, 0.0, 0.0, 7.884647369384766, 0.0, 0.0, 46.166221618652344, 1.868062973022461, 0.0555572509765625, 31.48283576965332, 0.200103759765625, 0.15767669677734375, -0.1631317138671875, 12.333656311035156, 0.0, 0.0, 10.805908203125, 0.01019287109375, 0.0, -0.14542388916015625, 0.1317138671875, 22.8050537109375, 0.0, 0.0, 22.805519104003906, 0.0, 0.0, 0.0, 24.00092315673828, 6.704795837402344, 0.0, 0.20006561279296875, 0.0, 0.0193939208984375, 0.0, 2.4671173095703125, 0.0, 0.00140380859375, 26.140708923339844, 0.7573738098144531, -0.12384033203125, 70.34158325195312, 0.0, 0.24997329711914062, 0.0, 0.0, 7.585906982421875, 0.0, 8.643804550170898, 0.0, 0.008392333984375, 0.0, 33.81196594238281, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 417, 500, 500, 500, 500, 500, 500, 500, 327, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 327, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 200, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.603740152256885, "mean_inference_ms": 4.95208078098845, "mean_action_processing_ms": 7.432973186649325, "mean_env_wait_ms": 11.389075315269638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21961512, "num_agent_steps_trained": 21961512, "num_env_steps_sampled": 21961512, "num_env_steps_trained": 21961512, "num_env_steps_sampled_this_iter": 60771, "num_env_steps_trained_this_iter": 60771, "timesteps_total": 21961512, "num_steps_trained_this_iter": 60771, "agent_timesteps_total": 21961512, "timers": {"training_iteration_time_ms": 46366.909, "load_time_ms": 47.767, "load_throughput": 1275815.521, "learn_time_ms": 26633.794, "learn_throughput": 2288.157, "synch_weights_time_ms": 9.58}, "counters": {"num_env_steps_sampled": 21961512, "num_env_steps_trained": 21961512, "num_agent_steps_sampled": 21961512, "num_agent_steps_trained": 21961512}, "done": false, "episodes_total": 44476, "training_iteration": 362, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-55-02", "timestamp": 1735109702, "time_this_iter_s": 47.04231905937195, "time_total_s": 10808.57338309288, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE5C90>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1951.4434843063354, "timesteps_since_restore": 0, "iterations_since_restore": 41, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.3969696969697, "ram_util_percent": 96.23636363636363}}
{"custom_metrics": {"rewards/0_mean": 8.811585821756502, "rewards/0_min": -1.5196113586425781, "rewards/0_max": 82.2041244506836, "rewards/1_mean": 8.811585821756502, "rewards/1_min": -1.5196113586425781, "rewards/1_max": 82.2041244506836, "rewards/2_mean": 8.811585821756502, "rewards/2_min": -1.5196113586425781, "rewards/2_max": 82.2041244506836, "rewards/3_mean": 8.811585821756502, "rewards/3_min": -1.5196113586425781, "rewards/3_max": 82.2041244506836, "rewards/4_mean": 8.811585821756502, "rewards/4_min": -1.5196113586425781, "rewards/4_max": 82.2041244506836}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11211174958026811, "policy_loss": 0.006846581579699728, "vf_loss": 0.11192131812410755, "vf_explained_var": 0.9841911440803891, "kl": 0.013568059067493157, "entropy": 23.15665373120989, "entropy_coeff": 0.01, "grad_gnorm": 1.571542969511615}, "model": {}, "num_grad_updates_lifetime": 26325.5, "diff_num_grad_updates_vs_sampler_policy": 26324.5}}, "num_env_steps_sampled": 22022401, "num_env_steps_trained": 22022401, "num_agent_steps_sampled": 22022401, "num_agent_steps_trained": 22022401}, "sampler_results": {"episode_reward_max": 82.2041244506836, "episode_reward_min": -1.5196113586425781, "episode_reward_mean": 8.811585821756502, "episode_len_mean": 495.0325203252033, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.811585821756502, "rewards/0_min": -1.5196113586425781, "rewards/0_max": 82.2041244506836, "rewards/1_mean": 8.811585821756502, "rewards/1_min": -1.5196113586425781, "rewards/1_max": 82.2041244506836, "rewards/2_mean": 8.811585821756502, "rewards/2_min": -1.5196113586425781, "rewards/2_max": 82.2041244506836, "rewards/3_mean": 8.811585821756502, "rewards/3_min": -1.5196113586425781, "rewards/3_max": 82.2041244506836, "rewards/4_mean": 8.811585821756502, "rewards/4_min": -1.5196113586425781, "rewards/4_max": 82.2041244506836}, "hist_stats": {"episode_reward": [14.278884887695312, -1.0977706909179688, 0.0, 0.0, 0.0, 74.18408203125, -0.5667457580566406, 0.0, 0.07135009765625, 14.850143432617188, -0.12636184692382812, 0.0, 63.479766845703125, 0.408416748046875, 0.0, 0.0, -0.34694671630859375, -0.2089691162109375, -0.21953582763671875, 41.087730407714844, 0.0, -0.1357879638671875, 0.0, 0.0, 0.0, 3.382568359375, 0.30797576904296875, 0.30754852294921875, 0.0, 59.21551513671875, 53.75322723388672, 48.729270935058594, 0.273712158203125, -0.10405731201171875, 0.0, 0.0, 6.994682312011719, 25.190303802490234, 0.0, 0.0, 0.0, 0.0541534423828125, 0.0, 0.0, 0.0, 0.5487518310546875, -0.10800933837890625, -0.2563285827636719, 0.17134857177734375, 12.050079345703125, 29.962081909179688, 2.5601577758789062, 0.8966445922851562, 0.0, 58.01284217834473, 0.3483619689941406, 0.4340362548828125, 0.0, -0.24683761596679688, 46.30168151855469, 0.0, 0.0, -0.40488433837890625, 0.0, 0.0, 0.0, 22.225173950195312, 5.783100128173828, 0.0, 82.2041244506836, 0.0, 39.998565673828125, 0.0, -1.5196113586425781, 0.0, 0.0, 0.0, 0.0, 37.15765380859375, 61.12704277038574, 0.0, 0.0, -0.6640777587890625, 0.0404205322265625, 0.0, 0.0, 0.14630126953125, 0.0, 0.0, 0.0, 8.27838134765625, 0.0257110595703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3787841796875, 3.734375, -0.530364990234375, 55.743194580078125, 0.0, 27.13739013671875, 25.39084243774414, 0.2398529052734375, 0.7067413330078125, 0.0, -0.5649871826171875, 15.518489837646484, 0.0, 0.0, 0.0, 35.536651611328125, 0.0, 4.277378082275391, 50.536346435546875, 0.497406005859375, 35.71208381652832, 20.12786102294922, 0.504669189453125, 0.04247283935546875, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 477, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 201, 500, 500, 500, 500, 500, 383, 328, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.605244692568558, "mean_inference_ms": 4.949719632013815, "mean_action_processing_ms": 7.433568768758469, "mean_env_wait_ms": 11.383995105026953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 82.2041244506836, "episode_reward_min": -1.5196113586425781, "episode_reward_mean": 8.811585821756502, "episode_len_mean": 495.0325203252033, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [14.278884887695312, -1.0977706909179688, 0.0, 0.0, 0.0, 74.18408203125, -0.5667457580566406, 0.0, 0.07135009765625, 14.850143432617188, -0.12636184692382812, 0.0, 63.479766845703125, 0.408416748046875, 0.0, 0.0, -0.34694671630859375, -0.2089691162109375, -0.21953582763671875, 41.087730407714844, 0.0, -0.1357879638671875, 0.0, 0.0, 0.0, 3.382568359375, 0.30797576904296875, 0.30754852294921875, 0.0, 59.21551513671875, 53.75322723388672, 48.729270935058594, 0.273712158203125, -0.10405731201171875, 0.0, 0.0, 6.994682312011719, 25.190303802490234, 0.0, 0.0, 0.0, 0.0541534423828125, 0.0, 0.0, 0.0, 0.5487518310546875, -0.10800933837890625, -0.2563285827636719, 0.17134857177734375, 12.050079345703125, 29.962081909179688, 2.5601577758789062, 0.8966445922851562, 0.0, 58.01284217834473, 0.3483619689941406, 0.4340362548828125, 0.0, -0.24683761596679688, 46.30168151855469, 0.0, 0.0, -0.40488433837890625, 0.0, 0.0, 0.0, 22.225173950195312, 5.783100128173828, 0.0, 82.2041244506836, 0.0, 39.998565673828125, 0.0, -1.5196113586425781, 0.0, 0.0, 0.0, 0.0, 37.15765380859375, 61.12704277038574, 0.0, 0.0, -0.6640777587890625, 0.0404205322265625, 0.0, 0.0, 0.14630126953125, 0.0, 0.0, 0.0, 8.27838134765625, 0.0257110595703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3787841796875, 3.734375, -0.530364990234375, 55.743194580078125, 0.0, 27.13739013671875, 25.39084243774414, 0.2398529052734375, 0.7067413330078125, 0.0, -0.5649871826171875, 15.518489837646484, 0.0, 0.0, 0.0, 35.536651611328125, 0.0, 4.277378082275391, 50.536346435546875, 0.497406005859375, 35.71208381652832, 20.12786102294922, 0.504669189453125, 0.04247283935546875, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 477, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 201, 500, 500, 500, 500, 500, 383, 328, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.605244692568558, "mean_inference_ms": 4.949719632013815, "mean_action_processing_ms": 7.433568768758469, "mean_env_wait_ms": 11.383995105026953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22022401, "num_agent_steps_trained": 22022401, "num_env_steps_sampled": 22022401, "num_env_steps_trained": 22022401, "num_env_steps_sampled_this_iter": 60889, "num_env_steps_trained_this_iter": 60889, "timesteps_total": 22022401, "num_steps_trained_this_iter": 60889, "agent_timesteps_total": 22022401, "timers": {"training_iteration_time_ms": 46468.723, "load_time_ms": 47.878, "load_throughput": 1272809.04, "learn_time_ms": 26605.945, "learn_throughput": 2290.432, "synch_weights_time_ms": 9.773}, "counters": {"num_env_steps_sampled": 22022401, "num_env_steps_trained": 22022401, "num_agent_steps_sampled": 22022401, "num_agent_steps_trained": 22022401}, "done": false, "episodes_total": 44599, "training_iteration": 363, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-55-49", "timestamp": 1735109749, "time_this_iter_s": 46.86564612388611, "time_total_s": 10855.439029216766, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE6AD0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFC70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 1998.3091304302216, "timesteps_since_restore": 0, "iterations_since_restore": 42, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.698484848484846, "ram_util_percent": 96.56212121212121}}
{"custom_metrics": {"rewards/0_mean": 10.058800122094533, "rewards/0_min": -0.6356582641601562, "rewards/0_max": 80.40113830566406, "rewards/1_mean": 10.058800122094533, "rewards/1_min": -0.6356582641601562, "rewards/1_max": 80.40113830566406, "rewards/2_mean": 10.058800122094533, "rewards/2_min": -0.6356582641601562, "rewards/2_max": 80.40113830566406, "rewards/3_mean": 10.058800122094533, "rewards/3_min": -0.6356582641601562, "rewards/3_max": 80.40113830566406, "rewards/4_mean": 10.058800122094533, "rewards/4_min": -0.6356582641601562, "rewards/4_max": 80.40113830566406}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.08576766423225679, "policy_loss": 0.0017925571076813395, "vf_loss": 0.13595291351899505, "vf_explained_var": 0.9857530960330256, "kl": 0.013024585671998837, "entropy": 22.417251123498986, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.7503670136906482}, "model": {}, "num_grad_updates_lifetime": 26978.0, "diff_num_grad_updates_vs_sampler_policy": 26977.0}}, "num_env_steps_sampled": 22083947, "num_env_steps_trained": 22083947, "num_agent_steps_sampled": 22083947, "num_agent_steps_trained": 22083947}, "sampler_results": {"episode_reward_max": 80.40113830566406, "episode_reward_min": -0.6356582641601562, "episode_reward_mean": 10.058800122094533, "episode_len_mean": 488.46031746031747, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.058800122094533, "rewards/0_min": -0.6356582641601562, "rewards/0_max": 80.40113830566406, "rewards/1_mean": 10.058800122094533, "rewards/1_min": -0.6356582641601562, "rewards/1_max": 80.40113830566406, "rewards/2_mean": 10.058800122094533, "rewards/2_min": -0.6356582641601562, "rewards/2_max": 80.40113830566406, "rewards/3_mean": 10.058800122094533, "rewards/3_min": -0.6356582641601562, "rewards/3_max": 80.40113830566406, "rewards/4_mean": 10.058800122094533, "rewards/4_min": -0.6356582641601562, "rewards/4_max": 80.40113830566406}, "hist_stats": {"episode_reward": [-0.246429443359375, -0.55291748046875, 42.92708969116211, 30.119226455688477, 13.64655876159668, 8.807672500610352, 25.897796630859375, 0.0, 11.68768310546875, 28.365711212158203, 54.18009567260742, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14479827880859375, 0.0039215087890625, 0.0, 0.0, 45.89942932128906, 0.0, 8.334213256835938, 0.0, 0.0, 4.2496185302734375, 4.478199005126953, 36.445255279541016, 0.0, 0.0, 0.0, 0.22734832763671875, 9.781387329101562, 43.54051971435547, 0.0, -0.144073486328125, -0.6356582641601562, 26.284164428710938, 0.0, 0.0, -0.37097930908203125, -0.017486572265625, 0.0, -0.018341064453125, 45.38755226135254, 18.337753295898438, 0.0, 5.881561279296875, 0.0, 0.0, 0.0, 0.3616046905517578, 0.0, 0.0, 1.2208251953125, 14.51492691040039, 0.0, 0.036468505859375, 46.16650390625, 71.28706359863281, -0.2359619140625, 0.01214599609375, 0.0, 21.721176147460938, 42.97904968261719, 56.94480514526367, 0.0, 23.527542114257812, 1.928558349609375, 0.0, 32.81015396118164, 5.529853820800781, 20.574886322021484, 0.0, 0.0, -0.11382293701171875, 0.0, 0.0, 58.22138595581055, 80.40113830566406, 69.47258758544922, 0.0, 24.300315856933594, 0.12163543701171875, 0.05309295654296875, 1.2289886474609375, -0.11395263671875, 0.0, 0.0, 0.0, -0.036548614501953125, 0.0, 0.0, 0.121246337890625, 0.0, 70.7139663696289, 35.4936637878418, -0.48645782470703125, 3.935455322265625, 0.0, 0.0, 0.0342559814453125, 45.15918731689453, 0.0, -0.001129150390625, 0.2019805908203125, 1.8280258178710938, 0.004913330078125, 0.5667724609375, 0.7680892944335938, 0.0, 0.8597793579101562, 0.0, 0.0, 0.0, 0.0, 19.380722045898438, -0.0420684814453125, -0.09392166137695312, -0.011444091796875, 53.70928192138672, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 237, 500, 132, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 413, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 426, 500, 500, 500, 500, 500, 500, 500, 183, 500, 359, 500, 500, 500, 500, 345, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599076058853369, "mean_inference_ms": 4.946289227901204, "mean_action_processing_ms": 7.433137962610222, "mean_env_wait_ms": 11.375082257305367, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 80.40113830566406, "episode_reward_min": -0.6356582641601562, "episode_reward_mean": 10.058800122094533, "episode_len_mean": 488.46031746031747, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.246429443359375, -0.55291748046875, 42.92708969116211, 30.119226455688477, 13.64655876159668, 8.807672500610352, 25.897796630859375, 0.0, 11.68768310546875, 28.365711212158203, 54.18009567260742, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14479827880859375, 0.0039215087890625, 0.0, 0.0, 45.89942932128906, 0.0, 8.334213256835938, 0.0, 0.0, 4.2496185302734375, 4.478199005126953, 36.445255279541016, 0.0, 0.0, 0.0, 0.22734832763671875, 9.781387329101562, 43.54051971435547, 0.0, -0.144073486328125, -0.6356582641601562, 26.284164428710938, 0.0, 0.0, -0.37097930908203125, -0.017486572265625, 0.0, -0.018341064453125, 45.38755226135254, 18.337753295898438, 0.0, 5.881561279296875, 0.0, 0.0, 0.0, 0.3616046905517578, 0.0, 0.0, 1.2208251953125, 14.51492691040039, 0.0, 0.036468505859375, 46.16650390625, 71.28706359863281, -0.2359619140625, 0.01214599609375, 0.0, 21.721176147460938, 42.97904968261719, 56.94480514526367, 0.0, 23.527542114257812, 1.928558349609375, 0.0, 32.81015396118164, 5.529853820800781, 20.574886322021484, 0.0, 0.0, -0.11382293701171875, 0.0, 0.0, 58.22138595581055, 80.40113830566406, 69.47258758544922, 0.0, 24.300315856933594, 0.12163543701171875, 0.05309295654296875, 1.2289886474609375, -0.11395263671875, 0.0, 0.0, 0.0, -0.036548614501953125, 0.0, 0.0, 0.121246337890625, 0.0, 70.7139663696289, 35.4936637878418, -0.48645782470703125, 3.935455322265625, 0.0, 0.0, 0.0342559814453125, 45.15918731689453, 0.0, -0.001129150390625, 0.2019805908203125, 1.8280258178710938, 0.004913330078125, 0.5667724609375, 0.7680892944335938, 0.0, 0.8597793579101562, 0.0, 0.0, 0.0, 0.0, 19.380722045898438, -0.0420684814453125, -0.09392166137695312, -0.011444091796875, 53.70928192138672, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 237, 500, 132, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 413, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 426, 500, 500, 500, 500, 500, 500, 500, 183, 500, 359, 500, 500, 500, 500, 345, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.599076058853369, "mean_inference_ms": 4.946289227901204, "mean_action_processing_ms": 7.433137962610222, "mean_env_wait_ms": 11.375082257305367, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22083947, "num_agent_steps_trained": 22083947, "num_env_steps_sampled": 22083947, "num_env_steps_trained": 22083947, "num_env_steps_sampled_this_iter": 61546, "num_env_steps_trained_this_iter": 61546, "timesteps_total": 22083947, "num_steps_trained_this_iter": 61546, "agent_timesteps_total": 22083947, "timers": {"training_iteration_time_ms": 46598.631, "load_time_ms": 47.878, "load_throughput": 1272980.611, "learn_time_ms": 26669.946, "learn_throughput": 2285.261, "synch_weights_time_ms": 9.574}, "counters": {"num_env_steps_sampled": 22083947, "num_env_steps_trained": 22083947, "num_agent_steps_sampled": 22083947, "num_agent_steps_trained": 22083947}, "done": false, "episodes_total": 44725, "training_iteration": 364, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-56-38", "timestamp": 1735109798, "time_this_iter_s": 48.73561906814575, "time_total_s": 10904.174648284912, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEBB50>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2047.0447494983673, "timesteps_since_restore": 0, "iterations_since_restore": 43, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.819117647058825, "ram_util_percent": 96.47058823529412}}
{"evaluation": {"episode_reward_max": 35.785221099853516, "episode_reward_min": 35.785221099853516, "episode_reward_mean": 35.785221099853516, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 35.785221099853516, "rewards/0_min": 35.785221099853516, "rewards/0_max": 35.785221099853516, "rewards/1_mean": 35.785221099853516, "rewards/1_min": 35.785221099853516, "rewards/1_max": 35.785221099853516, "rewards/2_mean": 35.785221099853516, "rewards/2_min": 35.785221099853516, "rewards/2_max": 35.785221099853516, "rewards/3_mean": 35.785221099853516, "rewards/3_min": 35.785221099853516, "rewards/3_max": 35.785221099853516, "rewards/4_mean": 35.785221099853516, "rewards/4_min": 35.785221099853516, "rewards/4_max": 35.785221099853516}, "hist_stats": {"episode_reward": [35.785221099853516], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6678184385539108, "mean_inference_ms": 3.455403168395847, "mean_action_processing_ms": 0.4662863017982495, "mean_env_wait_ms": 6.055919521783516, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 10.405842726792747, "rewards/0_min": -0.6728744506835938, "rewards/0_max": 86.88874435424805, "rewards/1_mean": 10.405842726792747, "rewards/1_min": -0.6728744506835938, "rewards/1_max": 86.88874435424805, "rewards/2_mean": 10.405842726792747, "rewards/2_min": -0.6728744506835938, "rewards/2_max": 86.88874435424805, "rewards/3_mean": 10.405842726792747, "rewards/3_min": -0.6728744506835938, "rewards/3_max": 86.88874435424805, "rewards/4_mean": 10.405842726792747, "rewards/4_min": -0.6728744506835938, "rewards/4_max": 86.88874435424805}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11141942681879588, "policy_loss": -0.0013181438761031522, "vf_loss": 0.12469235886228344, "vf_explained_var": 0.9849860827128093, "kl": 0.009553276463633492, "entropy": 23.5277281443278, "entropy_coeff": 0.01, "grad_gnorm": 1.131325037670987}, "model": {}, "num_grad_updates_lifetime": 27630.5, "diff_num_grad_updates_vs_sampler_policy": 27629.5}}, "num_env_steps_sampled": 22144765, "num_env_steps_trained": 22144765, "num_agent_steps_sampled": 22144765, "num_agent_steps_trained": 22144765}, "sampler_results": {"episode_reward_max": 86.88874435424805, "episode_reward_min": -0.6728744506835938, "episode_reward_mean": 10.405842726792747, "episode_len_mean": 494.4552845528455, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.405842726792747, "rewards/0_min": -0.6728744506835938, "rewards/0_max": 86.88874435424805, "rewards/1_mean": 10.405842726792747, "rewards/1_min": -0.6728744506835938, "rewards/1_max": 86.88874435424805, "rewards/2_mean": 10.405842726792747, "rewards/2_min": -0.6728744506835938, "rewards/2_max": 86.88874435424805, "rewards/3_mean": 10.405842726792747, "rewards/3_min": -0.6728744506835938, "rewards/3_max": 86.88874435424805, "rewards/4_mean": 10.405842726792747, "rewards/4_min": -0.6728744506835938, "rewards/4_max": 86.88874435424805}, "hist_stats": {"episode_reward": [0.08013916015625, -0.2907867431640625, -0.1194000244140625, 0.0, 0.08308029174804688, 3.376922607421875, -0.061557769775390625, -0.4031982421875, 0.0, 0.0, 39.38737487792969, 56.41476821899414, 0.0, -0.6728744506835938, 0.0, 0.0, 0.0, -0.3762664794921875, 0.7189483642578125, 0.0, 0.0, 50.847572326660156, 3.0828170776367188, 0.0, 0.0, 0.0, 1.1658935546875, 0.2557525634765625, 0.0, 0.0, 67.88736534118652, 0.0, 62.80310821533203, 0.0, 0.0, 53.60641098022461, 0.0, 0.0, 70.3379020690918, 0.0831451416015625, -0.504058837890625, 0.0, 80.66484069824219, 0.33758544921875, 0.0, 0.0, -0.13214111328125, 62.74402618408203, -0.003498077392578125, 14.277618408203125, 0.39471435546875, 0.0, 0.0, 0.0, 0.0, 0.00335693359375, 1.7383575439453125, 14.365987777709961, 86.88874435424805, 49.28654479980469, 0.0, 13.360069274902344, 0.1092681884765625, 0.0, 0.0, 23.726966857910156, 0.0, 0.0, 50.42719268798828, -0.06800079345703125, 0.0, -0.14994049072265625, 0.0, -0.130767822265625, 14.637962341308594, 0.0, 32.18173027038574, -0.1717071533203125, -0.25255584716796875, 0.0, 0.0, 0.0, 49.36460876464844, 0.0, 40.50493240356445, 0.0, 17.62706184387207, 15.869037628173828, 0.0, 0.0, 0.101959228515625, 60.350101470947266, 16.197998046875, 0.0, 0.1273651123046875, 0.0, 0.0940704345703125, -0.16873931884765625, 17.951828002929688, 0.0, 10.448211669921875, 0.3478546142578125, 0.0, 0.0, 0.0, 23.570484161376953, 59.484458923339844, 0.0, -0.1971588134765625, 0.2933197021484375, 0.14231109619140625, 0.0, 25.363502502441406, 0.0, -0.2538909912109375, 0.05686187744140625, 29.767135620117188, 0.0, 0.0, 0.04975128173828125, 17.94952392578125, 42.93665313720703, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 431, 500, 500, 500, 500, 500, 500, 500, 484, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 311, 500, 500, 500, 500, 500, 500, 500, 500, 500, 204, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.608946764776649, "mean_inference_ms": 4.951954365077546, "mean_action_processing_ms": 7.4414446318989, "mean_env_wait_ms": 11.389550834359168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 86.88874435424805, "episode_reward_min": -0.6728744506835938, "episode_reward_mean": 10.405842726792747, "episode_len_mean": 494.4552845528455, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.08013916015625, -0.2907867431640625, -0.1194000244140625, 0.0, 0.08308029174804688, 3.376922607421875, -0.061557769775390625, -0.4031982421875, 0.0, 0.0, 39.38737487792969, 56.41476821899414, 0.0, -0.6728744506835938, 0.0, 0.0, 0.0, -0.3762664794921875, 0.7189483642578125, 0.0, 0.0, 50.847572326660156, 3.0828170776367188, 0.0, 0.0, 0.0, 1.1658935546875, 0.2557525634765625, 0.0, 0.0, 67.88736534118652, 0.0, 62.80310821533203, 0.0, 0.0, 53.60641098022461, 0.0, 0.0, 70.3379020690918, 0.0831451416015625, -0.504058837890625, 0.0, 80.66484069824219, 0.33758544921875, 0.0, 0.0, -0.13214111328125, 62.74402618408203, -0.003498077392578125, 14.277618408203125, 0.39471435546875, 0.0, 0.0, 0.0, 0.0, 0.00335693359375, 1.7383575439453125, 14.365987777709961, 86.88874435424805, 49.28654479980469, 0.0, 13.360069274902344, 0.1092681884765625, 0.0, 0.0, 23.726966857910156, 0.0, 0.0, 50.42719268798828, -0.06800079345703125, 0.0, -0.14994049072265625, 0.0, -0.130767822265625, 14.637962341308594, 0.0, 32.18173027038574, -0.1717071533203125, -0.25255584716796875, 0.0, 0.0, 0.0, 49.36460876464844, 0.0, 40.50493240356445, 0.0, 17.62706184387207, 15.869037628173828, 0.0, 0.0, 0.101959228515625, 60.350101470947266, 16.197998046875, 0.0, 0.1273651123046875, 0.0, 0.0940704345703125, -0.16873931884765625, 17.951828002929688, 0.0, 10.448211669921875, 0.3478546142578125, 0.0, 0.0, 0.0, 23.570484161376953, 59.484458923339844, 0.0, -0.1971588134765625, 0.2933197021484375, 0.14231109619140625, 0.0, 25.363502502441406, 0.0, -0.2538909912109375, 0.05686187744140625, 29.767135620117188, 0.0, 0.0, 0.04975128173828125, 17.94952392578125, 42.93665313720703, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 431, 500, 500, 500, 500, 500, 500, 500, 484, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 311, 500, 500, 500, 500, 500, 500, 500, 500, 500, 204, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.608946764776649, "mean_inference_ms": 4.951954365077546, "mean_action_processing_ms": 7.4414446318989, "mean_env_wait_ms": 11.389550834359168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22144765, "num_agent_steps_trained": 22144765, "num_env_steps_sampled": 22144765, "num_env_steps_trained": 22144765, "num_env_steps_sampled_this_iter": 60818, "num_env_steps_trained_this_iter": 60818, "timesteps_total": 22144765, "num_steps_trained_this_iter": 60818, "agent_timesteps_total": 22144765, "timers": {"training_iteration_time_ms": 46703.546, "load_time_ms": 47.993, "load_throughput": 1269808.872, "learn_time_ms": 26643.517, "learn_throughput": 2287.318, "synch_weights_time_ms": 9.179}, "counters": {"num_env_steps_sampled": 22144765, "num_env_steps_trained": 22144765, "num_agent_steps_sampled": 22144765, "num_agent_steps_trained": 22144765}, "done": false, "episodes_total": 44848, "training_iteration": 365, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-57-25", "timestamp": 1735109845, "time_this_iter_s": 46.580227851867676, "time_total_s": 10950.75487613678, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0BC40>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2093.624977350235, "timesteps_since_restore": 0, "iterations_since_restore": 44, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 24.08787878787879, "ram_util_percent": 96.70757575757575}}
{"custom_metrics": {"rewards/0_mean": 8.25681221869684, "rewards/0_min": -0.9245529174804688, "rewards/0_max": 74.33315658569336, "rewards/1_mean": 8.25681221869684, "rewards/1_min": -0.9245529174804688, "rewards/1_max": 74.33315658569336, "rewards/2_mean": 8.25681221869684, "rewards/2_min": -0.9245529174804688, "rewards/2_max": 74.33315658569336, "rewards/3_mean": 8.25681221869684, "rewards/3_min": -0.9245529174804688, "rewards/3_max": 74.33315658569336, "rewards/4_mean": 8.25681221869684, "rewards/4_min": -0.9245529174804688, "rewards/4_max": 74.33315658569336}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13662953942955014, "policy_loss": -0.0005166989523873088, "vf_loss": 0.10693279756159181, "vf_explained_var": 0.9857368365166679, "kl": 0.011745952329568802, "entropy": 24.36402823735797, "entropy_coeff": 0.01, "grad_gnorm": 0.9374091844355303}, "model": {}, "num_grad_updates_lifetime": 28260.5, "diff_num_grad_updates_vs_sampler_policy": 28259.5}}, "num_env_steps_sampled": 22205473, "num_env_steps_trained": 22205473, "num_agent_steps_sampled": 22205473, "num_agent_steps_trained": 22205473}, "sampler_results": {"episode_reward_max": 74.33315658569336, "episode_reward_min": -0.9245529174804688, "episode_reward_mean": 8.25681221869684, "episode_len_mean": 489.5806451612903, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.25681221869684, "rewards/0_min": -0.9245529174804688, "rewards/0_max": 74.33315658569336, "rewards/1_mean": 8.25681221869684, "rewards/1_min": -0.9245529174804688, "rewards/1_max": 74.33315658569336, "rewards/2_mean": 8.25681221869684, "rewards/2_min": -0.9245529174804688, "rewards/2_max": 74.33315658569336, "rewards/3_mean": 8.25681221869684, "rewards/3_min": -0.9245529174804688, "rewards/3_max": 74.33315658569336, "rewards/4_mean": 8.25681221869684, "rewards/4_min": -0.9245529174804688, "rewards/4_max": 74.33315658569336}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.269500732421875, 2.2972793579101562, 21.368194580078125, 0.0, 0.0, 0.0, 0.0, 0.0, 6.2667083740234375, 0.0, 0.0, 73.67794799804688, 0.0, 37.62049865722656, -0.9245529174804688, 0.0, 7.1919097900390625, 0.0, -0.15497589111328125, 0.0, -0.1732025146484375, 0.4195098876953125, 30.02396011352539, 0.0, 21.302879333496094, 0.0, 11.006258010864258, 0.0, 0.0, 0.0, 0.0, -0.0251312255859375, 64.84424591064453, 4.224996566772461, 0.0, 0.0, 22.779373168945312, -0.2746429443359375, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1534423828125, 0.0, 0.0, 0.0, -0.13159942626953125, 44.310035705566406, 0.0, 0.0, 0.0, 0.00640106201171875, 74.33315658569336, 26.507400512695312, 44.89624786376953, 0.0, 0.0, 0.0, 48.446895599365234, 49.764991760253906, 5.8828887939453125, 0.0, 39.06007385253906, 0.0, 15.822158813476562, 25.75048828125, 0.0, 0.169189453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.50328826904297, -0.112762451171875, 1.5344505310058594, 0.0, 0.0, 31.921142578125, 0.0, 0.182220458984375, 0.0, 0.0, 0.0, -0.18219757080078125, 1.4111175537109375, 0.0, 0.0328826904296875, 0.0, 32.15583801269531, 0.0, 0.0, 0.0, 18.342247009277344, 0.0, 0.0, 0.0, -0.035003662109375, 37.40664291381836, 0.0, 8.543594360351562, 0.0424041748046875, 0.0, 0.0, 17.775314331054688, 0.0, 54.84893798828125, 0.0, 0.0, 59.569786071777344, 0.0, 0.0, 0.17486572265625, 5.070945739746094, 0.0, -0.05352783203125, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 136, 500, 500, 500, 500, 500, 500, 195, 500, 500, 500, 500, 500, 500, 500, 500, 500, 248, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 280, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 349, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614145858779638, "mean_inference_ms": 4.954920144142455, "mean_action_processing_ms": 7.442188129242831, "mean_env_wait_ms": 11.394205652529099, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.33315658569336, "episode_reward_min": -0.9245529174804688, "episode_reward_mean": 8.25681221869684, "episode_len_mean": 489.5806451612903, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.269500732421875, 2.2972793579101562, 21.368194580078125, 0.0, 0.0, 0.0, 0.0, 0.0, 6.2667083740234375, 0.0, 0.0, 73.67794799804688, 0.0, 37.62049865722656, -0.9245529174804688, 0.0, 7.1919097900390625, 0.0, -0.15497589111328125, 0.0, -0.1732025146484375, 0.4195098876953125, 30.02396011352539, 0.0, 21.302879333496094, 0.0, 11.006258010864258, 0.0, 0.0, 0.0, 0.0, -0.0251312255859375, 64.84424591064453, 4.224996566772461, 0.0, 0.0, 22.779373168945312, -0.2746429443359375, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1534423828125, 0.0, 0.0, 0.0, -0.13159942626953125, 44.310035705566406, 0.0, 0.0, 0.0, 0.00640106201171875, 74.33315658569336, 26.507400512695312, 44.89624786376953, 0.0, 0.0, 0.0, 48.446895599365234, 49.764991760253906, 5.8828887939453125, 0.0, 39.06007385253906, 0.0, 15.822158813476562, 25.75048828125, 0.0, 0.169189453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.50328826904297, -0.112762451171875, 1.5344505310058594, 0.0, 0.0, 31.921142578125, 0.0, 0.182220458984375, 0.0, 0.0, 0.0, -0.18219757080078125, 1.4111175537109375, 0.0, 0.0328826904296875, 0.0, 32.15583801269531, 0.0, 0.0, 0.0, 18.342247009277344, 0.0, 0.0, 0.0, -0.035003662109375, 37.40664291381836, 0.0, 8.543594360351562, 0.0424041748046875, 0.0, 0.0, 17.775314331054688, 0.0, 54.84893798828125, 0.0, 0.0, 59.569786071777344, 0.0, 0.0, 0.17486572265625, 5.070945739746094, 0.0, -0.05352783203125, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 136, 500, 500, 500, 500, 500, 500, 195, 500, 500, 500, 500, 500, 500, 500, 500, 500, 248, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 280, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 349, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614145858779638, "mean_inference_ms": 4.954920144142455, "mean_action_processing_ms": 7.442188129242831, "mean_env_wait_ms": 11.394205652529099, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22205473, "num_agent_steps_trained": 22205473, "num_env_steps_sampled": 22205473, "num_env_steps_trained": 22205473, "num_env_steps_sampled_this_iter": 60708, "num_env_steps_trained_this_iter": 60708, "timesteps_total": 22205473, "num_steps_trained_this_iter": 60708, "agent_timesteps_total": 22205473, "timers": {"training_iteration_time_ms": 46642.441, "load_time_ms": 47.986, "load_throughput": 1269174.987, "learn_time_ms": 26588.81, "learn_throughput": 2290.539, "synch_weights_time_ms": 9.17}, "counters": {"num_env_steps_sampled": 22205473, "num_env_steps_trained": 22205473, "num_agent_steps_sampled": 22205473, "num_agent_steps_trained": 22205473}, "done": false, "episodes_total": 44972, "training_iteration": 366, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-58-11", "timestamp": 1735109891, "time_this_iter_s": 46.38564991950989, "time_total_s": 10997.14052605629, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B08DF0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2140.010627269745, "timesteps_since_restore": 0, "iterations_since_restore": 45, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.643076923076922, "ram_util_percent": 97.06615384615385}}
{"custom_metrics": {"rewards/0_mean": 9.372781295776367, "rewards/0_min": -0.8940582275390625, "rewards/0_max": 78.64464569091797, "rewards/1_mean": 9.372781295776367, "rewards/1_min": -0.8940582275390625, "rewards/1_max": 78.64464569091797, "rewards/2_mean": 9.372781295776367, "rewards/2_min": -0.8940582275390625, "rewards/2_max": 78.64464569091797, "rewards/3_mean": 9.372781295776367, "rewards/3_min": -0.8940582275390625, "rewards/3_max": 78.64464569091797, "rewards/4_mean": 9.372781295776367, "rewards/4_min": -0.8940582275390625, "rewards/4_max": 78.64464569091797}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.11600945072991418, "policy_loss": 0.004555238244892468, "vf_loss": 0.09218237411530156, "vf_explained_var": 0.964665351879029, "kl": 0.01204461390078659, "entropy": 21.335682548038545, "entropy_coeff": 0.01, "grad_gnorm": 1.442835684191613}, "model": {}, "num_grad_updates_lifetime": 28890.5, "diff_num_grad_updates_vs_sampler_policy": 28889.5}}, "num_env_steps_sampled": 22266334, "num_env_steps_trained": 22266334, "num_agent_steps_sampled": 22266334, "num_agent_steps_trained": 22266334}, "sampler_results": {"episode_reward_max": 78.64464569091797, "episode_reward_min": -0.8940582275390625, "episode_reward_mean": 9.372781295776367, "episode_len_mean": 486.888, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.372781295776367, "rewards/0_min": -0.8940582275390625, "rewards/0_max": 78.64464569091797, "rewards/1_mean": 9.372781295776367, "rewards/1_min": -0.8940582275390625, "rewards/1_max": 78.64464569091797, "rewards/2_mean": 9.372781295776367, "rewards/2_min": -0.8940582275390625, "rewards/2_max": 78.64464569091797, "rewards/3_mean": 9.372781295776367, "rewards/3_min": -0.8940582275390625, "rewards/3_max": 78.64464569091797, "rewards/4_mean": 9.372781295776367, "rewards/4_min": -0.8940582275390625, "rewards/4_max": 78.64464569091797}, "hist_stats": {"episode_reward": [0.0, 10.407028198242188, -0.2359161376953125, 0.0, 0.0, 0.0, 66.95327758789062, 0.0, 0.0, 30.661998748779297, -0.00904083251953125, -0.1119232177734375, 54.824554443359375, 12.08595085144043, 25.076980590820312, 34.25907897949219, 0.0, 0.0, 13.776885986328125, -0.27588653564453125, 16.80260467529297, 0.0, 34.198211669921875, 28.862567901611328, 11.088966369628906, 8.720085144042969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.784957885742188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.277130126953125, 0.0, 0.0, 0.0, 0.0, 0.8650665283203125, 11.260093688964844, 78.64464569091797, 0.0, 36.741554260253906, 17.841995239257812, -0.723052978515625, 0.0, 0.0, 0.27993011474609375, 49.54861831665039, 45.2845344543457, -0.36737060546875, 11.183273315429688, 17.0230712890625, 0.0, 13.483139038085938, 6.942138671875, 22.538909912109375, -0.26644134521484375, 8.316959381103516, 41.7388916015625, 0.34508514404296875, 0.0, -0.3816871643066406, 1.3916778564453125, 27.30954933166504, 0.0, 25.875253677368164, -0.01020050048828125, 0.0, 5.5128326416015625, 0.0, 9.515525817871094, 2.291351318359375, 0.0, 29.156063079833984, 0.0, 0.0, 0.0, 40.62147521972656, 0.0, 0.3795623779296875, 9.873029708862305, -0.48604583740234375, 3.3742218017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 8.268539428710938, 25.17993927001953, 0.0, 0.2751007080078125, 36.946624755859375, 0.0, 0.08061981201171875, 13.499454498291016, 26.837188720703125, 0.0, -0.30657386779785156, 0.0, 1.3137588500976562, 31.300512313842773, 0.0, 0.0, 0.0, 29.07537078857422, 0.0, -0.8940582275390625, 0.901611328125, 54.5830192565918, 11.831472396850586, 0.0, 48.5615234375, 0.0, 0.0, 0.6393890380859375, -0.1927337646484375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 256, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 125, 500, 500, 500, 500, 500, 380, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 187, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 299, 500, 500, 500, 500, 500, 500, 500, 372, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614452437125367, "mean_inference_ms": 4.954680148299953, "mean_action_processing_ms": 7.440289641474123, "mean_env_wait_ms": 11.392777107489025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 78.64464569091797, "episode_reward_min": -0.8940582275390625, "episode_reward_mean": 9.372781295776367, "episode_len_mean": 486.888, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 10.407028198242188, -0.2359161376953125, 0.0, 0.0, 0.0, 66.95327758789062, 0.0, 0.0, 30.661998748779297, -0.00904083251953125, -0.1119232177734375, 54.824554443359375, 12.08595085144043, 25.076980590820312, 34.25907897949219, 0.0, 0.0, 13.776885986328125, -0.27588653564453125, 16.80260467529297, 0.0, 34.198211669921875, 28.862567901611328, 11.088966369628906, 8.720085144042969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.784957885742188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.277130126953125, 0.0, 0.0, 0.0, 0.0, 0.8650665283203125, 11.260093688964844, 78.64464569091797, 0.0, 36.741554260253906, 17.841995239257812, -0.723052978515625, 0.0, 0.0, 0.27993011474609375, 49.54861831665039, 45.2845344543457, -0.36737060546875, 11.183273315429688, 17.0230712890625, 0.0, 13.483139038085938, 6.942138671875, 22.538909912109375, -0.26644134521484375, 8.316959381103516, 41.7388916015625, 0.34508514404296875, 0.0, -0.3816871643066406, 1.3916778564453125, 27.30954933166504, 0.0, 25.875253677368164, -0.01020050048828125, 0.0, 5.5128326416015625, 0.0, 9.515525817871094, 2.291351318359375, 0.0, 29.156063079833984, 0.0, 0.0, 0.0, 40.62147521972656, 0.0, 0.3795623779296875, 9.873029708862305, -0.48604583740234375, 3.3742218017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 8.268539428710938, 25.17993927001953, 0.0, 0.2751007080078125, 36.946624755859375, 0.0, 0.08061981201171875, 13.499454498291016, 26.837188720703125, 0.0, -0.30657386779785156, 0.0, 1.3137588500976562, 31.300512313842773, 0.0, 0.0, 0.0, 29.07537078857422, 0.0, -0.8940582275390625, 0.901611328125, 54.5830192565918, 11.831472396850586, 0.0, 48.5615234375, 0.0, 0.0, 0.6393890380859375, -0.1927337646484375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 256, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 125, 500, 500, 500, 500, 500, 380, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 187, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 299, 500, 500, 500, 500, 500, 500, 500, 372, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614452437125367, "mean_inference_ms": 4.954680148299953, "mean_action_processing_ms": 7.440289641474123, "mean_env_wait_ms": 11.392777107489025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22266334, "num_agent_steps_trained": 22266334, "num_env_steps_sampled": 22266334, "num_env_steps_trained": 22266334, "num_env_steps_sampled_this_iter": 60861, "num_env_steps_trained_this_iter": 60861, "timesteps_total": 22266334, "num_steps_trained_this_iter": 60861, "agent_timesteps_total": 22266334, "timers": {"training_iteration_time_ms": 46479.602, "load_time_ms": 46.424, "load_throughput": 1312504.23, "learn_time_ms": 26568.253, "learn_throughput": 2293.406, "synch_weights_time_ms": 9.655}, "counters": {"num_env_steps_sampled": 22266334, "num_env_steps_trained": 22266334, "num_agent_steps_sampled": 22266334, "num_agent_steps_trained": 22266334}, "done": false, "episodes_total": 45097, "training_iteration": 367, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-58-57", "timestamp": 1735109937, "time_this_iter_s": 45.567272901535034, "time_total_s": 11042.707798957825, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE87C0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFC70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2185.57790017128, "timesteps_since_restore": 0, "iterations_since_restore": 46, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.5328125, "ram_util_percent": 96.63593750000001}}
{"custom_metrics": {"rewards/0_mean": 11.626090786321376, "rewards/0_min": -0.459686279296875, "rewards/0_max": 85.45370483398438, "rewards/1_mean": 11.626090786321376, "rewards/1_min": -0.459686279296875, "rewards/1_max": 85.45370483398438, "rewards/2_mean": 11.626090786321376, "rewards/2_min": -0.459686279296875, "rewards/2_max": 85.45370483398438, "rewards/3_mean": 11.626090786321376, "rewards/3_min": -0.459686279296875, "rewards/3_max": 85.45370483398438, "rewards/4_mean": 11.626090786321376, "rewards/4_min": -0.459686279296875, "rewards/4_max": 85.45370483398438}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09718205894801825, "policy_loss": -0.004412219809397819, "vf_loss": 0.1428957409576498, "vf_explained_var": 0.9806019617451562, "kl": 0.01461209027126195, "entropy": 23.64053222111293, "entropy_coeff": 0.01, "grad_gnorm": 1.8633633319229361}, "model": {}, "num_grad_updates_lifetime": 29520.5, "diff_num_grad_updates_vs_sampler_policy": 29519.5}}, "num_env_steps_sampled": 22327070, "num_env_steps_trained": 22327070, "num_agent_steps_sampled": 22327070, "num_agent_steps_trained": 22327070}, "sampler_results": {"episode_reward_max": 85.45370483398438, "episode_reward_min": -0.459686279296875, "episode_reward_mean": 11.626090786321376, "episode_len_mean": 493.7886178861789, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.626090786321376, "rewards/0_min": -0.459686279296875, "rewards/0_max": 85.45370483398438, "rewards/1_mean": 11.626090786321376, "rewards/1_min": -0.459686279296875, "rewards/1_max": 85.45370483398438, "rewards/2_mean": 11.626090786321376, "rewards/2_min": -0.459686279296875, "rewards/2_max": 85.45370483398438, "rewards/3_mean": 11.626090786321376, "rewards/3_min": -0.459686279296875, "rewards/3_max": 85.45370483398438, "rewards/4_mean": 11.626090786321376, "rewards/4_min": -0.459686279296875, "rewards/4_max": 85.45370483398438}, "hist_stats": {"episode_reward": [0.0, 31.829002380371094, 8.821456909179688, 0.0, 0.0, 0.0, 0.036441802978515625, 0.0, 0.0, 0.0, 0.0, 0.78192138671875, 0.0, 0.3570404052734375, -0.13671875, 0.0, -0.061279296875, 0.4785957336425781, 0.0, 0.1822967529296875, 51.398902893066406, 0.0, 24.738727569580078, 34.41386413574219, 0.20514678955078125, 2.425018310546875, -0.37891387939453125, -0.3906707763671875, 0.0, 0.0, 0.0, -0.1748504638671875, 0.0, 17.27880859375, 56.753204345703125, 0.0, 0.0, 71.89335632324219, 0.0, 46.00732421875, 26.231380462646484, 0.0, 0.0, 0.09039306640625, 0.005828857421875, 0.0, 20.99237060546875, 53.08502197265625, 0.0, -0.125946044921875, 0.0, -0.006542205810546875, 0.0, 0.4598846435546875, 0.0, 0.0, 16.003501892089844, 0.3928985595703125, 12.943496704101562, 0.5816116333007812, 17.738754272460938, -0.459686279296875, 11.608444213867188, 54.631248474121094, 0.0, 0.3767127990722656, 67.88860321044922, -0.28179931640625, 65.7745132446289, 0.0, 70.50374221801758, 10.196136474609375, -0.0419769287109375, 51.25963592529297, -0.1475830078125, 74.44859313964844, 0.0, 0.0, 0.0, -0.0304412841796875, 0.0, -8.392333984375e-05, 85.45370483398438, 0.0, -0.3091888427734375, 71.44489288330078, 0.0, -0.2825736999511719, 46.33978271484375, 18.282665252685547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.054115295410156, -0.13018035888671875, 38.69383239746094, 0.0, 0.0, 0.0, 2.2992630004882812, -0.26334381103515625, 77.68674087524414, -0.1013946533203125, 31.565290451049805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7680816650390625, 6.366647720336914, -0.10276031494140625, 0.0, 12.92367172241211, 6.2282562255859375, 65.99340057373047, -0.216522216796875, 0.0, 0.0, 9.737396240234375], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 244, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 446, 500, 500, 500, 500, 500, 500, 500, 500, 500, 184, 500, 500, 500, 500, 500, 500, 362, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.61440047030859, "mean_inference_ms": 4.952398159071652, "mean_action_processing_ms": 7.438623330398951, "mean_env_wait_ms": 11.391897556246576, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 85.45370483398438, "episode_reward_min": -0.459686279296875, "episode_reward_mean": 11.626090786321376, "episode_len_mean": 493.7886178861789, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 31.829002380371094, 8.821456909179688, 0.0, 0.0, 0.0, 0.036441802978515625, 0.0, 0.0, 0.0, 0.0, 0.78192138671875, 0.0, 0.3570404052734375, -0.13671875, 0.0, -0.061279296875, 0.4785957336425781, 0.0, 0.1822967529296875, 51.398902893066406, 0.0, 24.738727569580078, 34.41386413574219, 0.20514678955078125, 2.425018310546875, -0.37891387939453125, -0.3906707763671875, 0.0, 0.0, 0.0, -0.1748504638671875, 0.0, 17.27880859375, 56.753204345703125, 0.0, 0.0, 71.89335632324219, 0.0, 46.00732421875, 26.231380462646484, 0.0, 0.0, 0.09039306640625, 0.005828857421875, 0.0, 20.99237060546875, 53.08502197265625, 0.0, -0.125946044921875, 0.0, -0.006542205810546875, 0.0, 0.4598846435546875, 0.0, 0.0, 16.003501892089844, 0.3928985595703125, 12.943496704101562, 0.5816116333007812, 17.738754272460938, -0.459686279296875, 11.608444213867188, 54.631248474121094, 0.0, 0.3767127990722656, 67.88860321044922, -0.28179931640625, 65.7745132446289, 0.0, 70.50374221801758, 10.196136474609375, -0.0419769287109375, 51.25963592529297, -0.1475830078125, 74.44859313964844, 0.0, 0.0, 0.0, -0.0304412841796875, 0.0, -8.392333984375e-05, 85.45370483398438, 0.0, -0.3091888427734375, 71.44489288330078, 0.0, -0.2825736999511719, 46.33978271484375, 18.282665252685547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.054115295410156, -0.13018035888671875, 38.69383239746094, 0.0, 0.0, 0.0, 2.2992630004882812, -0.26334381103515625, 77.68674087524414, -0.1013946533203125, 31.565290451049805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7680816650390625, 6.366647720336914, -0.10276031494140625, 0.0, 12.92367172241211, 6.2282562255859375, 65.99340057373047, -0.216522216796875, 0.0, 0.0, 9.737396240234375], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 244, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 446, 500, 500, 500, 500, 500, 500, 500, 500, 500, 184, 500, 500, 500, 500, 500, 500, 362, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.61440047030859, "mean_inference_ms": 4.952398159071652, "mean_action_processing_ms": 7.438623330398951, "mean_env_wait_ms": 11.391897556246576, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22327070, "num_agent_steps_trained": 22327070, "num_env_steps_sampled": 22327070, "num_env_steps_trained": 22327070, "num_env_steps_sampled_this_iter": 60736, "num_env_steps_trained_this_iter": 60736, "timesteps_total": 22327070, "num_steps_trained_this_iter": 60736, "agent_timesteps_total": 22327070, "timers": {"training_iteration_time_ms": 46464.578, "load_time_ms": 45.54, "load_throughput": 1337658.245, "learn_time_ms": 26517.634, "learn_throughput": 2297.215, "synch_weights_time_ms": 9.657}, "counters": {"num_env_steps_sampled": 22327070, "num_env_steps_trained": 22327070, "num_agent_steps_sampled": 22327070, "num_agent_steps_trained": 22327070}, "done": false, "episodes_total": 45220, "training_iteration": 368, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_14-59-42", "timestamp": 1735109982, "time_this_iter_s": 45.42085528373718, "time_total_s": 11088.128654241562, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE5C90>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2230.998755455017, "timesteps_since_restore": 0, "iterations_since_restore": 47, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.814062500000002, "ram_util_percent": 96.459375}}
{"custom_metrics": {"rewards/0_mean": 11.405636033704203, "rewards/0_min": -0.7503433227539062, "rewards/0_max": 76.43931198120117, "rewards/1_mean": 11.405636033704203, "rewards/1_min": -0.7503433227539062, "rewards/1_max": 76.43931198120117, "rewards/2_mean": 11.405636033704203, "rewards/2_min": -0.7503433227539062, "rewards/2_max": 76.43931198120117, "rewards/3_mean": 11.405636033704203, "rewards/3_min": -0.7503433227539062, "rewards/3_max": 76.43931198120117, "rewards/4_mean": 11.405636033704203, "rewards/4_min": -0.7503433227539062, "rewards/4_max": 76.43931198120117}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09053859039734576, "policy_loss": -0.006728127547992858, "vf_loss": 0.1364351011517029, "vf_explained_var": 0.9859164572897412, "kl": 0.012504937440260417, "entropy": 22.087863151610843, "entropy_coeff": 0.01, "grad_gnorm": 1.3142346538485044}, "model": {}, "num_grad_updates_lifetime": 30150.5, "diff_num_grad_updates_vs_sampler_policy": 30149.5}}, "num_env_steps_sampled": 22387973, "num_env_steps_trained": 22387973, "num_agent_steps_sampled": 22387973, "num_agent_steps_trained": 22387973}, "sampler_results": {"episode_reward_max": 76.43931198120117, "episode_reward_min": -0.7503433227539062, "episode_reward_mean": 11.405636033704203, "episode_len_mean": 491.1532258064516, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.405636033704203, "rewards/0_min": -0.7503433227539062, "rewards/0_max": 76.43931198120117, "rewards/1_mean": 11.405636033704203, "rewards/1_min": -0.7503433227539062, "rewards/1_max": 76.43931198120117, "rewards/2_mean": 11.405636033704203, "rewards/2_min": -0.7503433227539062, "rewards/2_max": 76.43931198120117, "rewards/3_mean": 11.405636033704203, "rewards/3_min": -0.7503433227539062, "rewards/3_max": 76.43931198120117, "rewards/4_mean": 11.405636033704203, "rewards/4_min": -0.7503433227539062, "rewards/4_max": 76.43931198120117}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 5.7212371826171875, -0.1262359619140625, -0.2364044189453125, 0.17864990234375, 0.0, 25.937286376953125, 0.10107421875, 27.195663452148438, 0.04647064208984375, 0.0, 0.0, 35.060523986816406, 0.839630126953125, 0.0, 32.473548889160156, 52.18590545654297, 0.0, 30.848190307617188, 0.2792510986328125, 56.192081451416016, 33.64287567138672, 0.0, 0.0, 21.554046630859375, 0.0, -0.176300048828125, -0.0418243408203125, 0.5180816650390625, 64.55668640136719, 71.00626754760742, 0.0, 19.552337646484375, 0.0, 62.3687801361084, 14.66387939453125, 0.0, -0.29521942138671875, 0.0, 42.951011657714844, 0.0, 76.43931198120117, 0.3002166748046875, 0.0, 0.0, 0.0, 0.0, 7.907369613647461, 0.0, 0.0, 0.0, 55.10053253173828, 0.0, 73.96731948852539, 0.29461669921875, 0.15838623046875, 27.191802978515625, 20.07422637939453, 13.244056701660156, 42.54838562011719, -0.0049896240234375, 20.377822875976562, 0.0, 40.77789115905762, -0.0180816650390625, 0.0, 0.157806396484375, -0.4105682373046875, 0.0, 0.033721923828125, 0.0, 0.24983596801757812, 0.0, -0.16729736328125, 4.788581848144531, 2.93841552734375, 0.0, 72.28337860107422, 4.759515762329102, -0.172760009765625, 0.0, 0.0, 28.31269073486328, 7.397199630737305, 0.0, 12.772504806518555, 11.842803955078125, 0.0, -0.01781463623046875, -0.3607940673828125, -0.7503433227539062, 70.74634552001953, 14.858358383178711, -0.45967864990234375, 0.0, 0.0, 23.0752010345459, 0.0, 0.0, 43.821990966796875, 0.0, 0.3353118896484375, 0.0, -0.17185592651367188, 56.6087646484375, 0.0, 0.0, 0.0, 0.0, 40.96321678161621, 0.0, 0.0, -0.11141204833984375, 23.675556182861328, 0.0, 16.208389282226562, 0.0, -0.09337234497070312, 0.0, 5.8288116455078125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 291, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 163, 500, 500, 500, 500, 349, 500, 253, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 476, 500, 500, 500, 500, 371, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.59413685487662, "mean_inference_ms": 4.9514122339173445, "mean_action_processing_ms": 7.427874908130073, "mean_env_wait_ms": 11.38097250536848, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.43931198120117, "episode_reward_min": -0.7503433227539062, "episode_reward_mean": 11.405636033704203, "episode_len_mean": 491.1532258064516, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 5.7212371826171875, -0.1262359619140625, -0.2364044189453125, 0.17864990234375, 0.0, 25.937286376953125, 0.10107421875, 27.195663452148438, 0.04647064208984375, 0.0, 0.0, 35.060523986816406, 0.839630126953125, 0.0, 32.473548889160156, 52.18590545654297, 0.0, 30.848190307617188, 0.2792510986328125, 56.192081451416016, 33.64287567138672, 0.0, 0.0, 21.554046630859375, 0.0, -0.176300048828125, -0.0418243408203125, 0.5180816650390625, 64.55668640136719, 71.00626754760742, 0.0, 19.552337646484375, 0.0, 62.3687801361084, 14.66387939453125, 0.0, -0.29521942138671875, 0.0, 42.951011657714844, 0.0, 76.43931198120117, 0.3002166748046875, 0.0, 0.0, 0.0, 0.0, 7.907369613647461, 0.0, 0.0, 0.0, 55.10053253173828, 0.0, 73.96731948852539, 0.29461669921875, 0.15838623046875, 27.191802978515625, 20.07422637939453, 13.244056701660156, 42.54838562011719, -0.0049896240234375, 20.377822875976562, 0.0, 40.77789115905762, -0.0180816650390625, 0.0, 0.157806396484375, -0.4105682373046875, 0.0, 0.033721923828125, 0.0, 0.24983596801757812, 0.0, -0.16729736328125, 4.788581848144531, 2.93841552734375, 0.0, 72.28337860107422, 4.759515762329102, -0.172760009765625, 0.0, 0.0, 28.31269073486328, 7.397199630737305, 0.0, 12.772504806518555, 11.842803955078125, 0.0, -0.01781463623046875, -0.3607940673828125, -0.7503433227539062, 70.74634552001953, 14.858358383178711, -0.45967864990234375, 0.0, 0.0, 23.0752010345459, 0.0, 0.0, 43.821990966796875, 0.0, 0.3353118896484375, 0.0, -0.17185592651367188, 56.6087646484375, 0.0, 0.0, 0.0, 0.0, 40.96321678161621, 0.0, 0.0, -0.11141204833984375, 23.675556182861328, 0.0, 16.208389282226562, 0.0, -0.09337234497070312, 0.0, 5.8288116455078125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 291, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 163, 500, 500, 500, 500, 349, 500, 253, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 476, 500, 500, 500, 500, 371, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.59413685487662, "mean_inference_ms": 4.9514122339173445, "mean_action_processing_ms": 7.427874908130073, "mean_env_wait_ms": 11.38097250536848, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22387973, "num_agent_steps_trained": 22387973, "num_env_steps_sampled": 22387973, "num_env_steps_trained": 22387973, "num_env_steps_sampled_this_iter": 60903, "num_env_steps_trained_this_iter": 60903, "timesteps_total": 22387973, "num_steps_trained_this_iter": 60903, "agent_timesteps_total": 22387973, "timers": {"training_iteration_time_ms": 46619.098, "load_time_ms": 43.978, "load_throughput": 1386324.124, "learn_time_ms": 26630.398, "learn_throughput": 2289.384, "synch_weights_time_ms": 9.664}, "counters": {"num_env_steps_sampled": 22387973, "num_env_steps_trained": 22387973, "num_agent_steps_sampled": 22387973, "num_agent_steps_trained": 22387973}, "done": false, "episodes_total": 45344, "training_iteration": 369, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-00-29", "timestamp": 1735110029, "time_this_iter_s": 46.81381583213806, "time_total_s": 11134.9424700737, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A950>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2277.812571287155, "timesteps_since_restore": 0, "iterations_since_restore": 48, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 19.892424242424244, "ram_util_percent": 96.58181818181819}}
{"evaluation": {"episode_reward_max": 0.058490753173828125, "episode_reward_min": 0.058490753173828125, "episode_reward_mean": 0.058490753173828125, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.058490753173828125, "rewards/0_min": 0.058490753173828125, "rewards/0_max": 0.058490753173828125, "rewards/1_mean": 0.058490753173828125, "rewards/1_min": 0.058490753173828125, "rewards/1_max": 0.058490753173828125, "rewards/2_mean": 0.058490753173828125, "rewards/2_min": 0.058490753173828125, "rewards/2_max": 0.058490753173828125, "rewards/3_mean": 0.058490753173828125, "rewards/3_min": 0.058490753173828125, "rewards/3_max": 0.058490753173828125, "rewards/4_mean": 0.058490753173828125, "rewards/4_min": 0.058490753173828125, "rewards/4_max": 0.058490753173828125}, "hist_stats": {"episode_reward": [0.058490753173828125], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6763993251612129, "mean_inference_ms": 3.440396114960358, "mean_action_processing_ms": 0.47173220690334594, "mean_env_wait_ms": 5.987454690687229, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 9.803304703767635, "rewards/0_min": -0.9843368530273438, "rewards/0_max": 80.59199905395508, "rewards/1_mean": 9.803304703767635, "rewards/1_min": -0.9843368530273438, "rewards/1_max": 80.59199905395508, "rewards/2_mean": 9.803304703767635, "rewards/2_min": -0.9843368530273438, "rewards/2_max": 80.59199905395508, "rewards/3_mean": 9.803304703767635, "rewards/3_min": -0.9843368530273438, "rewards/3_max": 80.59199905395508, "rewards/4_mean": 9.803304703767635, "rewards/4_min": -0.9843368530273438, "rewards/4_max": 80.59199905395508}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09886847891743639, "policy_loss": 0.0035918968482985206, "vf_loss": 0.12950958976381652, "vf_explained_var": 0.9730347365613967, "kl": 0.010936982543133791, "entropy": 23.252365578545465, "entropy_coeff": 0.01, "grad_gnorm": 1.4534028529529535}, "model": {}, "num_grad_updates_lifetime": 30780.5, "diff_num_grad_updates_vs_sampler_policy": 30779.5}}, "num_env_steps_sampled": 22448151, "num_env_steps_trained": 22448151, "num_agent_steps_sampled": 22448151, "num_agent_steps_trained": 22448151}, "sampler_results": {"episode_reward_max": 80.59199905395508, "episode_reward_min": -0.9843368530273438, "episode_reward_mean": 9.803304703767635, "episode_len_mean": 497.3388429752066, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.803304703767635, "rewards/0_min": -0.9843368530273438, "rewards/0_max": 80.59199905395508, "rewards/1_mean": 9.803304703767635, "rewards/1_min": -0.9843368530273438, "rewards/1_max": 80.59199905395508, "rewards/2_mean": 9.803304703767635, "rewards/2_min": -0.9843368530273438, "rewards/2_max": 80.59199905395508, "rewards/3_mean": 9.803304703767635, "rewards/3_min": -0.9843368530273438, "rewards/3_max": 80.59199905395508, "rewards/4_mean": 9.803304703767635, "rewards/4_min": -0.9843368530273438, "rewards/4_max": 80.59199905395508}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.017333984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2567405700683594, 1.0705833435058594, 0.0, 0.0, 3.8888015747070312, 0.2601470947265625, -0.5810089111328125, 0.0, 0.0, 1.5216140747070312, 0.0, 0.0, 27.63445281982422, 80.59199905395508, 0.0, 0.0, 0.0, 43.45180892944336, 44.759193420410156, 0.0, 12.424606323242188, 5.190948486328125, 32.066993713378906, 45.00184631347656, -0.21662139892578125, 0.0, 41.320491790771484, 0.0, -0.28656005859375, 57.87656784057617, 0.0, 0.0, 0.0, 0.0, 12.115036010742188, -0.11625099182128906, 2.862203598022461, 0.0, 0.0, 36.88836669921875, -0.11719512939453125, 0.0, 0.0, 0.032928466796875, 3.4903945922851562, 0.0, 32.69318389892578, 0.0, 1.1891365051269531, 32.890716552734375, -0.21435546875, 0.0050048828125, 39.717071533203125, -0.9843368530273438, -0.6725311279296875, 0.024044036865234375, -0.0384521484375, 0.0, 0.17982101440429688, 0.0, 0.0, 3.936534881591797, -0.1220855712890625, 31.924972534179688, 0.93280029296875, 0.0, 0.0, 0.0, 63.60159683227539, 0.0, 8.609344482421875, 0.25008583068847656, 6.8284149169921875, 0.0, 31.930763244628906, 46.601959228515625, 0.00923919677734375, 0.0, 1.4502029418945312, 68.27588653564453, 1.096221923828125, 27.711196899414062, 0.0, 0.0, 56.20948791503906, -0.005191802978515625, 65.35701751708984, -0.15618133544921875, -0.164764404296875, 0.0, 0.0, 0.0, 55.45393371582031, 0.0, 0.0, 0.390594482421875, 0.0, -0.03810882568359375, 1.7614936828613281, 54.861114501953125, -0.23748779296875, 0.0, -0.1350860595703125, 0.0, 0.0, 0.0, 16.270057678222656, -0.6222915649414062, 58.02190399169922, -0.1429595947265625, -0.20850753784179688, 0.0, 30.387653350830078], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 325, 500, 500, 500, 500, 500, 500, 500, 500, 353, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.60731759761752, "mean_inference_ms": 4.951871590659905, "mean_action_processing_ms": 7.4333926826215775, "mean_env_wait_ms": 11.382134194078654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 80.59199905395508, "episode_reward_min": -0.9843368530273438, "episode_reward_mean": 9.803304703767635, "episode_len_mean": 497.3388429752066, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.017333984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2567405700683594, 1.0705833435058594, 0.0, 0.0, 3.8888015747070312, 0.2601470947265625, -0.5810089111328125, 0.0, 0.0, 1.5216140747070312, 0.0, 0.0, 27.63445281982422, 80.59199905395508, 0.0, 0.0, 0.0, 43.45180892944336, 44.759193420410156, 0.0, 12.424606323242188, 5.190948486328125, 32.066993713378906, 45.00184631347656, -0.21662139892578125, 0.0, 41.320491790771484, 0.0, -0.28656005859375, 57.87656784057617, 0.0, 0.0, 0.0, 0.0, 12.115036010742188, -0.11625099182128906, 2.862203598022461, 0.0, 0.0, 36.88836669921875, -0.11719512939453125, 0.0, 0.0, 0.032928466796875, 3.4903945922851562, 0.0, 32.69318389892578, 0.0, 1.1891365051269531, 32.890716552734375, -0.21435546875, 0.0050048828125, 39.717071533203125, -0.9843368530273438, -0.6725311279296875, 0.024044036865234375, -0.0384521484375, 0.0, 0.17982101440429688, 0.0, 0.0, 3.936534881591797, -0.1220855712890625, 31.924972534179688, 0.93280029296875, 0.0, 0.0, 0.0, 63.60159683227539, 0.0, 8.609344482421875, 0.25008583068847656, 6.8284149169921875, 0.0, 31.930763244628906, 46.601959228515625, 0.00923919677734375, 0.0, 1.4502029418945312, 68.27588653564453, 1.096221923828125, 27.711196899414062, 0.0, 0.0, 56.20948791503906, -0.005191802978515625, 65.35701751708984, -0.15618133544921875, -0.164764404296875, 0.0, 0.0, 0.0, 55.45393371582031, 0.0, 0.0, 0.390594482421875, 0.0, -0.03810882568359375, 1.7614936828613281, 54.861114501953125, -0.23748779296875, 0.0, -0.1350860595703125, 0.0, 0.0, 0.0, 16.270057678222656, -0.6222915649414062, 58.02190399169922, -0.1429595947265625, -0.20850753784179688, 0.0, 30.387653350830078], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 325, 500, 500, 500, 500, 500, 500, 500, 500, 353, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.60731759761752, "mean_inference_ms": 4.951871590659905, "mean_action_processing_ms": 7.4333926826215775, "mean_env_wait_ms": 11.382134194078654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22448151, "num_agent_steps_trained": 22448151, "num_env_steps_sampled": 22448151, "num_env_steps_trained": 22448151, "num_env_steps_sampled_this_iter": 60178, "num_env_steps_trained_this_iter": 60178, "timesteps_total": 22448151, "num_steps_trained_this_iter": 60178, "agent_timesteps_total": 22448151, "timers": {"training_iteration_time_ms": 46599.091, "load_time_ms": 43.979, "load_throughput": 1382790.955, "learn_time_ms": 26604.798, "learn_throughput": 2285.813, "synch_weights_time_ms": 9.67}, "counters": {"num_env_steps_sampled": 22448151, "num_env_steps_trained": 22448151, "num_agent_steps_sampled": 22448151, "num_agent_steps_trained": 22448151}, "done": false, "episodes_total": 45465, "training_iteration": 370, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-01-18", "timestamp": 1735110078, "time_this_iter_s": 48.04869055747986, "time_total_s": 11182.99116063118, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A588E0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2325.861261844635, "timesteps_since_restore": 0, "iterations_since_restore": 49, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.761764705882353, "ram_util_percent": 96.54705882352943}}
{"custom_metrics": {"rewards/0_mean": 11.912267223481209, "rewards/0_min": -0.538970947265625, "rewards/0_max": 84.26166534423828, "rewards/1_mean": 11.912267223481209, "rewards/1_min": -0.538970947265625, "rewards/1_max": 84.26166534423828, "rewards/2_mean": 11.912267223481209, "rewards/2_min": -0.538970947265625, "rewards/2_max": 84.26166534423828, "rewards/3_mean": 11.912267223481209, "rewards/3_min": -0.538970947265625, "rewards/3_max": 84.26166534423828, "rewards/4_mean": 11.912267223481209, "rewards/4_min": -0.538970947265625, "rewards/4_max": 84.26166534423828}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09112631463848095, "policy_loss": 0.003085563960115588, "vf_loss": 0.13050694661954093, "vf_explained_var": 0.9878865405680641, "kl": 0.012266023660315171, "entropy": 22.533979727729918, "entropy_coeff": 0.01, "grad_gnorm": 1.413672736878433}, "model": {}, "num_grad_updates_lifetime": 31410.5, "diff_num_grad_updates_vs_sampler_policy": 31409.5}}, "num_env_steps_sampled": 22508960, "num_env_steps_trained": 22508960, "num_agent_steps_sampled": 22508960, "num_agent_steps_trained": 22508960}, "sampler_results": {"episode_reward_max": 84.26166534423828, "episode_reward_min": -0.538970947265625, "episode_reward_mean": 11.912267223481209, "episode_len_mean": 490.39516129032256, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.912267223481209, "rewards/0_min": -0.538970947265625, "rewards/0_max": 84.26166534423828, "rewards/1_mean": 11.912267223481209, "rewards/1_min": -0.538970947265625, "rewards/1_max": 84.26166534423828, "rewards/2_mean": 11.912267223481209, "rewards/2_min": -0.538970947265625, "rewards/2_max": 84.26166534423828, "rewards/3_mean": 11.912267223481209, "rewards/3_min": -0.538970947265625, "rewards/3_max": 84.26166534423828, "rewards/4_mean": 11.912267223481209, "rewards/4_min": -0.538970947265625, "rewards/4_max": 84.26166534423828}, "hist_stats": {"episode_reward": [53.46953582763672, 0.0, 39.90241050720215, -0.26220703125, 69.60671997070312, 0.0, 0.0, 7.718482971191406, 0.0, 0.0, 0.0, 37.49845886230469, 0.0, 0.0, 12.472198486328125, 27.085296630859375, 0.0, 0.0, 22.58411407470703, 23.049293518066406, 47.00212097167969, 0.0, 0.0, 38.430423736572266, 29.565540313720703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.01607513427734375, 0.0752105712890625, 44.18595886230469, 16.583681106567383, 0.0, 19.805938720703125, 1.03717041015625, 0.0894012451171875, 0.0, 0.0, 19.8406982421875, 76.65058135986328, 0.0, 36.614295959472656, 6.175697326660156, -0.2220611572265625, 0.0, 10.593011856079102, -0.2098846435546875, 0.0, 0.0, 0.0, 13.456031799316406, -0.38458251953125, 30.771041870117188, 0.050567626953125, 0.0, 10.139617919921875, 0.0, -0.39673614501953125, 84.26166534423828, 0.0, 14.725204467773438, 0.0, -0.17659759521484375, -0.1208953857421875, -0.243927001953125, 0.3082427978515625, 0.0, 25.084857940673828, -0.538970947265625, 0.0, 0.0, 0.0, 0.4494781494140625, 13.887104034423828, -0.0823822021484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0336761474609375, 0.0, 0.0, -0.3097076416015625, 1.6222724914550781, 30.73876953125, 34.815460205078125, 33.563011169433594, 16.90727996826172, 7.25335693359375, 0.0, -0.0487518310546875, 0.8793106079101562, 72.4589958190918, 46.82895469665527, 43.343318939208984, -0.0287933349609375, 10.312614440917969, 0.0, 61.11388397216797, 43.59731674194336, -0.18836212158203125, 12.872129440307617, 10.386821746826172, 30.329797744750977, 44.41499710083008, 0.066864013671875, 25.56974983215332, 0.0, 36.674808502197266, 0.0, 0.0, 0.6615524291992188, 0.0, 0.0, 46.59345054626465, 36.168243408203125, -0.0256195068359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 338, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 149, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 445, 413, 500, 190, 500, 500, 500, 500, 500, 500, 446, 500, 500, 328, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.613445936475015, "mean_inference_ms": 4.948945572164923, "mean_action_processing_ms": 7.4355228669376245, "mean_env_wait_ms": 11.382522581775223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 84.26166534423828, "episode_reward_min": -0.538970947265625, "episode_reward_mean": 11.912267223481209, "episode_len_mean": 490.39516129032256, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [53.46953582763672, 0.0, 39.90241050720215, -0.26220703125, 69.60671997070312, 0.0, 0.0, 7.718482971191406, 0.0, 0.0, 0.0, 37.49845886230469, 0.0, 0.0, 12.472198486328125, 27.085296630859375, 0.0, 0.0, 22.58411407470703, 23.049293518066406, 47.00212097167969, 0.0, 0.0, 38.430423736572266, 29.565540313720703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.01607513427734375, 0.0752105712890625, 44.18595886230469, 16.583681106567383, 0.0, 19.805938720703125, 1.03717041015625, 0.0894012451171875, 0.0, 0.0, 19.8406982421875, 76.65058135986328, 0.0, 36.614295959472656, 6.175697326660156, -0.2220611572265625, 0.0, 10.593011856079102, -0.2098846435546875, 0.0, 0.0, 0.0, 13.456031799316406, -0.38458251953125, 30.771041870117188, 0.050567626953125, 0.0, 10.139617919921875, 0.0, -0.39673614501953125, 84.26166534423828, 0.0, 14.725204467773438, 0.0, -0.17659759521484375, -0.1208953857421875, -0.243927001953125, 0.3082427978515625, 0.0, 25.084857940673828, -0.538970947265625, 0.0, 0.0, 0.0, 0.4494781494140625, 13.887104034423828, -0.0823822021484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0336761474609375, 0.0, 0.0, -0.3097076416015625, 1.6222724914550781, 30.73876953125, 34.815460205078125, 33.563011169433594, 16.90727996826172, 7.25335693359375, 0.0, -0.0487518310546875, 0.8793106079101562, 72.4589958190918, 46.82895469665527, 43.343318939208984, -0.0287933349609375, 10.312614440917969, 0.0, 61.11388397216797, 43.59731674194336, -0.18836212158203125, 12.872129440307617, 10.386821746826172, 30.329797744750977, 44.41499710083008, 0.066864013671875, 25.56974983215332, 0.0, 36.674808502197266, 0.0, 0.0, 0.6615524291992188, 0.0, 0.0, 46.59345054626465, 36.168243408203125, -0.0256195068359375, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 338, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 149, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 445, 413, 500, 190, 500, 500, 500, 500, 500, 500, 446, 500, 500, 328, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.613445936475015, "mean_inference_ms": 4.948945572164923, "mean_action_processing_ms": 7.4355228669376245, "mean_env_wait_ms": 11.382522581775223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22508960, "num_agent_steps_trained": 22508960, "num_env_steps_sampled": 22508960, "num_env_steps_trained": 22508960, "num_env_steps_sampled_this_iter": 60809, "num_env_steps_trained_this_iter": 60809, "timesteps_total": 22508960, "num_steps_trained_this_iter": 60809, "agent_timesteps_total": 22508960, "timers": {"training_iteration_time_ms": 46950.359, "load_time_ms": 45.183, "load_throughput": 1346138.016, "learn_time_ms": 26837.349, "learn_throughput": 2266.315, "synch_weights_time_ms": 10.67}, "counters": {"num_env_steps_sampled": 22508960, "num_env_steps_trained": 22508960, "num_agent_steps_sampled": 22508960, "num_agent_steps_trained": 22508960}, "done": false, "episodes_total": 45589, "training_iteration": 371, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-02-06", "timestamp": 1735110126, "time_this_iter_s": 48.140461444854736, "time_total_s": 11231.131622076035, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE7CA0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C73F40>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2374.0017232894897, "timesteps_since_restore": 0, "iterations_since_restore": 50, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.16176470588235, "ram_util_percent": 96.8529411764706}}
{"custom_metrics": {"rewards/0_mean": 10.236777049739187, "rewards/0_min": -1.0957412719726562, "rewards/0_max": 82.2829818725586, "rewards/1_mean": 10.236777049739187, "rewards/1_min": -1.0957412719726562, "rewards/1_max": 82.2829818725586, "rewards/2_mean": 10.236777049739187, "rewards/2_min": -1.0957412719726562, "rewards/2_max": 82.2829818725586, "rewards/3_mean": 10.236777049739187, "rewards/3_min": -1.0957412719726562, "rewards/3_max": 82.2829818725586, "rewards/4_mean": 10.236777049739187, "rewards/4_min": -1.0957412719726562, "rewards/4_max": 82.2829818725586}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08914523675674221, "policy_loss": 0.0014215527381378388, "vf_loss": 0.14203292378076604, "vf_explained_var": 0.9784720972416893, "kl": 0.012357536812372033, "entropy": 23.32253184242854, "entropy_coeff": 0.01, "grad_gnorm": 1.4329605001305776}, "model": {}, "num_grad_updates_lifetime": 32040.5, "diff_num_grad_updates_vs_sampler_policy": 32039.5}}, "num_env_steps_sampled": 22569874, "num_env_steps_trained": 22569874, "num_agent_steps_sampled": 22569874, "num_agent_steps_trained": 22569874}, "sampler_results": {"episode_reward_max": 82.2829818725586, "episode_reward_min": -1.0957412719726562, "episode_reward_mean": 10.236777049739187, "episode_len_mean": 495.2357723577236, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.236777049739187, "rewards/0_min": -1.0957412719726562, "rewards/0_max": 82.2829818725586, "rewards/1_mean": 10.236777049739187, "rewards/1_min": -1.0957412719726562, "rewards/1_max": 82.2829818725586, "rewards/2_mean": 10.236777049739187, "rewards/2_min": -1.0957412719726562, "rewards/2_max": 82.2829818725586, "rewards/3_mean": 10.236777049739187, "rewards/3_min": -1.0957412719726562, "rewards/3_max": 82.2829818725586, "rewards/4_mean": 10.236777049739187, "rewards/4_min": -1.0957412719726562, "rewards/4_max": 82.2829818725586}, "hist_stats": {"episode_reward": [-0.14646148681640625, 35.95693778991699, 0.0, 40.777748107910156, 63.659088134765625, 0.0, 0.0, 43.42132568359375, 0.0, 0.0, 45.31993865966797, -0.5154571533203125, -0.09717559814453125, 0.0, 0.0, -0.27374267578125, 0.68634033203125, 0.0, 0.00860595703125, 0.0, -0.2519378662109375, 0.0, 0.0, 4.604499816894531, 17.881244659423828, -0.08837890625, 41.028465270996094, 0.0, 0.5548210144042969, 0.0, 0.0, -1.0957412719726562, 0.0, -0.0044708251953125, 0.445159912109375, 0.0, 16.861724853515625, -0.6038055419921875, 7.3780670166015625, 0.0, 0.0, 0.0, -0.058624267578125, 18.232131958007812, 40.428775787353516, 52.840476989746094, 0.0, 0.0, 0.0, 47.056182861328125, 0.0, 0.0, 0.0, 57.38195037841797, 2.1786422729492188, 0.0, 25.969322204589844, 34.47008514404297, 0.0, 0.32341766357421875, 10.011489868164062, 0.0, 0.0, 82.2829818725586, 0.0, -0.5334701538085938, 0.0, 0.0, 0.0, 0.0, 0.0, 20.166114807128906, 0.2839813232421875, 0.0, -0.17545318603515625, -0.2965202331542969, 0.0, 0.0, 0.0, 11.706184387207031, 52.71421813964844, 7.267978668212891, 0.0, -0.302581787109375, 10.639728546142578, 34.81719207763672, 9.106269836425781, 0.0, 7.935325622558594, 18.469650268554688, 0.8917312622070312, 0.0, 0.0, 0.0, 0.2730560302734375, 0.0, -0.24599456787109375, 0.0, 0.04221343994140625, 0.0, 0.0, 55.05144119262695, 0.0, 42.7987060546875, 0.07305908203125, 0.0, 12.947731018066406, 81.80807495117188, 75.18865966796875, 0.0, 0.0, -0.17536163330078125, 0.0, 0.1101531982421875, 0.0, 60.46799087524414, 50.13726997375488, 0.05999755859375, -0.29959869384765625, 0.0, -0.06531524658203125, 0.0, 21.637516021728516], "episode_lengths": [500, 306, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 143, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 469, 496, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.611627438531352, "mean_inference_ms": 4.9478518887860155, "mean_action_processing_ms": 7.434503409450972, "mean_env_wait_ms": 11.381937126271177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 82.2829818725586, "episode_reward_min": -1.0957412719726562, "episode_reward_mean": 10.236777049739187, "episode_len_mean": 495.2357723577236, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.14646148681640625, 35.95693778991699, 0.0, 40.777748107910156, 63.659088134765625, 0.0, 0.0, 43.42132568359375, 0.0, 0.0, 45.31993865966797, -0.5154571533203125, -0.09717559814453125, 0.0, 0.0, -0.27374267578125, 0.68634033203125, 0.0, 0.00860595703125, 0.0, -0.2519378662109375, 0.0, 0.0, 4.604499816894531, 17.881244659423828, -0.08837890625, 41.028465270996094, 0.0, 0.5548210144042969, 0.0, 0.0, -1.0957412719726562, 0.0, -0.0044708251953125, 0.445159912109375, 0.0, 16.861724853515625, -0.6038055419921875, 7.3780670166015625, 0.0, 0.0, 0.0, -0.058624267578125, 18.232131958007812, 40.428775787353516, 52.840476989746094, 0.0, 0.0, 0.0, 47.056182861328125, 0.0, 0.0, 0.0, 57.38195037841797, 2.1786422729492188, 0.0, 25.969322204589844, 34.47008514404297, 0.0, 0.32341766357421875, 10.011489868164062, 0.0, 0.0, 82.2829818725586, 0.0, -0.5334701538085938, 0.0, 0.0, 0.0, 0.0, 0.0, 20.166114807128906, 0.2839813232421875, 0.0, -0.17545318603515625, -0.2965202331542969, 0.0, 0.0, 0.0, 11.706184387207031, 52.71421813964844, 7.267978668212891, 0.0, -0.302581787109375, 10.639728546142578, 34.81719207763672, 9.106269836425781, 0.0, 7.935325622558594, 18.469650268554688, 0.8917312622070312, 0.0, 0.0, 0.0, 0.2730560302734375, 0.0, -0.24599456787109375, 0.0, 0.04221343994140625, 0.0, 0.0, 55.05144119262695, 0.0, 42.7987060546875, 0.07305908203125, 0.0, 12.947731018066406, 81.80807495117188, 75.18865966796875, 0.0, 0.0, -0.17536163330078125, 0.0, 0.1101531982421875, 0.0, 60.46799087524414, 50.13726997375488, 0.05999755859375, -0.29959869384765625, 0.0, -0.06531524658203125, 0.0, 21.637516021728516], "episode_lengths": [500, 306, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 143, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 469, 496, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.611627438531352, "mean_inference_ms": 4.9478518887860155, "mean_action_processing_ms": 7.434503409450972, "mean_env_wait_ms": 11.381937126271177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22569874, "num_agent_steps_trained": 22569874, "num_env_steps_sampled": 22569874, "num_env_steps_trained": 22569874, "num_env_steps_sampled_this_iter": 60914, "num_env_steps_trained_this_iter": 60914, "timesteps_total": 22569874, "num_steps_trained_this_iter": 60914, "agent_timesteps_total": 22569874, "timers": {"training_iteration_time_ms": 47067.724, "load_time_ms": 45.18, "load_throughput": 1346516.326, "learn_time_ms": 27045.918, "learn_throughput": 2249.367, "synch_weights_time_ms": 10.478}, "counters": {"num_env_steps_sampled": 22569874, "num_env_steps_trained": 22569874, "num_agent_steps_sampled": 22569874, "num_agent_steps_trained": 22569874}, "done": false, "episodes_total": 45712, "training_iteration": 372, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-02-54", "timestamp": 1735110174, "time_this_iter_s": 48.202682971954346, "time_total_s": 11279.334305047989, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B09B10>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCE5F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2422.204406261444, "timesteps_since_restore": 0, "iterations_since_restore": 51, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.429411764705883, "ram_util_percent": 96.91176470588235}}
{"custom_metrics": {"rewards/0_mean": 9.840989558927474, "rewards/0_min": -0.7393951416015625, "rewards/0_max": 70.98229598999023, "rewards/1_mean": 9.840989558927474, "rewards/1_min": -0.7393951416015625, "rewards/1_max": 70.98229598999023, "rewards/2_mean": 9.840989558927474, "rewards/2_min": -0.7393951416015625, "rewards/2_max": 70.98229598999023, "rewards/3_mean": 9.840989558927474, "rewards/3_min": -0.7393951416015625, "rewards/3_max": 70.98229598999023, "rewards/4_mean": 9.840989558927474, "rewards/4_min": -0.7393951416015625, "rewards/4_max": 70.98229598999023}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10389919322638196, "policy_loss": -0.002477173481268452, "vf_loss": 0.11637633321437216, "vf_explained_var": 0.9868782267684029, "kl": 0.011807775646743793, "entropy": 21.83961263081384, "entropy_coeff": 0.01, "grad_gnorm": 1.414427082477108}, "model": {}, "num_grad_updates_lifetime": 32670.5, "diff_num_grad_updates_vs_sampler_policy": 32669.5}}, "num_env_steps_sampled": 22630990, "num_env_steps_trained": 22630990, "num_agent_steps_sampled": 22630990, "num_agent_steps_trained": 22630990}, "sampler_results": {"episode_reward_max": 70.98229598999023, "episode_reward_min": -0.7393951416015625, "episode_reward_mean": 9.840989558927474, "episode_len_mean": 492.8709677419355, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.840989558927474, "rewards/0_min": -0.7393951416015625, "rewards/0_max": 70.98229598999023, "rewards/1_mean": 9.840989558927474, "rewards/1_min": -0.7393951416015625, "rewards/1_max": 70.98229598999023, "rewards/2_mean": 9.840989558927474, "rewards/2_min": -0.7393951416015625, "rewards/2_max": 70.98229598999023, "rewards/3_mean": 9.840989558927474, "rewards/3_min": -0.7393951416015625, "rewards/3_max": 70.98229598999023, "rewards/4_mean": 9.840989558927474, "rewards/4_min": -0.7393951416015625, "rewards/4_max": 70.98229598999023}, "hist_stats": {"episode_reward": [0.14946746826171875, 18.865707397460938, 0.0, 0.719482421875, 0.4531402587890625, 0.0, 32.95334243774414, 9.467933654785156, 3.41033935546875, 0.0, 0.0, 0.0, 0.0, 25.768314361572266, 0.0, 0.3309326171875, 0.0, -0.5911941528320312, 0.0, 13.452880859375, 34.27998352050781, 62.21977233886719, 1.805694580078125, 0.0, 0.0, -0.054656982421875, 0.0, 0.0, 0.0, 7.561859130859375, 0.0, 0.0, 0.0, 0.0, -0.7393951416015625, 0.413177490234375, 0.0, 68.06916046142578, 40.38099670410156, 40.10426330566406, 58.784645080566406, 0.0, 0.0, 0.19422149658203125, -0.33681488037109375, 0.22191619873046875, 0.0, 33.74302673339844, 0.0, -0.19136810302734375, 29.322288513183594, 28.349014282226562, 3.656604766845703, 0.057342529296875, -0.3452606201171875, 66.86080169677734, 48.97810363769531, -0.5913581848144531, 0.0, 0.0, 23.411026000976562, 0.4186859130859375, 0.0, 0.7204380035400391, 0.0, 0.0, -0.1664581298828125, 28.331390380859375, 0.0, 0.0, 0.0, 34.597524642944336, 0.3029022216796875, 0.0, 35.98117446899414, 0.0, 0.33446502685546875, 0.0, 47.373565673828125, 8.316810607910156, 0.0, 13.273563385009766, 2.0077171325683594, 25.202301025390625, 0.7406005859375, 8.449508666992188, -0.03511810302734375, 0.0, -0.528564453125, 0.02980804443359375, 5.0736541748046875, -0.4783363342285156, 1.7918548583984375, 0.0, 0.0, 0.0, 0.0, 40.29541015625, 0.0, -0.40914154052734375, 0.0, 28.950393676757812, 0.0088348388671875, 34.10011291503906, 0.0, 0.0, 43.86737251281738, 30.19542694091797, 27.70135498046875, 49.213775634765625, 0.0, 70.98229598999023, 0.3256988525390625, 0.0, 26.087493896484375, 0.0, 0.03821563720703125, 0.0, -0.180206298828125, 6.392555236816406, 0.0, -0.14115142822265625, 0.0, -0.01861572265625], "episode_lengths": [500, 500, 500, 500, 500, 500, 299, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 350, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 420, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 314, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 305, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614446590857058, "mean_inference_ms": 4.946595191076168, "mean_action_processing_ms": 7.433352480238277, "mean_env_wait_ms": 11.384822731326278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 70.98229598999023, "episode_reward_min": -0.7393951416015625, "episode_reward_mean": 9.840989558927474, "episode_len_mean": 492.8709677419355, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.14946746826171875, 18.865707397460938, 0.0, 0.719482421875, 0.4531402587890625, 0.0, 32.95334243774414, 9.467933654785156, 3.41033935546875, 0.0, 0.0, 0.0, 0.0, 25.768314361572266, 0.0, 0.3309326171875, 0.0, -0.5911941528320312, 0.0, 13.452880859375, 34.27998352050781, 62.21977233886719, 1.805694580078125, 0.0, 0.0, -0.054656982421875, 0.0, 0.0, 0.0, 7.561859130859375, 0.0, 0.0, 0.0, 0.0, -0.7393951416015625, 0.413177490234375, 0.0, 68.06916046142578, 40.38099670410156, 40.10426330566406, 58.784645080566406, 0.0, 0.0, 0.19422149658203125, -0.33681488037109375, 0.22191619873046875, 0.0, 33.74302673339844, 0.0, -0.19136810302734375, 29.322288513183594, 28.349014282226562, 3.656604766845703, 0.057342529296875, -0.3452606201171875, 66.86080169677734, 48.97810363769531, -0.5913581848144531, 0.0, 0.0, 23.411026000976562, 0.4186859130859375, 0.0, 0.7204380035400391, 0.0, 0.0, -0.1664581298828125, 28.331390380859375, 0.0, 0.0, 0.0, 34.597524642944336, 0.3029022216796875, 0.0, 35.98117446899414, 0.0, 0.33446502685546875, 0.0, 47.373565673828125, 8.316810607910156, 0.0, 13.273563385009766, 2.0077171325683594, 25.202301025390625, 0.7406005859375, 8.449508666992188, -0.03511810302734375, 0.0, -0.528564453125, 0.02980804443359375, 5.0736541748046875, -0.4783363342285156, 1.7918548583984375, 0.0, 0.0, 0.0, 0.0, 40.29541015625, 0.0, -0.40914154052734375, 0.0, 28.950393676757812, 0.0088348388671875, 34.10011291503906, 0.0, 0.0, 43.86737251281738, 30.19542694091797, 27.70135498046875, 49.213775634765625, 0.0, 70.98229598999023, 0.3256988525390625, 0.0, 26.087493896484375, 0.0, 0.03821563720703125, 0.0, -0.180206298828125, 6.392555236816406, 0.0, -0.14115142822265625, 0.0, -0.01861572265625], "episode_lengths": [500, 500, 500, 500, 500, 500, 299, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 350, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 420, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 314, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 305, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.614446590857058, "mean_inference_ms": 4.946595191076168, "mean_action_processing_ms": 7.433352480238277, "mean_env_wait_ms": 11.384822731326278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22630990, "num_agent_steps_trained": 22630990, "num_env_steps_sampled": 22630990, "num_env_steps_trained": 22630990, "num_env_steps_sampled_this_iter": 61116, "num_env_steps_trained_this_iter": 61116, "timesteps_total": 22630990, "num_steps_trained_this_iter": 61116, "agent_timesteps_total": 22630990, "timers": {"training_iteration_time_ms": 47286.011, "load_time_ms": 45.067, "load_throughput": 1350397.948, "learn_time_ms": 27245.753, "learn_throughput": 2233.702, "synch_weights_time_ms": 10.286}, "counters": {"num_env_steps_sampled": 22630990, "num_env_steps_trained": 22630990, "num_agent_steps_sampled": 22630990, "num_agent_steps_trained": 22630990}, "done": false, "episodes_total": 45836, "training_iteration": 373, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-03-43", "timestamp": 1735110223, "time_this_iter_s": 49.046443462371826, "time_total_s": 11328.38074851036, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B52F80>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2471.250849723816, "timesteps_since_restore": 0, "iterations_since_restore": 52, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.88550724637681, "ram_util_percent": 97.58695652173913}}
{"custom_metrics": {"rewards/0_mean": 10.381654043046256, "rewards/0_min": -0.6613235473632812, "rewards/0_max": 63.783172607421875, "rewards/1_mean": 10.381654043046256, "rewards/1_min": -0.6613235473632812, "rewards/1_max": 63.783172607421875, "rewards/2_mean": 10.381654043046256, "rewards/2_min": -0.6613235473632812, "rewards/2_max": 63.783172607421875, "rewards/3_mean": 10.381654043046256, "rewards/3_min": -0.6613235473632812, "rewards/3_max": 63.783172607421875, "rewards/4_mean": 10.381654043046256, "rewards/4_min": -0.6613235473632812, "rewards/4_max": 63.783172607421875}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.14952413637545847, "policy_loss": 0.0009306646999903024, "vf_loss": 0.0772080115604377, "vf_explained_var": 0.9927055238731324, "kl": 0.012537112837612984, "entropy": 22.829750923883346, "entropy_coeff": 0.01, "grad_gnorm": 1.560958300696479}, "model": {}, "num_grad_updates_lifetime": 33300.5, "diff_num_grad_updates_vs_sampler_policy": 33299.5}}, "num_env_steps_sampled": 22692344, "num_env_steps_trained": 22692344, "num_agent_steps_sampled": 22692344, "num_agent_steps_trained": 22692344}, "sampler_results": {"episode_reward_max": 63.783172607421875, "episode_reward_min": -0.6613235473632812, "episode_reward_mean": 10.381654043046256, "episode_len_mean": 486.93650793650795, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.381654043046256, "rewards/0_min": -0.6613235473632812, "rewards/0_max": 63.783172607421875, "rewards/1_mean": 10.381654043046256, "rewards/1_min": -0.6613235473632812, "rewards/1_max": 63.783172607421875, "rewards/2_mean": 10.381654043046256, "rewards/2_min": -0.6613235473632812, "rewards/2_max": 63.783172607421875, "rewards/3_mean": 10.381654043046256, "rewards/3_min": -0.6613235473632812, "rewards/3_max": 63.783172607421875, "rewards/4_mean": 10.381654043046256, "rewards/4_min": -0.6613235473632812, "rewards/4_max": 63.783172607421875}, "hist_stats": {"episode_reward": [0.320220947265625, 0.0, -0.042816162109375, 0.0, 0.20986175537109375, 0.0, 0.0, 0.0, 37.74199676513672, 0.0, 0.4009857177734375, 0.0, 0.03021240234375, 0.0, 0.0, -0.08026885986328125, 38.433006286621094, 20.151399612426758, 18.09661865234375, -0.0719451904296875, 1.2552452087402344, 0.0, 21.623489379882812, -0.5721702575683594, -0.01172637939453125, -6.4849853515625e-05, 57.83673858642578, 0.0, 58.5758171081543, 25.235504150390625, 0.0, -0.6613235473632812, 0.0, 7.920989990234375, 0.0, 45.19341278076172, 0.0, 0.0, 0.0, 42.12560844421387, 0.06622314453125, 61.306697845458984, 1.2968368530273438, 0.0, 0.8514633178710938, 46.754913330078125, 14.643915176391602, -0.36932373046875, -0.050323486328125, 0.0, 0.0, 0.1408233642578125, 0.0, 16.206037521362305, 10.315940856933594, 25.091278076171875, 14.625240325927734, 13.537405014038086, -0.46270751953125, 38.12049865722656, 13.309804916381836, 0.0, 41.92464828491211, 0.0, 0.0, 0.0, 12.468124389648438, 0.0, 0.0, -0.0970306396484375, 62.0327262878418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24672698974609375, 0.0, 25.376750946044922, 0.39325714111328125, 0.0, 10.170082092285156, 60.885541915893555, 2.1245040893554688, 10.771743774414062, 15.123689651489258, 0.0, 22.19042205810547, 0.0, 0.0747222900390625, 4.597621917724609, -0.3093109130859375, 41.373287200927734, 0.0, -0.049205780029296875, 0.0, 0.0, 8.511978149414062, -0.18798065185546875, 0.0, 63.783172607421875, 0.0, 0.0, 0.0, 0.0, -0.34400177001953125, 0.1483917236328125, 0.0, 41.470563888549805, 0.0, 0.0, 51.96605682373047, 59.73259735107422, -0.1733551025390625, 30.931961059570312, -0.084930419921875, 20.49938201904297, 47.03216552734375, 0.0, 0.0, 2.2032318115234375, 0.0, 1.4038238525390625, 0.0, 0.0, 42.80153465270996], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 312, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 411, 500, 500, 500, 406, 500, 415, 500, 500, 500, 500, 372, 500, 500, 500, 500, 500, 500, 500, 317, 500, 500, 298, 500, 500, 331, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.620018082189649, "mean_inference_ms": 4.948135488589551, "mean_action_processing_ms": 7.439639540477471, "mean_env_wait_ms": 11.389994683943547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 63.783172607421875, "episode_reward_min": -0.6613235473632812, "episode_reward_mean": 10.381654043046256, "episode_len_mean": 486.93650793650795, "episodes_this_iter": 126, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.320220947265625, 0.0, -0.042816162109375, 0.0, 0.20986175537109375, 0.0, 0.0, 0.0, 37.74199676513672, 0.0, 0.4009857177734375, 0.0, 0.03021240234375, 0.0, 0.0, -0.08026885986328125, 38.433006286621094, 20.151399612426758, 18.09661865234375, -0.0719451904296875, 1.2552452087402344, 0.0, 21.623489379882812, -0.5721702575683594, -0.01172637939453125, -6.4849853515625e-05, 57.83673858642578, 0.0, 58.5758171081543, 25.235504150390625, 0.0, -0.6613235473632812, 0.0, 7.920989990234375, 0.0, 45.19341278076172, 0.0, 0.0, 0.0, 42.12560844421387, 0.06622314453125, 61.306697845458984, 1.2968368530273438, 0.0, 0.8514633178710938, 46.754913330078125, 14.643915176391602, -0.36932373046875, -0.050323486328125, 0.0, 0.0, 0.1408233642578125, 0.0, 16.206037521362305, 10.315940856933594, 25.091278076171875, 14.625240325927734, 13.537405014038086, -0.46270751953125, 38.12049865722656, 13.309804916381836, 0.0, 41.92464828491211, 0.0, 0.0, 0.0, 12.468124389648438, 0.0, 0.0, -0.0970306396484375, 62.0327262878418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24672698974609375, 0.0, 25.376750946044922, 0.39325714111328125, 0.0, 10.170082092285156, 60.885541915893555, 2.1245040893554688, 10.771743774414062, 15.123689651489258, 0.0, 22.19042205810547, 0.0, 0.0747222900390625, 4.597621917724609, -0.3093109130859375, 41.373287200927734, 0.0, -0.049205780029296875, 0.0, 0.0, 8.511978149414062, -0.18798065185546875, 0.0, 63.783172607421875, 0.0, 0.0, 0.0, 0.0, -0.34400177001953125, 0.1483917236328125, 0.0, 41.470563888549805, 0.0, 0.0, 51.96605682373047, 59.73259735107422, -0.1733551025390625, 30.931961059570312, -0.084930419921875, 20.49938201904297, 47.03216552734375, 0.0, 0.0, 2.2032318115234375, 0.0, 1.4038238525390625, 0.0, 0.0, 42.80153465270996], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 312, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 411, 500, 500, 500, 406, 500, 415, 500, 500, 500, 500, 372, 500, 500, 500, 500, 500, 500, 500, 317, 500, 500, 298, 500, 500, 331, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 452, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 368]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.620018082189649, "mean_inference_ms": 4.948135488589551, "mean_action_processing_ms": 7.439639540477471, "mean_env_wait_ms": 11.389994683943547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22692344, "num_agent_steps_trained": 22692344, "num_env_steps_sampled": 22692344, "num_env_steps_trained": 22692344, "num_env_steps_sampled_this_iter": 61354, "num_env_steps_trained_this_iter": 61354, "timesteps_total": 22692344, "num_steps_trained_this_iter": 61354, "agent_timesteps_total": 22692344, "timers": {"training_iteration_time_ms": 47310.178, "load_time_ms": 45.067, "load_throughput": 1349974.776, "learn_time_ms": 27026.632, "learn_throughput": 2251.102, "synch_weights_time_ms": 10.483}, "counters": {"num_env_steps_sampled": 22692344, "num_env_steps_trained": 22692344, "num_agent_steps_sampled": 22692344, "num_agent_steps_trained": 22692344}, "done": false, "episodes_total": 45962, "training_iteration": 374, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-04-33", "timestamp": 1735110273, "time_this_iter_s": 48.97929859161377, "time_total_s": 11377.360047101974, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B503D0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CCF760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2520.2301483154297, "timesteps_since_restore": 0, "iterations_since_restore": 53, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.43188405797102, "ram_util_percent": 97.77681159420291}}
{"evaluation": {"episode_reward_max": 0.5326766967773438, "episode_reward_min": 0.5326766967773438, "episode_reward_mean": 0.5326766967773438, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.5326766967773438, "rewards/0_min": 0.5326766967773438, "rewards/0_max": 0.5326766967773438, "rewards/1_mean": 0.5326766967773438, "rewards/1_min": 0.5326766967773438, "rewards/1_max": 0.5326766967773438, "rewards/2_mean": 0.5326766967773438, "rewards/2_min": 0.5326766967773438, "rewards/2_max": 0.5326766967773438, "rewards/3_mean": 0.5326766967773438, "rewards/3_min": 0.5326766967773438, "rewards/3_max": 0.5326766967773438, "rewards/4_mean": 0.5326766967773438, "rewards/4_min": 0.5326766967773438, "rewards/4_max": 0.5326766967773438}, "hist_stats": {"episode_reward": [0.5326766967773438], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6961088314032126, "mean_inference_ms": 3.457848537273785, "mean_action_processing_ms": 0.47574917027525976, "mean_env_wait_ms": 5.96587182478219, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 7.9511716385518225, "rewards/0_min": -0.9730949401855469, "rewards/0_max": 70.2730484008789, "rewards/1_mean": 7.9511716385518225, "rewards/1_min": -0.9730949401855469, "rewards/1_max": 70.2730484008789, "rewards/2_mean": 7.9511716385518225, "rewards/2_min": -0.9730949401855469, "rewards/2_max": 70.2730484008789, "rewards/3_mean": 7.9511716385518225, "rewards/3_min": -0.9730949401855469, "rewards/3_max": 70.2730484008789, "rewards/4_mean": 7.9511716385518225, "rewards/4_min": -0.9730949401855469, "rewards/4_max": 70.2730484008789}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.1445357643029147, "policy_loss": 0.001029598956506922, "vf_loss": 0.10158086938022207, "vf_explained_var": 0.981425412685152, "kl": 0.012790888880882116, "entropy": 24.77937764970083, "entropy_coeff": 0.01, "grad_gnorm": 1.6743726152276235}, "model": {}, "num_grad_updates_lifetime": 33930.5, "diff_num_grad_updates_vs_sampler_policy": 33929.5}}, "num_env_steps_sampled": 22752653, "num_env_steps_trained": 22752653, "num_agent_steps_sampled": 22752653, "num_agent_steps_trained": 22752653}, "sampler_results": {"episode_reward_max": 70.2730484008789, "episode_reward_min": -0.9730949401855469, "episode_reward_mean": 7.9511716385518225, "episode_len_mean": 498.42148760330576, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.9511716385518225, "rewards/0_min": -0.9730949401855469, "rewards/0_max": 70.2730484008789, "rewards/1_mean": 7.9511716385518225, "rewards/1_min": -0.9730949401855469, "rewards/1_max": 70.2730484008789, "rewards/2_mean": 7.9511716385518225, "rewards/2_min": -0.9730949401855469, "rewards/2_max": 70.2730484008789, "rewards/3_mean": 7.9511716385518225, "rewards/3_min": -0.9730949401855469, "rewards/3_max": 70.2730484008789, "rewards/4_mean": 7.9511716385518225, "rewards/4_min": -0.9730949401855469, "rewards/4_max": 70.2730484008789}, "hist_stats": {"episode_reward": [0.0, 9.05352783203125, 0.0, 0.0, 18.63330078125, 1.2480392456054688, -0.063629150390625, 0.0, 0.0, 0.0, 30.496978759765625, 42.28003692626953, -0.255523681640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30987548828125, -0.0992584228515625, 31.16623306274414, -0.9730949401855469, 0.0, 0.0, 0.0, 67.9036750793457, 22.585079193115234, 0.0, 0.033447265625, 0.0, 22.291065216064453, 0.0, 61.376277923583984, 26.14989471435547, 0.0, 0.0, 0.4441680908203125, 5.642284393310547, -0.001068115234375, 0.3090476989746094, 63.504234313964844, 0.0, -0.1647491455078125, 6.8690032958984375, 0.0, 0.0, 45.14881134033203, 35.632240295410156, 0.0, -0.14788818359375, 8.068038940429688, 0.0261688232421875, 46.012516021728516, 0.0, 0.0, 0.0, 0.081939697265625, 0.0, 32.96253204345703, 0.0, 0.1444091796875, 0.0, 0.0, 0.0, -0.18585968017578125, 22.268714904785156, 58.29267883300781, -0.3831329345703125, 48.79148483276367, 0.0, 0.0, 0.00875091552734375, 4.621269226074219, 0.0, 0.0936126708984375, 0.0, 8.014404296875, -0.3241729736328125, -0.6703720092773438, 0.0, 0.0, 0.0, 0.0, 56.251800537109375, 0.0, 0.0, -0.019084930419921875, 24.663660049438477, 0.0, 0.0, 69.16148376464844, 70.2730484008789, 8.948558807373047, -0.053863525390625, 0.0, -0.06150054931640625, -0.20992279052734375, 0.0, 0.0, 0.0, 0.0, 0.7834930419921875, 0.0, -0.8829574584960938, 0.0, 0.0, 0.11449432373046875, 0.0, -0.17501068115234375, 16.66949462890625, -0.5669174194335938, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 309, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.649220959836093, "mean_inference_ms": 4.951023695514092, "mean_action_processing_ms": 7.455200352161264, "mean_env_wait_ms": 11.401376337627557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 70.2730484008789, "episode_reward_min": -0.9730949401855469, "episode_reward_mean": 7.9511716385518225, "episode_len_mean": 498.42148760330576, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 9.05352783203125, 0.0, 0.0, 18.63330078125, 1.2480392456054688, -0.063629150390625, 0.0, 0.0, 0.0, 30.496978759765625, 42.28003692626953, -0.255523681640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30987548828125, -0.0992584228515625, 31.16623306274414, -0.9730949401855469, 0.0, 0.0, 0.0, 67.9036750793457, 22.585079193115234, 0.0, 0.033447265625, 0.0, 22.291065216064453, 0.0, 61.376277923583984, 26.14989471435547, 0.0, 0.0, 0.4441680908203125, 5.642284393310547, -0.001068115234375, 0.3090476989746094, 63.504234313964844, 0.0, -0.1647491455078125, 6.8690032958984375, 0.0, 0.0, 45.14881134033203, 35.632240295410156, 0.0, -0.14788818359375, 8.068038940429688, 0.0261688232421875, 46.012516021728516, 0.0, 0.0, 0.0, 0.081939697265625, 0.0, 32.96253204345703, 0.0, 0.1444091796875, 0.0, 0.0, 0.0, -0.18585968017578125, 22.268714904785156, 58.29267883300781, -0.3831329345703125, 48.79148483276367, 0.0, 0.0, 0.00875091552734375, 4.621269226074219, 0.0, 0.0936126708984375, 0.0, 8.014404296875, -0.3241729736328125, -0.6703720092773438, 0.0, 0.0, 0.0, 0.0, 56.251800537109375, 0.0, 0.0, -0.019084930419921875, 24.663660049438477, 0.0, 0.0, 69.16148376464844, 70.2730484008789, 8.948558807373047, -0.053863525390625, 0.0, -0.06150054931640625, -0.20992279052734375, 0.0, 0.0, 0.0, 0.0, 0.7834930419921875, 0.0, -0.8829574584960938, 0.0, 0.0, 0.11449432373046875, 0.0, -0.17501068115234375, 16.66949462890625, -0.5669174194335938, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 309, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.649220959836093, "mean_inference_ms": 4.951023695514092, "mean_action_processing_ms": 7.455200352161264, "mean_env_wait_ms": 11.401376337627557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22752653, "num_agent_steps_trained": 22752653, "num_env_steps_sampled": 22752653, "num_env_steps_trained": 22752653, "num_env_steps_sampled_this_iter": 60309, "num_env_steps_trained_this_iter": 60309, "timesteps_total": 22752653, "num_steps_trained_this_iter": 60309, "agent_timesteps_total": 22752653, "timers": {"training_iteration_time_ms": 47719.397, "load_time_ms": 46.519, "load_throughput": 1306756.954, "learn_time_ms": 27344.193, "learn_throughput": 2223.097, "synch_weights_time_ms": 9.543}, "counters": {"num_env_steps_sampled": 22752653, "num_env_steps_trained": 22752653, "num_agent_steps_sampled": 22752653, "num_agent_steps_trained": 22752653}, "done": false, "episodes_total": 46083, "training_iteration": 375, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-05-23", "timestamp": 1735110323, "time_this_iter_s": 50.68496060371399, "time_total_s": 11428.045007705688, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE5600>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3C73F40>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2570.9151089191437, "timesteps_since_restore": 0, "iterations_since_restore": 54, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 26.616901408450705, "ram_util_percent": 98.03943661971827}}
{"custom_metrics": {"rewards/0_mean": 11.166843646910133, "rewards/0_min": -0.8272781372070312, "rewards/0_max": 79.7557144165039, "rewards/1_mean": 11.166843646910133, "rewards/1_min": -0.8272781372070312, "rewards/1_max": 79.7557144165039, "rewards/2_mean": 11.166843646910133, "rewards/2_min": -0.8272781372070312, "rewards/2_max": 79.7557144165039, "rewards/3_mean": 11.166843646910133, "rewards/3_min": -0.8272781372070312, "rewards/3_max": 79.7557144165039, "rewards/4_mean": 11.166843646910133, "rewards/4_min": -0.8272781372070312, "rewards/4_max": 79.7557144165039}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10230649355257594, "policy_loss": -0.012183159746096602, "vf_loss": 0.13520535429318745, "vf_explained_var": 0.986477855368266, "kl": 0.012886135436091867, "entropy": 22.59810540032765, "entropy_coeff": 0.01, "grad_gnorm": 1.521766740958842}, "model": {}, "num_grad_updates_lifetime": 34560.5, "diff_num_grad_updates_vs_sampler_policy": 34559.5}}, "num_env_steps_sampled": 22813617, "num_env_steps_trained": 22813617, "num_agent_steps_sampled": 22813617, "num_agent_steps_trained": 22813617}, "sampler_results": {"episode_reward_max": 79.7557144165039, "episode_reward_min": -0.8272781372070312, "episode_reward_mean": 11.166843646910133, "episode_len_mean": 495.6422764227642, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.166843646910133, "rewards/0_min": -0.8272781372070312, "rewards/0_max": 79.7557144165039, "rewards/1_mean": 11.166843646910133, "rewards/1_min": -0.8272781372070312, "rewards/1_max": 79.7557144165039, "rewards/2_mean": 11.166843646910133, "rewards/2_min": -0.8272781372070312, "rewards/2_max": 79.7557144165039, "rewards/3_mean": 11.166843646910133, "rewards/3_min": -0.8272781372070312, "rewards/3_max": 79.7557144165039, "rewards/4_mean": 11.166843646910133, "rewards/4_min": -0.8272781372070312, "rewards/4_max": 79.7557144165039}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 22.445533752441406, 0.0, 0.0, 0.0, -0.364105224609375, 0.0, 0.0, 0.7146759033203125, 5.8968658447265625, -0.112579345703125, 4.850860595703125, 0.0, -0.1688995361328125, -0.8272781372070312, 59.30712127685547, 0.0, 0.0, 0.0, -0.439971923828125, 0.2633514404296875, 20.167699813842773, 0.0, -0.48314666748046875, 0.0, 49.2867546081543, 0.0, 0.0, 43.45289993286133, 0.0, 0.0, 32.69125175476074, 0.0, 0.0, 0.2395782470703125, 63.73997497558594, 13.820526123046875, 0.0, 0.0, 21.762054443359375, 0.0, 23.923187255859375, -0.18450927734375, 0.0, 0.0, 30.874244689941406, 67.61239624023438, 9.453361511230469, 0.0, 0.17390823364257812, 0.0, 14.380102157592773, 64.08572387695312, -0.7194671630859375, 5.605384826660156, 6.464958190917969, 11.99395751953125, 0.21443939208984375, 0.24075698852539062, 71.29438018798828, 0.0, 56.88887023925781, -0.3221893310546875, -0.4545097351074219, 0.0, 0.0, 0.0, 37.14568328857422, -0.052001953125, -0.37758636474609375, 12.306625366210938, 0.09728240966796875, 18.82209014892578, 0.0, 0.0, 24.70501136779785, 0.0, 0.0, 9.515090942382812, 0.0, 1.6707534790039062, 28.70562744140625, 0.0, 9.09677505493164, 0.422332763671875, 0.0, 0.0, 11.716968536376953, 0.0, 58.69938659667969, 58.26863098144531, 0.0, 0.0, 0.19586181640625, 36.65279006958008, 16.809389114379883, 0.0, 0.0, 0.0, 0.0, 7.498313903808594, 40.68107986450195, 0.0, 79.7557144165039, 0.0, 0.0, 16.2703857421875, 61.4227294921875, 0.0, 0.19538116455078125, 0.0, 0.0, 0.14117431640625, 0.0, -0.30810546875, 17.238311767578125, 19.160926818847656, 0.0, 50.161109924316406, 59.13587188720703], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500, 340, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 391, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 282, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.661396468632168, "mean_inference_ms": 4.957563240294423, "mean_action_processing_ms": 7.456941380803937, "mean_env_wait_ms": 11.410028618749216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 79.7557144165039, "episode_reward_min": -0.8272781372070312, "episode_reward_mean": 11.166843646910133, "episode_len_mean": 495.6422764227642, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 22.445533752441406, 0.0, 0.0, 0.0, -0.364105224609375, 0.0, 0.0, 0.7146759033203125, 5.8968658447265625, -0.112579345703125, 4.850860595703125, 0.0, -0.1688995361328125, -0.8272781372070312, 59.30712127685547, 0.0, 0.0, 0.0, -0.439971923828125, 0.2633514404296875, 20.167699813842773, 0.0, -0.48314666748046875, 0.0, 49.2867546081543, 0.0, 0.0, 43.45289993286133, 0.0, 0.0, 32.69125175476074, 0.0, 0.0, 0.2395782470703125, 63.73997497558594, 13.820526123046875, 0.0, 0.0, 21.762054443359375, 0.0, 23.923187255859375, -0.18450927734375, 0.0, 0.0, 30.874244689941406, 67.61239624023438, 9.453361511230469, 0.0, 0.17390823364257812, 0.0, 14.380102157592773, 64.08572387695312, -0.7194671630859375, 5.605384826660156, 6.464958190917969, 11.99395751953125, 0.21443939208984375, 0.24075698852539062, 71.29438018798828, 0.0, 56.88887023925781, -0.3221893310546875, -0.4545097351074219, 0.0, 0.0, 0.0, 37.14568328857422, -0.052001953125, -0.37758636474609375, 12.306625366210938, 0.09728240966796875, 18.82209014892578, 0.0, 0.0, 24.70501136779785, 0.0, 0.0, 9.515090942382812, 0.0, 1.6707534790039062, 28.70562744140625, 0.0, 9.09677505493164, 0.422332763671875, 0.0, 0.0, 11.716968536376953, 0.0, 58.69938659667969, 58.26863098144531, 0.0, 0.0, 0.19586181640625, 36.65279006958008, 16.809389114379883, 0.0, 0.0, 0.0, 0.0, 7.498313903808594, 40.68107986450195, 0.0, 79.7557144165039, 0.0, 0.0, 16.2703857421875, 61.4227294921875, 0.0, 0.19538116455078125, 0.0, 0.0, 0.14117431640625, 0.0, -0.30810546875, 17.238311767578125, 19.160926818847656, 0.0, 50.161109924316406, 59.13587188720703], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500, 340, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 391, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 282, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.661396468632168, "mean_inference_ms": 4.957563240294423, "mean_action_processing_ms": 7.456941380803937, "mean_env_wait_ms": 11.410028618749216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22813617, "num_agent_steps_trained": 22813617, "num_env_steps_sampled": 22813617, "num_env_steps_trained": 22813617, "num_env_steps_sampled_this_iter": 60964, "num_env_steps_trained_this_iter": 60964, "timesteps_total": 22813617, "num_steps_trained_this_iter": 60964, "agent_timesteps_total": 22813617, "timers": {"training_iteration_time_ms": 47898.571, "load_time_ms": 45.764, "load_throughput": 1328875.588, "learn_time_ms": 27421.5, "learn_throughput": 2217.763, "synch_weights_time_ms": 10.639}, "counters": {"num_env_steps_sampled": 22813617, "num_env_steps_trained": 22813617, "num_agent_steps_sampled": 22813617, "num_agent_steps_trained": 22813617}, "done": false, "episodes_total": 46206, "training_iteration": 376, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-06-12", "timestamp": 1735110372, "time_this_iter_s": 48.17273283004761, "time_total_s": 11476.217740535736, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B50100>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2619.0878417491913, "timesteps_since_restore": 0, "iterations_since_restore": 55, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.994117647058825, "ram_util_percent": 98.43529411764708}}
{"custom_metrics": {"rewards/0_mean": 9.596520568847657, "rewards/0_min": -0.6943206787109375, "rewards/0_max": 71.12592315673828, "rewards/1_mean": 9.596520568847657, "rewards/1_min": -0.6943206787109375, "rewards/1_max": 71.12592315673828, "rewards/2_mean": 9.596520568847657, "rewards/2_min": -0.6943206787109375, "rewards/2_max": 71.12592315673828, "rewards/3_mean": 9.596520568847657, "rewards/3_min": -0.6943206787109375, "rewards/3_max": 71.12592315673828, "rewards/4_mean": 9.596520568847657, "rewards/4_min": -0.6943206787109375, "rewards/4_max": 71.12592315673828}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.10667116599444179, "policy_loss": -0.001015983130092974, "vf_loss": 0.12203366311232525, "vf_explained_var": 0.9736873751657981, "kl": 0.012009712049082197, "entropy": 22.82968438607675, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.244409735136562}, "model": {}, "num_grad_updates_lifetime": 35213.0, "diff_num_grad_updates_vs_sampler_policy": 35212.0}}, "num_env_steps_sampled": 22875149, "num_env_steps_trained": 22875149, "num_agent_steps_sampled": 22875149, "num_agent_steps_trained": 22875149}, "sampler_results": {"episode_reward_max": 71.12592315673828, "episode_reward_min": -0.6943206787109375, "episode_reward_mean": 9.596520568847657, "episode_len_mean": 492.256, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.596520568847657, "rewards/0_min": -0.6943206787109375, "rewards/0_max": 71.12592315673828, "rewards/1_mean": 9.596520568847657, "rewards/1_min": -0.6943206787109375, "rewards/1_max": 71.12592315673828, "rewards/2_mean": 9.596520568847657, "rewards/2_min": -0.6943206787109375, "rewards/2_max": 71.12592315673828, "rewards/3_mean": 9.596520568847657, "rewards/3_min": -0.6943206787109375, "rewards/3_max": 71.12592315673828, "rewards/4_mean": 9.596520568847657, "rewards/4_min": -0.6943206787109375, "rewards/4_max": 71.12592315673828}, "hist_stats": {"episode_reward": [3.340545654296875, 0.0, -0.159393310546875, 17.205230712890625, 6.860355377197266, 0.0, 11.5797119140625, 0.0, 26.659393310546875, 0.0, 0.0, 15.850139617919922, 29.255142211914062, 7.431205749511719, 0.0, 71.12592315673828, 21.856752395629883, 14.953582763671875, 48.029775619506836, -0.6943206787109375, 0.0, 0.0, 0.0, 3.285736083984375, 0.3762779235839844, 0.4564208984375, 26.82634735107422, 0.68109130859375, 0.0, 0.0, 0.0, 0.0, 0.19574737548828125, 0.0, 0.0359954833984375, 65.05783081054688, 0.0, 0.0, 21.061927795410156, 0.0727386474609375, 0.9788742065429688, 0.0, 28.062450408935547, 34.788475036621094, 0.0, 29.70440673828125, 68.10897827148438, 3.7637901306152344, 0.3042449951171875, -0.262298583984375, 64.99250793457031, 0.1626434326171875, 34.75489807128906, 56.10108947753906, 0.0, 0.0, 0.0, 47.15345001220703, 20.58460235595703, 0.0, 0.0, 0.0, 0.0909423828125, 45.893184661865234, -0.0932464599609375, 0.5410671234130859, 20.851272583007812, 0.0, 0.0, -0.2369842529296875, 0.0, 0.0, -0.1138153076171875, 0.0, 0.0, 0.0, 0.0, 0.0, 23.585309982299805, 0.0, -0.6116790771484375, 55.415035247802734, 0.0, 0.0, 0.0, 0.0, -0.0216217041015625, 0.0, 0.0, 0.0, 16.050094604492188, 0.0, -0.266021728515625, -0.08079910278320312, 0.0, 0.374298095703125, 0.0, 0.0, 0.0, 0.0, 0.559600830078125, 6.121925354003906, 59.5629997253418, 0.0, 0.0, 0.0, -0.08138275146484375, 33.29530334472656, 0.0, 0.0, 0.0, 44.46060371398926, 20.90435791015625, 0.0, 0.055950164794921875, 17.17397117614746, -0.056671142578125, 0.02300262451171875, 0.2247772216796875, -0.411590576171875, 51.40312957763672, 0.0, -0.15177154541015625, 0.0, 24.56155776977539], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 393, 500, 411, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 367, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 307, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 300, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.672270297635595, "mean_inference_ms": 4.954646735167284, "mean_action_processing_ms": 7.460127152027141, "mean_env_wait_ms": 11.409127208157514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 71.12592315673828, "episode_reward_min": -0.6943206787109375, "episode_reward_mean": 9.596520568847657, "episode_len_mean": 492.256, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [3.340545654296875, 0.0, -0.159393310546875, 17.205230712890625, 6.860355377197266, 0.0, 11.5797119140625, 0.0, 26.659393310546875, 0.0, 0.0, 15.850139617919922, 29.255142211914062, 7.431205749511719, 0.0, 71.12592315673828, 21.856752395629883, 14.953582763671875, 48.029775619506836, -0.6943206787109375, 0.0, 0.0, 0.0, 3.285736083984375, 0.3762779235839844, 0.4564208984375, 26.82634735107422, 0.68109130859375, 0.0, 0.0, 0.0, 0.0, 0.19574737548828125, 0.0, 0.0359954833984375, 65.05783081054688, 0.0, 0.0, 21.061927795410156, 0.0727386474609375, 0.9788742065429688, 0.0, 28.062450408935547, 34.788475036621094, 0.0, 29.70440673828125, 68.10897827148438, 3.7637901306152344, 0.3042449951171875, -0.262298583984375, 64.99250793457031, 0.1626434326171875, 34.75489807128906, 56.10108947753906, 0.0, 0.0, 0.0, 47.15345001220703, 20.58460235595703, 0.0, 0.0, 0.0, 0.0909423828125, 45.893184661865234, -0.0932464599609375, 0.5410671234130859, 20.851272583007812, 0.0, 0.0, -0.2369842529296875, 0.0, 0.0, -0.1138153076171875, 0.0, 0.0, 0.0, 0.0, 0.0, 23.585309982299805, 0.0, -0.6116790771484375, 55.415035247802734, 0.0, 0.0, 0.0, 0.0, -0.0216217041015625, 0.0, 0.0, 0.0, 16.050094604492188, 0.0, -0.266021728515625, -0.08079910278320312, 0.0, 0.374298095703125, 0.0, 0.0, 0.0, 0.0, 0.559600830078125, 6.121925354003906, 59.5629997253418, 0.0, 0.0, 0.0, -0.08138275146484375, 33.29530334472656, 0.0, 0.0, 0.0, 44.46060371398926, 20.90435791015625, 0.0, 0.055950164794921875, 17.17397117614746, -0.056671142578125, 0.02300262451171875, 0.2247772216796875, -0.411590576171875, 51.40312957763672, 0.0, -0.15177154541015625, 0.0, 24.56155776977539], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 393, 500, 411, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 367, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 307, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 300, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.672270297635595, "mean_inference_ms": 4.954646735167284, "mean_action_processing_ms": 7.460127152027141, "mean_env_wait_ms": 11.409127208157514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22875149, "num_agent_steps_trained": 22875149, "num_env_steps_sampled": 22875149, "num_env_steps_trained": 22875149, "num_env_steps_sampled_this_iter": 61532, "num_env_steps_trained_this_iter": 61532, "timesteps_total": 22875149, "num_steps_trained_this_iter": 61532, "agent_timesteps_total": 22875149, "timers": {"training_iteration_time_ms": 48233.555, "load_time_ms": 49.042, "load_throughput": 1241406.208, "learn_time_ms": 27652.704, "learn_throughput": 2201.647, "synch_weights_time_ms": 10.155}, "counters": {"num_env_steps_sampled": 22875149, "num_env_steps_trained": 22875149, "num_agent_steps_sampled": 22875149, "num_agent_steps_trained": 22875149}, "done": false, "episodes_total": 46331, "training_iteration": 377, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-07-01", "timestamp": 1735110421, "time_this_iter_s": 48.923524379730225, "time_total_s": 11525.141264915466, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0AA40>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E37553F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2668.0113661289215, "timesteps_since_restore": 0, "iterations_since_restore": 56, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 23.036764705882348, "ram_util_percent": 97.0470588235294}}
{"custom_metrics": {"rewards/0_mean": 9.304504549600244, "rewards/0_min": -0.4091644287109375, "rewards/0_max": 77.21007919311523, "rewards/1_mean": 9.304504549600244, "rewards/1_min": -0.4091644287109375, "rewards/1_max": 77.21007919311523, "rewards/2_mean": 9.304504549600244, "rewards/2_min": -0.4091644287109375, "rewards/2_max": 77.21007919311523, "rewards/3_mean": 9.304504549600244, "rewards/3_min": -0.4091644287109375, "rewards/3_max": 77.21007919311523, "rewards/4_mean": 9.304504549600244, "rewards/4_min": -0.4091644287109375, "rewards/4_max": 77.21007919311523}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.161409892272613, "policy_loss": -0.0157729550663914, "vf_loss": 0.08485319254890321, "vf_explained_var": 0.9839379632283771, "kl": 0.011122956746331757, "entropy": 23.105323479667543, "entropy_coeff": 0.01, "grad_gnorm": 1.3013817733242399}, "model": {}, "num_grad_updates_lifetime": 35865.5, "diff_num_grad_updates_vs_sampler_policy": 35864.5}}, "num_env_steps_sampled": 22936226, "num_env_steps_trained": 22936226, "num_agent_steps_sampled": 22936226, "num_agent_steps_trained": 22936226}, "sampler_results": {"episode_reward_max": 77.21007919311523, "episode_reward_min": -0.4091644287109375, "episode_reward_mean": 9.304504549600244, "episode_len_mean": 496.5609756097561, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.304504549600244, "rewards/0_min": -0.4091644287109375, "rewards/0_max": 77.21007919311523, "rewards/1_mean": 9.304504549600244, "rewards/1_min": -0.4091644287109375, "rewards/1_max": 77.21007919311523, "rewards/2_mean": 9.304504549600244, "rewards/2_min": -0.4091644287109375, "rewards/2_max": 77.21007919311523, "rewards/3_mean": 9.304504549600244, "rewards/3_min": -0.4091644287109375, "rewards/3_max": 77.21007919311523, "rewards/4_mean": 9.304504549600244, "rewards/4_min": -0.4091644287109375, "rewards/4_max": 77.21007919311523}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 2.4657669067382812, 0.0, 58.55063247680664, 0.0, 53.064796447753906, 0.0, 0.36119842529296875, 21.62169647216797, 0.0, 0.0, 0.0, 25.133262634277344, 0.0, 4.753501892089844, 1.6891860961914062, 24.441909790039062, 0.0, 0.0, 2.946746826171875, 0.1245880126953125, 28.49433135986328, -0.4091644287109375, 14.355316162109375, 34.16705322265625, 0.0, 0.0, 24.30786895751953, 0.0, -0.1625518798828125, 0.0, 0.0, 0.0, -0.0803375244140625, 9.576614379882812, 0.0, 0.0, 0.0, 0.3097076416015625, 0.0, -0.1504974365234375, 51.120582580566406, 0.0, 62.33274459838867, 0.0, -0.046722412109375, 0.3817138671875, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14806365966796875, 2.0325164794921875, 0.0, 0.0, 58.24424743652344, 61.17848205566406, 3.7497711181640625, 5.590400695800781, 0.3540840148925781, -0.05084991455078125, 0.0681610107421875, 77.21007919311523, 0.0, -0.044963836669921875, 0.032928466796875, 0.0, 0.0, 0.0, 25.604965209960938, 65.2607536315918, 0.0, 0.0, 0.2344207763671875, 38.179054260253906, 26.89889144897461, 0.0, 0.40015411376953125, 0.0, 0.0, 0.0, 32.29882049560547, 0.0, 67.11030578613281, 0.0, 0.0, 0.0, 0.0, -0.0556793212890625, 0.127777099609375, 20.14008331298828, 0.0, 17.869491577148438, 0.0, 0.0, 0.1822052001953125, 50.19801139831543, 0.0, 0.0, -0.1868743896484375, 47.38340759277344, 50.73414993286133, 8.021589279174805, 4.672748565673828, 0.047664642333984375, 13.545341491699219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.750946044921875, 0.0, 0.0, 0.0, 20.9322509765625, 0.5368423461914062, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 414, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 276, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.662736662665463, "mean_inference_ms": 4.953205751884766, "mean_action_processing_ms": 7.450977885165994, "mean_env_wait_ms": 11.40372422766505, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 77.21007919311523, "episode_reward_min": -0.4091644287109375, "episode_reward_mean": 9.304504549600244, "episode_len_mean": 496.5609756097561, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 2.4657669067382812, 0.0, 58.55063247680664, 0.0, 53.064796447753906, 0.0, 0.36119842529296875, 21.62169647216797, 0.0, 0.0, 0.0, 25.133262634277344, 0.0, 4.753501892089844, 1.6891860961914062, 24.441909790039062, 0.0, 0.0, 2.946746826171875, 0.1245880126953125, 28.49433135986328, -0.4091644287109375, 14.355316162109375, 34.16705322265625, 0.0, 0.0, 24.30786895751953, 0.0, -0.1625518798828125, 0.0, 0.0, 0.0, -0.0803375244140625, 9.576614379882812, 0.0, 0.0, 0.0, 0.3097076416015625, 0.0, -0.1504974365234375, 51.120582580566406, 0.0, 62.33274459838867, 0.0, -0.046722412109375, 0.3817138671875, 0.0, 0.0, 0.0, 0.0, 0.0, -0.14806365966796875, 2.0325164794921875, 0.0, 0.0, 58.24424743652344, 61.17848205566406, 3.7497711181640625, 5.590400695800781, 0.3540840148925781, -0.05084991455078125, 0.0681610107421875, 77.21007919311523, 0.0, -0.044963836669921875, 0.032928466796875, 0.0, 0.0, 0.0, 25.604965209960938, 65.2607536315918, 0.0, 0.0, 0.2344207763671875, 38.179054260253906, 26.89889144897461, 0.0, 0.40015411376953125, 0.0, 0.0, 0.0, 32.29882049560547, 0.0, 67.11030578613281, 0.0, 0.0, 0.0, 0.0, -0.0556793212890625, 0.127777099609375, 20.14008331298828, 0.0, 17.869491577148438, 0.0, 0.0, 0.1822052001953125, 50.19801139831543, 0.0, 0.0, -0.1868743896484375, 47.38340759277344, 50.73414993286133, 8.021589279174805, 4.672748565673828, 0.047664642333984375, 13.545341491699219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.750946044921875, 0.0, 0.0, 0.0, 20.9322509765625, 0.5368423461914062, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 414, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 276, 500, 500, 500, 387, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.662736662665463, "mean_inference_ms": 4.953205751884766, "mean_action_processing_ms": 7.450977885165994, "mean_env_wait_ms": 11.40372422766505, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22936226, "num_agent_steps_trained": 22936226, "num_env_steps_sampled": 22936226, "num_env_steps_trained": 22936226, "num_env_steps_sampled_this_iter": 61077, "num_env_steps_trained_this_iter": 61077, "timesteps_total": 22936226, "num_steps_trained_this_iter": 61077, "agent_timesteps_total": 22936226, "timers": {"training_iteration_time_ms": 48478.957, "load_time_ms": 49.16, "load_throughput": 1239125.675, "learn_time_ms": 27819.812, "learn_throughput": 2189.648, "synch_weights_time_ms": 10.154}, "counters": {"num_env_steps_sampled": 22936226, "num_env_steps_trained": 22936226, "num_agent_steps_sampled": 22936226, "num_agent_steps_trained": 22936226}, "done": false, "episodes_total": 46454, "training_iteration": 378, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-07-49", "timestamp": 1735110469, "time_this_iter_s": 47.87487483024597, "time_total_s": 11573.016139745712, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B53640>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CCF760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2715.8862409591675, "timesteps_since_restore": 0, "iterations_since_restore": 57, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.77794117647059, "ram_util_percent": 96.86911764705884}}
{"custom_metrics": {"rewards/0_mean": 10.582078272296537, "rewards/0_min": -1.7305831909179688, "rewards/0_max": 76.5942611694336, "rewards/1_mean": 10.582078272296537, "rewards/1_min": -1.7305831909179688, "rewards/1_max": 76.5942611694336, "rewards/2_mean": 10.582078272296537, "rewards/2_min": -1.7305831909179688, "rewards/2_max": 76.5942611694336, "rewards/3_mean": 10.582078272296537, "rewards/3_min": -1.7305831909179688, "rewards/3_max": 76.5942611694336, "rewards/4_mean": 10.582078272296537, "rewards/4_min": -1.7305831909179688, "rewards/4_max": 76.5942611694336}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13080390074127723, "policy_loss": -0.01315180713695193, "vf_loss": 0.1114820247663865, "vf_explained_var": 0.9901739134674981, "kl": 0.01159578777021832, "entropy": 22.97211616152809, "entropy_coeff": 0.01, "grad_gnorm": 1.4056268627208377}, "model": {}, "num_grad_updates_lifetime": 36495.5, "diff_num_grad_updates_vs_sampler_policy": 36494.5}}, "num_env_steps_sampled": 22997325, "num_env_steps_trained": 22997325, "num_agent_steps_sampled": 22997325, "num_agent_steps_trained": 22997325}, "sampler_results": {"episode_reward_max": 76.5942611694336, "episode_reward_min": -1.7305831909179688, "episode_reward_mean": 10.582078272296537, "episode_len_mean": 492.73387096774195, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.582078272296537, "rewards/0_min": -1.7305831909179688, "rewards/0_max": 76.5942611694336, "rewards/1_mean": 10.582078272296537, "rewards/1_min": -1.7305831909179688, "rewards/1_max": 76.5942611694336, "rewards/2_mean": 10.582078272296537, "rewards/2_min": -1.7305831909179688, "rewards/2_max": 76.5942611694336, "rewards/3_mean": 10.582078272296537, "rewards/3_min": -1.7305831909179688, "rewards/3_max": 76.5942611694336, "rewards/4_mean": 10.582078272296537, "rewards/4_min": -1.7305831909179688, "rewards/4_max": 76.5942611694336}, "hist_stats": {"episode_reward": [-0.04796600341796875, 0.0, 10.375648498535156, 0.00710296630859375, 0.0067138671875, 11.759063720703125, 0.0, 68.3157958984375, 0.0, -0.12566757202148438, 0.0, 0.0, 0.0, 41.843841552734375, 40.88768005371094, 67.1855239868164, 0.0, 0.0, -0.10333251953125, 55.45457458496094, 0.11288833618164062, -0.04460906982421875, -0.1311187744140625, 0.0, 47.11064910888672, 0.0, 0.0, 0.0, 0.0, 0.0, 13.479515075683594, 12.139411926269531, 0.0, -0.8109283447265625, 30.24371337890625, 0.509185791015625, 0.06296539306640625, 57.00196075439453, 15.222320556640625, 49.68811798095703, 0.0, 0.0, 29.713930130004883, 52.714263916015625, 0.0, 0.0, 2.3182525634765625, 5.91357421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.548583984375, 30.1868896484375, -0.1074981689453125, 33.735870361328125, 0.0, 0.0, -0.1550750732421875, 0.0, 47.85578155517578, -0.0911712646484375, 31.18152618408203, 5.7128143310546875, -0.858917236328125, 0.24660491943359375, 0.0, 33.95286560058594, 0.0, 0.0, -0.14342117309570312, 0.0, 0.0, 0.0, 0.0, 17.722930908203125, -0.185638427734375, 0.482025146484375, 0.0, -0.2514190673828125, 20.579151153564453, 17.271377563476562, -0.0182037353515625, 0.0, 0.5450439453125, 6.738555908203125, 27.636184692382812, 76.5942611694336, 0.0, 0.0, -0.8160476684570312, 33.64679718017578, 2.313037872314453, 0.0, 26.092117309570312, 33.57763671875, 44.92852783203125, 0.0, 0.0, 0.0, -1.7305831909179688, -0.139739990234375, 0.0, 0.0, 0.0, 63.05882263183594, 7.5130767822265625, 27.972515106201172, 0.0, 0.03838348388671875, 0.0, 33.83241271972656, -0.321380615234375, 0.0, 0.0, 35.42860412597656, 0.0, -0.3372955322265625, 0.0, 0.0, 3.1386260986328125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 392, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 333, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 299, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 75, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.662858486019706, "mean_inference_ms": 4.948715956298492, "mean_action_processing_ms": 7.451805375718055, "mean_env_wait_ms": 11.397660022355504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.5942611694336, "episode_reward_min": -1.7305831909179688, "episode_reward_mean": 10.582078272296537, "episode_len_mean": 492.73387096774195, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.04796600341796875, 0.0, 10.375648498535156, 0.00710296630859375, 0.0067138671875, 11.759063720703125, 0.0, 68.3157958984375, 0.0, -0.12566757202148438, 0.0, 0.0, 0.0, 41.843841552734375, 40.88768005371094, 67.1855239868164, 0.0, 0.0, -0.10333251953125, 55.45457458496094, 0.11288833618164062, -0.04460906982421875, -0.1311187744140625, 0.0, 47.11064910888672, 0.0, 0.0, 0.0, 0.0, 0.0, 13.479515075683594, 12.139411926269531, 0.0, -0.8109283447265625, 30.24371337890625, 0.509185791015625, 0.06296539306640625, 57.00196075439453, 15.222320556640625, 49.68811798095703, 0.0, 0.0, 29.713930130004883, 52.714263916015625, 0.0, 0.0, 2.3182525634765625, 5.91357421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.548583984375, 30.1868896484375, -0.1074981689453125, 33.735870361328125, 0.0, 0.0, -0.1550750732421875, 0.0, 47.85578155517578, -0.0911712646484375, 31.18152618408203, 5.7128143310546875, -0.858917236328125, 0.24660491943359375, 0.0, 33.95286560058594, 0.0, 0.0, -0.14342117309570312, 0.0, 0.0, 0.0, 0.0, 17.722930908203125, -0.185638427734375, 0.482025146484375, 0.0, -0.2514190673828125, 20.579151153564453, 17.271377563476562, -0.0182037353515625, 0.0, 0.5450439453125, 6.738555908203125, 27.636184692382812, 76.5942611694336, 0.0, 0.0, -0.8160476684570312, 33.64679718017578, 2.313037872314453, 0.0, 26.092117309570312, 33.57763671875, 44.92852783203125, 0.0, 0.0, 0.0, -1.7305831909179688, -0.139739990234375, 0.0, 0.0, 0.0, 63.05882263183594, 7.5130767822265625, 27.972515106201172, 0.0, 0.03838348388671875, 0.0, 33.83241271972656, -0.321380615234375, 0.0, 0.0, 35.42860412597656, 0.0, -0.3372955322265625, 0.0, 0.0, 3.1386260986328125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 392, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 333, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 299, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 75, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.662858486019706, "mean_inference_ms": 4.948715956298492, "mean_action_processing_ms": 7.451805375718055, "mean_env_wait_ms": 11.397660022355504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22997325, "num_agent_steps_trained": 22997325, "num_env_steps_sampled": 22997325, "num_env_steps_trained": 22997325, "num_env_steps_sampled_this_iter": 61099, "num_env_steps_trained_this_iter": 61099, "timesteps_total": 22997325, "num_steps_trained_this_iter": 61099, "agent_timesteps_total": 22997325, "timers": {"training_iteration_time_ms": 48578.017, "load_time_ms": 50.094, "load_throughput": 1216419.825, "learn_time_ms": 27795.939, "learn_throughput": 2192.234, "synch_weights_time_ms": 10.148}, "counters": {"num_env_steps_sampled": 22997325, "num_env_steps_trained": 22997325, "num_agent_steps_sampled": 22997325, "num_agent_steps_trained": 22997325}, "done": false, "episodes_total": 46578, "training_iteration": 379, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-08-37", "timestamp": 1735110517, "time_this_iter_s": 47.804413080215454, "time_total_s": 11620.820552825928, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE6290>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E37553F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2763.690654039383, "timesteps_since_restore": 0, "iterations_since_restore": 58, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.076119402985075, "ram_util_percent": 97.16268656716419}}
{"evaluation": {"episode_reward_max": 40.5479736328125, "episode_reward_min": 40.5479736328125, "episode_reward_mean": 40.5479736328125, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 40.5479736328125, "rewards/0_min": 40.5479736328125, "rewards/0_max": 40.5479736328125, "rewards/1_mean": 40.5479736328125, "rewards/1_min": 40.5479736328125, "rewards/1_max": 40.5479736328125, "rewards/2_mean": 40.5479736328125, "rewards/2_min": 40.5479736328125, "rewards/2_max": 40.5479736328125, "rewards/3_mean": 40.5479736328125, "rewards/3_min": 40.5479736328125, "rewards/3_max": 40.5479736328125, "rewards/4_mean": 40.5479736328125, "rewards/4_min": 40.5479736328125, "rewards/4_max": 40.5479736328125}, "hist_stats": {"episode_reward": [40.5479736328125], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7004302415305864, "mean_inference_ms": 3.4682666872008965, "mean_action_processing_ms": 0.4785592467402284, "mean_env_wait_ms": 6.025839082361599, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 10.036935217012235, "rewards/0_min": -0.8872528076171875, "rewards/0_max": 89.19645690917969, "rewards/1_mean": 10.036935217012235, "rewards/1_min": -0.8872528076171875, "rewards/1_max": 89.19645690917969, "rewards/2_mean": 10.036935217012235, "rewards/2_min": -0.8872528076171875, "rewards/2_max": 89.19645690917969, "rewards/3_mean": 10.036935217012235, "rewards/3_min": -0.8872528076171875, "rewards/3_max": 89.19645690917969, "rewards/4_mean": 10.036935217012235, "rewards/4_min": -0.8872528076171875, "rewards/4_max": 89.19645690917969}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10431570537881589, "policy_loss": 0.003628151153495151, "vf_loss": 0.1304580395627353, "vf_explained_var": 0.9872318277283321, "kl": 0.01233694386254582, "entropy": 23.902645898243737, "entropy_coeff": 0.01, "grad_gnorm": 1.6217289477586747}, "model": {}, "num_grad_updates_lifetime": 37125.5, "diff_num_grad_updates_vs_sampler_policy": 37124.5}}, "num_env_steps_sampled": 23057979, "num_env_steps_trained": 23057979, "num_agent_steps_sampled": 23057979, "num_agent_steps_trained": 23057979}, "sampler_results": {"episode_reward_max": 89.19645690917969, "episode_reward_min": -0.8872528076171875, "episode_reward_mean": 10.036935217012235, "episode_len_mean": 493.1219512195122, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.036935217012235, "rewards/0_min": -0.8872528076171875, "rewards/0_max": 89.19645690917969, "rewards/1_mean": 10.036935217012235, "rewards/1_min": -0.8872528076171875, "rewards/1_max": 89.19645690917969, "rewards/2_mean": 10.036935217012235, "rewards/2_min": -0.8872528076171875, "rewards/2_max": 89.19645690917969, "rewards/3_mean": 10.036935217012235, "rewards/3_min": -0.8872528076171875, "rewards/3_max": 89.19645690917969, "rewards/4_mean": 10.036935217012235, "rewards/4_min": -0.8872528076171875, "rewards/4_max": 89.19645690917969}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.23348236083984375, 0.0, 0.0, 0.0, 17.99578285217285, -0.22608184814453125, 0.0, 0.0, 0.0, 1.448333740234375, 18.165359497070312, 0.0, 4.3056182861328125, 0.0, 0.0, 52.15153503417969, 0.0, 34.33928680419922, 0.01055908203125, 0.0, 14.755950927734375, 0.0, 0.0, 0.0, 0.20300674438476562, 0.0, 9.768388748168945, 38.058937072753906, -0.12061691284179688, 0.0, 0.0, 0.0, 0.0, -0.4497222900390625, 8.715312957763672, 12.309226989746094, 10.8438720703125, 0.0, 2.832366943359375, 6.393573760986328, 12.152999877929688, 0.0, 42.500633239746094, 0.0, 3.0892257690429688, 0.0, 2.4118499755859375, 0.0, -0.247100830078125, -0.8872528076171875, 0.0, -0.021823883056640625, 0.0, 0.0, 45.893035888671875, 0.0, 0.0, 0.0, 24.877838134765625, 0.0, 0.0, 65.27919006347656, 52.20800018310547, 0.0, 39.40737533569336, 0.08626556396484375, -0.0115509033203125, 0.0, 68.98282241821289, 30.21173858642578, 26.075206756591797, 0.0, 51.632469177246094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.18046569824219, 5.9989013671875, -0.0331268310546875, -0.1243438720703125, 45.324729919433594, 28.210174560546875, 29.85491180419922, 0.0852203369140625, 0.128204345703125, -0.06918716430664062, 53.45600891113281, 0.0, 0.0, 0.0, 76.99856567382812, 0.0, 0.0748748779296875, 0.0, 0.1402130126953125, 0.0, -0.01723480224609375, 0.0, 0.0, 0.9752655029296875, 0.0, 0.0, 0.0, 89.19645690917969, 0.0, 0.0, 3.313983917236328, 0.0, 39.113075256347656, 54.66918754577637, 0.0, 0.3277740478515625, 10.745979309082031, 0.0, 0.0, 0.0, 53.33515167236328, -0.2503509521484375], "episode_lengths": [500, 500, 500, 500, 500, 500, 215, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 379, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 328, 500, 500, 500, 500, 500, 500, 500, 393, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.665634028723543, "mean_inference_ms": 4.9498395178326655, "mean_action_processing_ms": 7.4500433553501875, "mean_env_wait_ms": 11.395549307320215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 89.19645690917969, "episode_reward_min": -0.8872528076171875, "episode_reward_mean": 10.036935217012235, "episode_len_mean": 493.1219512195122, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.23348236083984375, 0.0, 0.0, 0.0, 17.99578285217285, -0.22608184814453125, 0.0, 0.0, 0.0, 1.448333740234375, 18.165359497070312, 0.0, 4.3056182861328125, 0.0, 0.0, 52.15153503417969, 0.0, 34.33928680419922, 0.01055908203125, 0.0, 14.755950927734375, 0.0, 0.0, 0.0, 0.20300674438476562, 0.0, 9.768388748168945, 38.058937072753906, -0.12061691284179688, 0.0, 0.0, 0.0, 0.0, -0.4497222900390625, 8.715312957763672, 12.309226989746094, 10.8438720703125, 0.0, 2.832366943359375, 6.393573760986328, 12.152999877929688, 0.0, 42.500633239746094, 0.0, 3.0892257690429688, 0.0, 2.4118499755859375, 0.0, -0.247100830078125, -0.8872528076171875, 0.0, -0.021823883056640625, 0.0, 0.0, 45.893035888671875, 0.0, 0.0, 0.0, 24.877838134765625, 0.0, 0.0, 65.27919006347656, 52.20800018310547, 0.0, 39.40737533569336, 0.08626556396484375, -0.0115509033203125, 0.0, 68.98282241821289, 30.21173858642578, 26.075206756591797, 0.0, 51.632469177246094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.18046569824219, 5.9989013671875, -0.0331268310546875, -0.1243438720703125, 45.324729919433594, 28.210174560546875, 29.85491180419922, 0.0852203369140625, 0.128204345703125, -0.06918716430664062, 53.45600891113281, 0.0, 0.0, 0.0, 76.99856567382812, 0.0, 0.0748748779296875, 0.0, 0.1402130126953125, 0.0, -0.01723480224609375, 0.0, 0.0, 0.9752655029296875, 0.0, 0.0, 0.0, 89.19645690917969, 0.0, 0.0, 3.313983917236328, 0.0, 39.113075256347656, 54.66918754577637, 0.0, 0.3277740478515625, 10.745979309082031, 0.0, 0.0, 0.0, 53.33515167236328, -0.2503509521484375], "episode_lengths": [500, 500, 500, 500, 500, 500, 215, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 339, 500, 500, 500, 500, 500, 500, 379, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 328, 500, 500, 500, 500, 500, 500, 500, 393, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.665634028723543, "mean_inference_ms": 4.9498395178326655, "mean_action_processing_ms": 7.4500433553501875, "mean_env_wait_ms": 11.395549307320215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23057979, "num_agent_steps_trained": 23057979, "num_env_steps_sampled": 23057979, "num_env_steps_trained": 23057979, "num_env_steps_sampled_this_iter": 60654, "num_env_steps_trained_this_iter": 60654, "timesteps_total": 23057979, "num_steps_trained_this_iter": 60654, "agent_timesteps_total": 23057979, "timers": {"training_iteration_time_ms": 48529.729, "load_time_ms": 50.093, "load_throughput": 1217386.265, "learn_time_ms": 27655.678, "learn_throughput": 2205.073, "synch_weights_time_ms": 10.143}, "counters": {"num_env_steps_sampled": 23057979, "num_env_steps_trained": 23057979, "num_agent_steps_sampled": 23057979, "num_agent_steps_trained": 23057979}, "done": false, "episodes_total": 46701, "training_iteration": 380, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-09-24", "timestamp": 1735110564, "time_this_iter_s": 47.565818309783936, "time_total_s": 11668.386371135712, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE9060>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2811.256472349167, "timesteps_since_restore": 0, "iterations_since_restore": 59, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.28507462686567, "ram_util_percent": 96.25820895522388}}
{"custom_metrics": {"rewards/0_mean": 8.183462219853554, "rewards/0_min": -0.9852142333984375, "rewards/0_max": 74.50579833984375, "rewards/1_mean": 8.183462219853554, "rewards/1_min": -0.9852142333984375, "rewards/1_max": 74.50579833984375, "rewards/2_mean": 8.183462219853554, "rewards/2_min": -0.9852142333984375, "rewards/2_max": 74.50579833984375, "rewards/3_mean": 8.183462219853554, "rewards/3_min": -0.9852142333984375, "rewards/3_max": 74.50579833984375, "rewards/4_mean": 8.183462219853554, "rewards/4_min": -0.9852142333984375, "rewards/4_max": 74.50579833984375}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.16298352370522767, "policy_loss": 0.002577749422123325, "vf_loss": 0.07656506196362897, "vf_explained_var": 0.962007153507263, "kl": 0.012168725068858337, "entropy": 24.274238250369116, "entropy_coeff": 0.01, "grad_gnorm": 1.508384846150875}, "model": {}, "num_grad_updates_lifetime": 37755.5, "diff_num_grad_updates_vs_sampler_policy": 37754.5}}, "num_env_steps_sampled": 23118905, "num_env_steps_trained": 23118905, "num_agent_steps_sampled": 23118905, "num_agent_steps_trained": 23118905}, "sampler_results": {"episode_reward_max": 74.50579833984375, "episode_reward_min": -0.9852142333984375, "episode_reward_mean": 8.183462219853554, "episode_len_mean": 491.33870967741933, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.183462219853554, "rewards/0_min": -0.9852142333984375, "rewards/0_max": 74.50579833984375, "rewards/1_mean": 8.183462219853554, "rewards/1_min": -0.9852142333984375, "rewards/1_max": 74.50579833984375, "rewards/2_mean": 8.183462219853554, "rewards/2_min": -0.9852142333984375, "rewards/2_max": 74.50579833984375, "rewards/3_mean": 8.183462219853554, "rewards/3_min": -0.9852142333984375, "rewards/3_max": 74.50579833984375, "rewards/4_mean": 8.183462219853554, "rewards/4_min": -0.9852142333984375, "rewards/4_max": 74.50579833984375}, "hist_stats": {"episode_reward": [0.392120361328125, 3.529693603515625, 0.040447235107421875, 0.0, -0.193115234375, -0.4525604248046875, -0.14189910888671875, 0.0, 0.0, 0.0550689697265625, 27.642578125, 0.0, 1.022064208984375, -0.9852142333984375, 65.98719787597656, 0.22159576416015625, 12.708259582519531, 0.0, 33.0758056640625, 0.0, -0.0856781005859375, 0.0, -0.025360107421875, 32.81261444091797, -0.13512420654296875, 0.0, 0.0, 0.0, 0.644561767578125, 68.70582580566406, 9.190120697021484, 0.0, 11.959526062011719, 0.0, 67.31002426147461, 0.32977294921875, -0.1044769287109375, 0.0, 1.6668815612792969, 0.0, 0.0, 9.974689483642578, 0.0, 18.81352996826172, 0.0, -0.1693267822265625, 0.0, 0.0, 0.0, 0.0, 20.674880981445312, 0.0, 43.598968505859375, 2.7950286865234375, -0.026493072509765625, 10.735488891601562, 0.0, 2.5332775115966797, 49.48106002807617, 0.0, 10.731727600097656, 0.0, 0.0, 0.0, 14.233413696289062, 61.27009963989258, 70.65961456298828, 0.006103515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2985992431640625, -0.8966522216796875, 4.843046188354492, 0.0, 0.0, 19.51013946533203, -0.170318603515625, 3.995513916015625, 0.0, 0.0, 6.04345703125, 0.0, 19.883567810058594, 0.0, 0.0, 7.420051574707031, 28.797962188720703, 74.50579833984375, 28.370948791503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013843536376953125, -0.24833297729492188, 0.08599853515625, 0.5735626220703125, 18.94181251525879, 0.0, 13.828426361083984, 13.177742004394531, 23.888442993164062, 0.0, 0.0, -0.065704345703125, 7.489715576171875, 0.0, 0.0, 0.0, 0.0, 6.13665771484375, 45.1669807434082, 2.4708023071289062, 0.0, 0.0, 0.0, 40.908164978027344, -0.0072021484375, -0.09930419921875], "episode_lengths": [500, 128, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 421, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 423, 288, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 389, 500, 500, 500, 500, 500, 500, 500, 500, 416, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.651385654454073, "mean_inference_ms": 4.945639791157337, "mean_action_processing_ms": 7.44347665302632, "mean_env_wait_ms": 11.387866725998817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.50579833984375, "episode_reward_min": -0.9852142333984375, "episode_reward_mean": 8.183462219853554, "episode_len_mean": 491.33870967741933, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.392120361328125, 3.529693603515625, 0.040447235107421875, 0.0, -0.193115234375, -0.4525604248046875, -0.14189910888671875, 0.0, 0.0, 0.0550689697265625, 27.642578125, 0.0, 1.022064208984375, -0.9852142333984375, 65.98719787597656, 0.22159576416015625, 12.708259582519531, 0.0, 33.0758056640625, 0.0, -0.0856781005859375, 0.0, -0.025360107421875, 32.81261444091797, -0.13512420654296875, 0.0, 0.0, 0.0, 0.644561767578125, 68.70582580566406, 9.190120697021484, 0.0, 11.959526062011719, 0.0, 67.31002426147461, 0.32977294921875, -0.1044769287109375, 0.0, 1.6668815612792969, 0.0, 0.0, 9.974689483642578, 0.0, 18.81352996826172, 0.0, -0.1693267822265625, 0.0, 0.0, 0.0, 0.0, 20.674880981445312, 0.0, 43.598968505859375, 2.7950286865234375, -0.026493072509765625, 10.735488891601562, 0.0, 2.5332775115966797, 49.48106002807617, 0.0, 10.731727600097656, 0.0, 0.0, 0.0, 14.233413696289062, 61.27009963989258, 70.65961456298828, 0.006103515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2985992431640625, -0.8966522216796875, 4.843046188354492, 0.0, 0.0, 19.51013946533203, -0.170318603515625, 3.995513916015625, 0.0, 0.0, 6.04345703125, 0.0, 19.883567810058594, 0.0, 0.0, 7.420051574707031, 28.797962188720703, 74.50579833984375, 28.370948791503906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013843536376953125, -0.24833297729492188, 0.08599853515625, 0.5735626220703125, 18.94181251525879, 0.0, 13.828426361083984, 13.177742004394531, 23.888442993164062, 0.0, 0.0, -0.065704345703125, 7.489715576171875, 0.0, 0.0, 0.0, 0.0, 6.13665771484375, 45.1669807434082, 2.4708023071289062, 0.0, 0.0, 0.0, 40.908164978027344, -0.0072021484375, -0.09930419921875], "episode_lengths": [500, 128, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 421, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 423, 288, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 389, 500, 500, 500, 500, 500, 500, 500, 500, 416, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.651385654454073, "mean_inference_ms": 4.945639791157337, "mean_action_processing_ms": 7.44347665302632, "mean_env_wait_ms": 11.387866725998817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23118905, "num_agent_steps_trained": 23118905, "num_env_steps_sampled": 23118905, "num_env_steps_trained": 23118905, "num_env_steps_sampled_this_iter": 60926, "num_env_steps_trained_this_iter": 60926, "timesteps_total": 23118905, "num_steps_trained_this_iter": 60926, "agent_timesteps_total": 23118905, "timers": {"training_iteration_time_ms": 48464.489, "load_time_ms": 50.202, "load_throughput": 1214974.259, "learn_time_ms": 27442.545, "learn_throughput": 2222.625, "synch_weights_time_ms": 10.143}, "counters": {"num_env_steps_sampled": 23118905, "num_env_steps_trained": 23118905, "num_agent_steps_sampled": 23118905, "num_agent_steps_trained": 23118905}, "done": false, "episodes_total": 46825, "training_iteration": 381, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-10-12", "timestamp": 1735110612, "time_this_iter_s": 47.488043785095215, "time_total_s": 11715.874414920807, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B53280>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E37553F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2858.744516134262, "timesteps_since_restore": 0, "iterations_since_restore": 60, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.007462686567163, "ram_util_percent": 96.18805970149252}}
{"custom_metrics": {"rewards/0_mean": 8.663647628412015, "rewards/0_min": -0.5647201538085938, "rewards/0_max": 85.52383041381836, "rewards/1_mean": 8.663647628412015, "rewards/1_min": -0.5647201538085938, "rewards/1_max": 85.52383041381836, "rewards/2_mean": 8.663647628412015, "rewards/2_min": -0.5647201538085938, "rewards/2_max": 85.52383041381836, "rewards/3_mean": 8.663647628412015, "rewards/3_min": -0.5647201538085938, "rewards/3_max": 85.52383041381836, "rewards/4_mean": 8.663647628412015, "rewards/4_min": -0.5647201538085938, "rewards/4_max": 85.52383041381836}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.1733132508686847, "policy_loss": -0.005191049307939552, "vf_loss": 0.07594760479516394, "vf_explained_var": 0.9858104110710204, "kl": 0.013148459118776141, "entropy": 24.47354532877604, "entropy_coeff": 0.01, "grad_gnorm": 1.2910723511661801}, "model": {}, "num_grad_updates_lifetime": 38385.5, "diff_num_grad_updates_vs_sampler_policy": 38384.5}}, "num_env_steps_sampled": 23179875, "num_env_steps_trained": 23179875, "num_agent_steps_sampled": 23179875, "num_agent_steps_trained": 23179875}, "sampler_results": {"episode_reward_max": 85.52383041381836, "episode_reward_min": -0.5647201538085938, "episode_reward_mean": 8.663647628412015, "episode_len_mean": 495.6910569105691, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.663647628412015, "rewards/0_min": -0.5647201538085938, "rewards/0_max": 85.52383041381836, "rewards/1_mean": 8.663647628412015, "rewards/1_min": -0.5647201538085938, "rewards/1_max": 85.52383041381836, "rewards/2_mean": 8.663647628412015, "rewards/2_min": -0.5647201538085938, "rewards/2_max": 85.52383041381836, "rewards/3_mean": 8.663647628412015, "rewards/3_min": -0.5647201538085938, "rewards/3_max": 85.52383041381836, "rewards/4_mean": 8.663647628412015, "rewards/4_min": -0.5647201538085938, "rewards/4_max": 85.52383041381836}, "hist_stats": {"episode_reward": [-0.1773223876953125, 18.89116859436035, 0.0, 0.2498798370361328, 0.0, 0.0, 0.0, 28.63555145263672, 0.2949066162109375, 10.182868957519531, 0.12744140625, 0.0, 61.235008239746094, 1.4863548278808594, 29.252899169921875, 0.0, -0.166656494140625, -0.03668212890625, 0.0, 0.0, 4.818145751953125, -0.0452728271484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.24943923950195312, 5.076194763183594, 0.25423431396484375, 0.00299072265625, 67.99531555175781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1779022216796875, 0.0, 0.0, 0.0, 0.0, -0.19427871704101562, 21.78451919555664, -0.1786956787109375, 0.0, 0.0, 0.0, 0.0, 43.00084686279297, 48.067657470703125, 0.0, 33.083351135253906, 0.0, 0.0, 0.0, 1.2156982421875, -0.197998046875, 0.0, -0.2131500244140625, 0.1315155029296875, 0.0, 0.0, 61.17243957519531, 68.90771102905273, 0.0, 0.0, 0.0, 21.068893432617188, 25.095230102539062, 29.32379150390625, 0.0, 29.81061553955078, 0.0, 0.0, 37.39295959472656, 0.0, -0.5647201538085938, 0.5864105224609375, 0.0, 0.0, 0.0, 43.39143753051758, 30.85959243774414, 0.0, 85.52383041381836, 0.0, 0.0, 0.8431854248046875, 28.718963623046875, 0.29364013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.125518798828125, 19.82030487060547, 35.81916046142578, 23.807029724121094, 0.0, 39.187400817871094, 0.0, -0.161651611328125, 5.0556793212890625, 24.9263916015625, 31.403411865234375, -0.2267608642578125, 0.0, 0.0, -0.4229393005371094, 0.0, 5.3379669189453125, 30.176898956298828, 0.0, -0.14868927001953125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 192, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 499, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.642785156864258, "mean_inference_ms": 4.943092183378573, "mean_action_processing_ms": 7.439892758517745, "mean_env_wait_ms": 11.383562674964047, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 85.52383041381836, "episode_reward_min": -0.5647201538085938, "episode_reward_mean": 8.663647628412015, "episode_len_mean": 495.6910569105691, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.1773223876953125, 18.89116859436035, 0.0, 0.2498798370361328, 0.0, 0.0, 0.0, 28.63555145263672, 0.2949066162109375, 10.182868957519531, 0.12744140625, 0.0, 61.235008239746094, 1.4863548278808594, 29.252899169921875, 0.0, -0.166656494140625, -0.03668212890625, 0.0, 0.0, 4.818145751953125, -0.0452728271484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.24943923950195312, 5.076194763183594, 0.25423431396484375, 0.00299072265625, 67.99531555175781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1779022216796875, 0.0, 0.0, 0.0, 0.0, -0.19427871704101562, 21.78451919555664, -0.1786956787109375, 0.0, 0.0, 0.0, 0.0, 43.00084686279297, 48.067657470703125, 0.0, 33.083351135253906, 0.0, 0.0, 0.0, 1.2156982421875, -0.197998046875, 0.0, -0.2131500244140625, 0.1315155029296875, 0.0, 0.0, 61.17243957519531, 68.90771102905273, 0.0, 0.0, 0.0, 21.068893432617188, 25.095230102539062, 29.32379150390625, 0.0, 29.81061553955078, 0.0, 0.0, 37.39295959472656, 0.0, -0.5647201538085938, 0.5864105224609375, 0.0, 0.0, 0.0, 43.39143753051758, 30.85959243774414, 0.0, 85.52383041381836, 0.0, 0.0, 0.8431854248046875, 28.718963623046875, 0.29364013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.125518798828125, 19.82030487060547, 35.81916046142578, 23.807029724121094, 0.0, 39.187400817871094, 0.0, -0.161651611328125, 5.0556793212890625, 24.9263916015625, 31.403411865234375, -0.2267608642578125, 0.0, 0.0, -0.4229393005371094, 0.0, 5.3379669189453125, 30.176898956298828, 0.0, -0.14868927001953125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 192, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 279, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 499, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.642785156864258, "mean_inference_ms": 4.943092183378573, "mean_action_processing_ms": 7.439892758517745, "mean_env_wait_ms": 11.383562674964047, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23179875, "num_agent_steps_trained": 23179875, "num_env_steps_sampled": 23179875, "num_env_steps_trained": 23179875, "num_env_steps_sampled_this_iter": 60970, "num_env_steps_trained_this_iter": 60970, "timesteps_total": 23179875, "num_steps_trained_this_iter": 60970, "agent_timesteps_total": 23179875, "timers": {"training_iteration_time_ms": 48195.004, "load_time_ms": 50.746, "load_throughput": 1202057.844, "learn_time_ms": 27220.148, "learn_throughput": 2240.991, "synch_weights_time_ms": 10.142}, "counters": {"num_env_steps_sampled": 23179875, "num_env_steps_trained": 23179875, "num_agent_steps_sampled": 23179875, "num_agent_steps_trained": 23179875}, "done": false, "episodes_total": 46948, "training_iteration": 382, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-10-58", "timestamp": 1735110658, "time_this_iter_s": 45.51783800125122, "time_total_s": 11761.392252922058, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A58340>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CCF760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2904.2623541355133, "timesteps_since_restore": 0, "iterations_since_restore": 61, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.0234375, "ram_util_percent": 96.290625}}
{"custom_metrics": {"rewards/0_mean": 10.874347066879272, "rewards/0_min": -0.441619873046875, "rewards/0_max": 81.91496276855469, "rewards/1_mean": 10.874347066879272, "rewards/1_min": -0.441619873046875, "rewards/1_max": 81.91496276855469, "rewards/2_mean": 10.874347066879272, "rewards/2_min": -0.441619873046875, "rewards/2_max": 81.91496276855469, "rewards/3_mean": 10.874347066879272, "rewards/3_min": -0.441619873046875, "rewards/3_max": 81.91496276855469, "rewards/4_mean": 10.874347066879272, "rewards/4_min": -0.441619873046875, "rewards/4_max": 81.91496276855469}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07190076118512523, "policy_loss": 0.002767805747045338, "vf_loss": 0.1448730680219356, "vf_explained_var": 0.9871151283619896, "kl": 0.013135959081617849, "entropy": 22.02066485087077, "entropy_coeff": 0.01, "grad_gnorm": 1.6456391778020631}, "model": {}, "num_grad_updates_lifetime": 39015.5, "diff_num_grad_updates_vs_sampler_policy": 39014.5}}, "num_env_steps_sampled": 23239875, "num_env_steps_trained": 23239875, "num_agent_steps_sampled": 23239875, "num_agent_steps_trained": 23239875}, "sampler_results": {"episode_reward_max": 81.91496276855469, "episode_reward_min": -0.441619873046875, "episode_reward_mean": 10.874347066879272, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.874347066879272, "rewards/0_min": -0.441619873046875, "rewards/0_max": 81.91496276855469, "rewards/1_mean": 10.874347066879272, "rewards/1_min": -0.441619873046875, "rewards/1_max": 81.91496276855469, "rewards/2_mean": 10.874347066879272, "rewards/2_min": -0.441619873046875, "rewards/2_max": 81.91496276855469, "rewards/3_mean": 10.874347066879272, "rewards/3_min": -0.441619873046875, "rewards/3_max": 81.91496276855469, "rewards/4_mean": 10.874347066879272, "rewards/4_min": -0.441619873046875, "rewards/4_max": 81.91496276855469}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.221160888671875, 0.0, 0.0, 0.0, 0.0, 47.518096923828125, 33.81314468383789, 0.9880218505859375, 0.0, -0.2690582275390625, 80.32378387451172, 0.0, 13.131767272949219, -0.29244232177734375, 19.705810546875, 0.3411102294921875, -0.37560272216796875, 0.0, 4.14337158203125, -0.441619873046875, 41.184326171875, -0.1209869384765625, 0.0, 77.7674446105957, 0.0520172119140625, 1.0321197509765625, 0.0, 0.0, 0.0, 28.156959533691406, 0.0, 31.823986053466797, 0.0, 81.91496276855469, -0.133056640625, 0.0, 0.0, 66.61618232727051, 19.64623260498047, 38.817100524902344, 0.0, 61.8592414855957, 48.232479095458984, 3.22210693359375, 0.0, -0.00266265869140625, -0.03765869140625, 30.81275177001953, 0.0, 11.566207885742188, 11.373794555664062, -0.3318023681640625, -0.20444488525390625, 0.0, 0.0, -0.1356353759765625, 0.55584716796875, 0.0, 0.0, 7.5020751953125, 0.0, 0.0316162109375, 0.0, 0.0, 52.756858825683594, 5.2003021240234375, 1.737213134765625, -0.21241378784179688, 30.543426513671875, 0.0, 0.0, -0.1072998046875, 0.0, 0.0, 42.01521301269531, 0.0, 0.4378318786621094, 0.0, 0.0, 0.0, 16.756439208984375, 0.0, -0.033447265625, 0.0, 33.4813232421875, 0.0, 14.553924560546875, 0.0, 0.05245208740234375, 26.854629516601562, 27.686691284179688, 6.40325927734375, 39.99249267578125, 22.664871215820312, 0.0, 0.2006378173828125, 0.0, 0.0, 8.864147186279297, 0.35248565673828125, 47.37101745605469, 0.0, 0.070037841796875, 3.7662811279296875, 12.330604553222656, 0.0, 0.4379539489746094, 0.0, 43.523712158203125, -0.038330078125, 46.36676025390625, 44.32750701904297, -0.176422119140625, 0.0, 0.0, 0.0, 2.8023605346679688, 14.372699737548828], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.642468557241065, "mean_inference_ms": 4.946050390894682, "mean_action_processing_ms": 7.433581763094324, "mean_env_wait_ms": 11.382116266732858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 81.91496276855469, "episode_reward_min": -0.441619873046875, "episode_reward_mean": 10.874347066879272, "episode_len_mean": 500.0, "episodes_this_iter": 120, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.221160888671875, 0.0, 0.0, 0.0, 0.0, 47.518096923828125, 33.81314468383789, 0.9880218505859375, 0.0, -0.2690582275390625, 80.32378387451172, 0.0, 13.131767272949219, -0.29244232177734375, 19.705810546875, 0.3411102294921875, -0.37560272216796875, 0.0, 4.14337158203125, -0.441619873046875, 41.184326171875, -0.1209869384765625, 0.0, 77.7674446105957, 0.0520172119140625, 1.0321197509765625, 0.0, 0.0, 0.0, 28.156959533691406, 0.0, 31.823986053466797, 0.0, 81.91496276855469, -0.133056640625, 0.0, 0.0, 66.61618232727051, 19.64623260498047, 38.817100524902344, 0.0, 61.8592414855957, 48.232479095458984, 3.22210693359375, 0.0, -0.00266265869140625, -0.03765869140625, 30.81275177001953, 0.0, 11.566207885742188, 11.373794555664062, -0.3318023681640625, -0.20444488525390625, 0.0, 0.0, -0.1356353759765625, 0.55584716796875, 0.0, 0.0, 7.5020751953125, 0.0, 0.0316162109375, 0.0, 0.0, 52.756858825683594, 5.2003021240234375, 1.737213134765625, -0.21241378784179688, 30.543426513671875, 0.0, 0.0, -0.1072998046875, 0.0, 0.0, 42.01521301269531, 0.0, 0.4378318786621094, 0.0, 0.0, 0.0, 16.756439208984375, 0.0, -0.033447265625, 0.0, 33.4813232421875, 0.0, 14.553924560546875, 0.0, 0.05245208740234375, 26.854629516601562, 27.686691284179688, 6.40325927734375, 39.99249267578125, 22.664871215820312, 0.0, 0.2006378173828125, 0.0, 0.0, 8.864147186279297, 0.35248565673828125, 47.37101745605469, 0.0, 0.070037841796875, 3.7662811279296875, 12.330604553222656, 0.0, 0.4379539489746094, 0.0, 43.523712158203125, -0.038330078125, 46.36676025390625, 44.32750701904297, -0.176422119140625, 0.0, 0.0, 0.0, 2.8023605346679688, 14.372699737548828], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.642468557241065, "mean_inference_ms": 4.946050390894682, "mean_action_processing_ms": 7.433581763094324, "mean_env_wait_ms": 11.382116266732858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23239875, "num_agent_steps_trained": 23239875, "num_env_steps_sampled": 23239875, "num_env_steps_trained": 23239875, "num_env_steps_sampled_this_iter": 60000, "num_env_steps_trained_this_iter": 60000, "timesteps_total": 23239875, "num_steps_trained_this_iter": 60000, "agent_timesteps_total": 23239875, "timers": {"training_iteration_time_ms": 47948.352, "load_time_ms": 50.745, "load_throughput": 1199899.262, "learn_time_ms": 27116.14, "learn_throughput": 2245.471, "synch_weights_time_ms": 10.143}, "counters": {"num_env_steps_sampled": 23239875, "num_env_steps_trained": 23239875, "num_agent_steps_sampled": 23239875, "num_agent_steps_trained": 23239875}, "done": false, "episodes_total": 47068, "training_iteration": 383, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-11-44", "timestamp": 1735110704, "time_this_iter_s": 46.57991909980774, "time_total_s": 11807.972172021866, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3A93FD0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFC70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2950.842273235321, "timesteps_since_restore": 0, "iterations_since_restore": 62, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.468181818181815, "ram_util_percent": 96.34999999999998}}
{"custom_metrics": {"rewards/0_mean": 7.112183346011775, "rewards/0_min": -0.8040618896484375, "rewards/0_max": 68.47920608520508, "rewards/1_mean": 7.112183346011775, "rewards/1_min": -0.8040618896484375, "rewards/1_max": 68.47920608520508, "rewards/2_mean": 7.112183346011775, "rewards/2_min": -0.8040618896484375, "rewards/2_max": 68.47920608520508, "rewards/3_mean": 7.112183346011775, "rewards/3_min": -0.8040618896484375, "rewards/3_max": 68.47920608520508, "rewards/4_mean": 7.112183346011775, "rewards/4_min": -0.8040618896484375, "rewards/4_max": 68.47920608520508}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.17576054426091206, "policy_loss": -0.0001913934340192345, "vf_loss": 0.07921896863965289, "vf_explained_var": 0.9694647677361019, "kl": 0.01085084717358566, "entropy": 25.533744878617544, "entropy_coeff": 0.01, "grad_gnorm": 1.0667307979530758}, "model": {}, "num_grad_updates_lifetime": 39645.5, "diff_num_grad_updates_vs_sampler_policy": 39644.5}}, "num_env_steps_sampled": 23300958, "num_env_steps_trained": 23300958, "num_agent_steps_sampled": 23300958, "num_agent_steps_trained": 23300958}, "sampler_results": {"episode_reward_max": 68.47920608520508, "episode_reward_min": -0.8040618896484375, "episode_reward_mean": 7.112183346011775, "episode_len_mean": 496.609756097561, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.112183346011775, "rewards/0_min": -0.8040618896484375, "rewards/0_max": 68.47920608520508, "rewards/1_mean": 7.112183346011775, "rewards/1_min": -0.8040618896484375, "rewards/1_max": 68.47920608520508, "rewards/2_mean": 7.112183346011775, "rewards/2_min": -0.8040618896484375, "rewards/2_max": 68.47920608520508, "rewards/3_mean": 7.112183346011775, "rewards/3_min": -0.8040618896484375, "rewards/3_max": 68.47920608520508, "rewards/4_mean": 7.112183346011775, "rewards/4_min": -0.8040618896484375, "rewards/4_max": 68.47920608520508}, "hist_stats": {"episode_reward": [0.0, 0.0, 1.209798812866211, 2.5688934326171875, 0.0, 0.5494384765625, 0.1367950439453125, 0.0, 0.38323211669921875, 0.0, 33.81194305419922, 53.06298828125, -0.1363677978515625, 0.7372245788574219, 0.0, 23.7525634765625, 0.0, 0.0, 19.282167434692383, 0.0, 0.0, 4.3405303955078125, -0.8040618896484375, 0.0, -0.1116485595703125, 0.0, 0.0, 0.03905487060546875, -0.018096923828125, 0.0, 0.0, 26.328441619873047, 18.506927490234375, 0.21179962158203125, 2.6100921630859375, 0.0, 0.0, 0.0, 8.923751831054688, 0.8134613037109375, 0.0, 0.0, 24.469650268554688, 0.0, 0.0, 0.481353759765625, 59.62451934814453, 16.00702476501465, 0.0, 10.153579711914062, 32.51203155517578, 0.2012786865234375, 0.0, 37.07579803466797, 0.0, -0.4638671875, 0.0, 0.0, 0.0, -0.3227386474609375, 0.0, 0.0, 0.0, 43.28037643432617, 0.0, 30.743255615234375, 0.0, 23.0248966217041, 0.0, 9.369361877441406, 37.91035079956055, -0.1407318115234375, 0.0, 0.0, 0.0, 0.0, 0.270477294921875, 40.16781997680664, -0.5678558349609375, 0.0, 0.0, 0.0, 0.7029571533203125, 0.0, 0.0, 32.47853088378906, 0.0, 0.0, 0.0, 0.0, 9.842567443847656, 16.611160278320312, 68.47920608520508, 0.0, 0.0, 0.0, -0.190673828125, -0.1793670654296875, 0.0, 0.0, 4.096214294433594, 0.0, 0.20645904541015625, 0.0, 49.321205139160156, 0.0, 9.888824462890625, 0.7115478515625, 0.0, 13.566719055175781, 30.161048889160156, 9.957246780395508, 0.0, -0.08310699462890625, 0.0572662353515625, 0.0, -0.1173248291015625, 27.731292724609375, 0.0, -0.5598068237304688, 41.97304916381836, 0.0, 0.1480255126953125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 334, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 284, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 465, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.628106929972992, "mean_inference_ms": 4.943868722375578, "mean_action_processing_ms": 7.425544253720074, "mean_env_wait_ms": 11.374492763200571, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 68.47920608520508, "episode_reward_min": -0.8040618896484375, "episode_reward_mean": 7.112183346011775, "episode_len_mean": 496.609756097561, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 1.209798812866211, 2.5688934326171875, 0.0, 0.5494384765625, 0.1367950439453125, 0.0, 0.38323211669921875, 0.0, 33.81194305419922, 53.06298828125, -0.1363677978515625, 0.7372245788574219, 0.0, 23.7525634765625, 0.0, 0.0, 19.282167434692383, 0.0, 0.0, 4.3405303955078125, -0.8040618896484375, 0.0, -0.1116485595703125, 0.0, 0.0, 0.03905487060546875, -0.018096923828125, 0.0, 0.0, 26.328441619873047, 18.506927490234375, 0.21179962158203125, 2.6100921630859375, 0.0, 0.0, 0.0, 8.923751831054688, 0.8134613037109375, 0.0, 0.0, 24.469650268554688, 0.0, 0.0, 0.481353759765625, 59.62451934814453, 16.00702476501465, 0.0, 10.153579711914062, 32.51203155517578, 0.2012786865234375, 0.0, 37.07579803466797, 0.0, -0.4638671875, 0.0, 0.0, 0.0, -0.3227386474609375, 0.0, 0.0, 0.0, 43.28037643432617, 0.0, 30.743255615234375, 0.0, 23.0248966217041, 0.0, 9.369361877441406, 37.91035079956055, -0.1407318115234375, 0.0, 0.0, 0.0, 0.0, 0.270477294921875, 40.16781997680664, -0.5678558349609375, 0.0, 0.0, 0.0, 0.7029571533203125, 0.0, 0.0, 32.47853088378906, 0.0, 0.0, 0.0, 0.0, 9.842567443847656, 16.611160278320312, 68.47920608520508, 0.0, 0.0, 0.0, -0.190673828125, -0.1793670654296875, 0.0, 0.0, 4.096214294433594, 0.0, 0.20645904541015625, 0.0, 49.321205139160156, 0.0, 9.888824462890625, 0.7115478515625, 0.0, 13.566719055175781, 30.161048889160156, 9.957246780395508, 0.0, -0.08310699462890625, 0.0572662353515625, 0.0, -0.1173248291015625, 27.731292724609375, 0.0, -0.5598068237304688, 41.97304916381836, 0.0, 0.1480255126953125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 334, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 284, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 465, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.628106929972992, "mean_inference_ms": 4.943868722375578, "mean_action_processing_ms": 7.425544253720074, "mean_env_wait_ms": 11.374492763200571, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23300958, "num_agent_steps_trained": 23300958, "num_env_steps_sampled": 23300958, "num_env_steps_trained": 23300958, "num_env_steps_sampled_this_iter": 61083, "num_env_steps_trained_this_iter": 61083, "timesteps_total": 23300958, "num_steps_trained_this_iter": 61083, "agent_timesteps_total": 23300958, "timers": {"training_iteration_time_ms": 47703.868, "load_time_ms": 50.745, "load_throughput": 1199350.001, "learn_time_ms": 27086.203, "learn_throughput": 2246.952, "synch_weights_time_ms": 10.143}, "counters": {"num_env_steps_sampled": 23300958, "num_env_steps_trained": 23300958, "num_agent_steps_sampled": 23300958, "num_agent_steps_trained": 23300958}, "done": false, "episodes_total": 47191, "training_iteration": 384, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-12-31", "timestamp": 1735110751, "time_this_iter_s": 46.53446054458618, "time_total_s": 11854.506632566452, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BE8430>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFB50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 2997.376733779907, "timesteps_since_restore": 0, "iterations_since_restore": 63, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 20.796923076923076, "ram_util_percent": 96.37230769230769}}
{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.705928953587688, "mean_inference_ms": 3.459520549741897, "mean_action_processing_ms": 0.4757498066492437, "mean_env_wait_ms": 5.963942506206602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 11.535073970391498, "rewards/0_min": -0.6029510498046875, "rewards/0_max": 90.38750457763672, "rewards/1_mean": 11.535073970391498, "rewards/1_min": -0.6029510498046875, "rewards/1_max": 90.38750457763672, "rewards/2_mean": 11.535073970391498, "rewards/2_min": -0.6029510498046875, "rewards/2_max": 90.38750457763672, "rewards/3_mean": 11.535073970391498, "rewards/3_min": -0.6029510498046875, "rewards/3_max": 90.38750457763672, "rewards/4_mean": 11.535073970391498, "rewards/4_min": -0.6029510498046875, "rewards/4_max": 90.38750457763672}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08435181330229777, "policy_loss": 0.00955234599994525, "vf_loss": 0.14860885038691027, "vf_explained_var": 0.9889800247691927, "kl": 0.01432053952548091, "entropy": 24.323799154493543, "entropy_coeff": 0.01, "grad_gnorm": 1.8436871548966756}, "model": {}, "num_grad_updates_lifetime": 40275.5, "diff_num_grad_updates_vs_sampler_policy": 40274.5}}, "num_env_steps_sampled": 23361898, "num_env_steps_trained": 23361898, "num_agent_steps_sampled": 23361898, "num_agent_steps_trained": 23361898}, "sampler_results": {"episode_reward_max": 90.38750457763672, "episode_reward_min": -0.6029510498046875, "episode_reward_mean": 11.535073970391498, "episode_len_mean": 495.4471544715447, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.535073970391498, "rewards/0_min": -0.6029510498046875, "rewards/0_max": 90.38750457763672, "rewards/1_mean": 11.535073970391498, "rewards/1_min": -0.6029510498046875, "rewards/1_max": 90.38750457763672, "rewards/2_mean": 11.535073970391498, "rewards/2_min": -0.6029510498046875, "rewards/2_max": 90.38750457763672, "rewards/3_mean": 11.535073970391498, "rewards/3_min": -0.6029510498046875, "rewards/3_max": 90.38750457763672, "rewards/4_mean": 11.535073970391498, "rewards/4_min": -0.6029510498046875, "rewards/4_max": 90.38750457763672}, "hist_stats": {"episode_reward": [0.0, 0.0, 90.38750457763672, -0.01566314697265625, 10.607986450195312, 0.0, -0.6029510498046875, 0.0, 66.90397834777832, 0.0, 0.0, 0.0, 83.10231018066406, 0.5272903442382812, 0.0, 0.0, -0.154998779296875, 11.759754180908203, 0.0, 29.099586486816406, 0.0, 42.17927169799805, 28.046283721923828, 0.0, 0.0, 0.0, 20.177099227905273, -0.366973876953125, 0.0, 0.0, 46.89459228515625, 0.12926483154296875, 0.0, 0.0, 0.26831817626953125, 0.9940032958984375, 66.7887191772461, 0.6622543334960938, 0.46585845947265625, 0.0, 11.02532958984375, -0.0042572021484375, 0.0, -0.2925262451171875, -0.421295166015625, 0.0, 34.84548759460449, -0.01490020751953125, -0.5847015380859375, 37.94332695007324, 0.0, 0.0, 4.559288024902344, 0.0, 0.0, 27.58403778076172, 0.0, 0.0, 6.057991027832031, 0.0, 0.0, 0.0, 24.5111083984375, 0.664459228515625, 0.2621002197265625, 0.0, 3.786895751953125, 22.687721252441406, 0.0, 0.0, 43.808998107910156, 0.0, 0.0, 31.2455997467041, 0.0, 0.0, 33.822166442871094, -0.0576934814453125, 0.0, 0.4992866516113281, 0.0, 13.927993774414062, 27.47506332397461, 41.443359375, 0.0, 0.0, 0.7699203491210938, 59.18103790283203, 74.03546714782715, 0.0, 64.0777816772461, 0.0, 0.0, 0.241241455078125, -0.26556396484375, 80.40342712402344, 0.0, 0.31842041015625, -0.23297119140625, -0.03554534912109375, 0.0, 49.037376403808594, 0.0, 0.0471038818359375, 47.583702087402344, 39.75586700439453, -0.0642852783203125, 0.1000213623046875, 0.0, -0.182037353515625, -0.093505859375, 14.449554443359375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0004425048828125, 79.3784294128418, 0.0, -0.1863250732421875, 47.867095947265625, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 260, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 369, 500, 500, 360, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.626576619914903, "mean_inference_ms": 4.941803563569205, "mean_action_processing_ms": 7.428248162447818, "mean_env_wait_ms": 11.371688863793151, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 90.38750457763672, "episode_reward_min": -0.6029510498046875, "episode_reward_mean": 11.535073970391498, "episode_len_mean": 495.4471544715447, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 90.38750457763672, -0.01566314697265625, 10.607986450195312, 0.0, -0.6029510498046875, 0.0, 66.90397834777832, 0.0, 0.0, 0.0, 83.10231018066406, 0.5272903442382812, 0.0, 0.0, -0.154998779296875, 11.759754180908203, 0.0, 29.099586486816406, 0.0, 42.17927169799805, 28.046283721923828, 0.0, 0.0, 0.0, 20.177099227905273, -0.366973876953125, 0.0, 0.0, 46.89459228515625, 0.12926483154296875, 0.0, 0.0, 0.26831817626953125, 0.9940032958984375, 66.7887191772461, 0.6622543334960938, 0.46585845947265625, 0.0, 11.02532958984375, -0.0042572021484375, 0.0, -0.2925262451171875, -0.421295166015625, 0.0, 34.84548759460449, -0.01490020751953125, -0.5847015380859375, 37.94332695007324, 0.0, 0.0, 4.559288024902344, 0.0, 0.0, 27.58403778076172, 0.0, 0.0, 6.057991027832031, 0.0, 0.0, 0.0, 24.5111083984375, 0.664459228515625, 0.2621002197265625, 0.0, 3.786895751953125, 22.687721252441406, 0.0, 0.0, 43.808998107910156, 0.0, 0.0, 31.2455997467041, 0.0, 0.0, 33.822166442871094, -0.0576934814453125, 0.0, 0.4992866516113281, 0.0, 13.927993774414062, 27.47506332397461, 41.443359375, 0.0, 0.0, 0.7699203491210938, 59.18103790283203, 74.03546714782715, 0.0, 64.0777816772461, 0.0, 0.0, 0.241241455078125, -0.26556396484375, 80.40342712402344, 0.0, 0.31842041015625, -0.23297119140625, -0.03554534912109375, 0.0, 49.037376403808594, 0.0, 0.0471038818359375, 47.583702087402344, 39.75586700439453, -0.0642852783203125, 0.1000213623046875, 0.0, -0.182037353515625, -0.093505859375, 14.449554443359375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0004425048828125, 79.3784294128418, 0.0, -0.1863250732421875, 47.867095947265625, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 260, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 369, 500, 500, 360, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 451, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.626576619914903, "mean_inference_ms": 4.941803563569205, "mean_action_processing_ms": 7.428248162447818, "mean_env_wait_ms": 11.371688863793151, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23361898, "num_agent_steps_trained": 23361898, "num_env_steps_sampled": 23361898, "num_env_steps_trained": 23361898, "num_env_steps_sampled_this_iter": 60940, "num_env_steps_trained_this_iter": 60940, "timesteps_total": 23361898, "num_steps_trained_this_iter": 60940, "agent_timesteps_total": 23361898, "timers": {"training_iteration_time_ms": 47391.355, "load_time_ms": 49.189, "load_throughput": 1238577.479, "learn_time_ms": 26873.611, "learn_throughput": 2267.075, "synch_weights_time_ms": 10.083}, "counters": {"num_env_steps_sampled": 23361898, "num_env_steps_trained": 23361898, "num_agent_steps_sampled": 23361898, "num_agent_steps_trained": 23361898}, "done": false, "episodes_total": 47314, "training_iteration": 385, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-13-19", "timestamp": 1735110799, "time_this_iter_s": 47.54727482795715, "time_total_s": 11902.05390739441, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE43A0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3BCFC70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 3044.9240086078644, "timesteps_since_restore": 0, "iterations_since_restore": 64, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.834328358208953, "ram_util_percent": 96.28059701492536}}
{"custom_metrics": {"rewards/0_mean": 9.42556205997622, "rewards/0_min": -0.7596054077148438, "rewards/0_max": 90.1700553894043, "rewards/1_mean": 9.42556205997622, "rewards/1_min": -0.7596054077148438, "rewards/1_max": 90.1700553894043, "rewards/2_mean": 9.42556205997622, "rewards/2_min": -0.7596054077148438, "rewards/2_max": 90.1700553894043, "rewards/3_mean": 9.42556205997622, "rewards/3_min": -0.7596054077148438, "rewards/3_max": 90.1700553894043, "rewards/4_mean": 9.42556205997622, "rewards/4_min": -0.7596054077148438, "rewards/4_max": 90.1700553894043}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09309227001476324, "policy_loss": 0.0005013893569065701, "vf_loss": 0.1479749467955636, "vf_explained_var": 0.9840474536494603, "kl": 0.011557161057042697, "entropy": 24.215369319915773, "entropy_coeff": 0.01, "grad_gnorm": 1.3390547956266101}, "model": {}, "num_grad_updates_lifetime": 40905.5, "diff_num_grad_updates_vs_sampler_policy": 40904.5}}, "num_env_steps_sampled": 23422544, "num_env_steps_trained": 23422544, "num_agent_steps_sampled": 23422544, "num_agent_steps_trained": 23422544}, "sampler_results": {"episode_reward_max": 90.1700553894043, "episode_reward_min": -0.7596054077148438, "episode_reward_mean": 9.42556205997622, "episode_len_mean": 493.0569105691057, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 9.42556205997622, "rewards/0_min": -0.7596054077148438, "rewards/0_max": 90.1700553894043, "rewards/1_mean": 9.42556205997622, "rewards/1_min": -0.7596054077148438, "rewards/1_max": 90.1700553894043, "rewards/2_mean": 9.42556205997622, "rewards/2_min": -0.7596054077148438, "rewards/2_max": 90.1700553894043, "rewards/3_mean": 9.42556205997622, "rewards/3_min": -0.7596054077148438, "rewards/3_max": 90.1700553894043, "rewards/4_mean": 9.42556205997622, "rewards/4_min": -0.7596054077148438, "rewards/4_max": 90.1700553894043}, "hist_stats": {"episode_reward": [-0.12872314453125, 0.0, -0.258636474609375, 0.159027099609375, 8.187797546386719, 0.0, 0.0106353759765625, 0.0, -0.5060577392578125, 11.33706283569336, 0.0, 0.0, 0.0, -0.1502227783203125, 0.89520263671875, 0.0, 0.0, 43.989418029785156, 56.606849670410156, 0.0, 0.046295166015625, 0.0129852294921875, 1.051727294921875, 1.2970829010009766, -0.468841552734375, 0.0, -0.2413787841796875, 0.0, 4.191505432128906, 0.0, 37.54291534423828, 0.013275146484375, 0.0, 0.11144256591796875, 0.0, 34.03403854370117, 0.1643047332763672, 1.3498077392578125, 0.0, 0.1173095703125, 0.0, 0.0, 25.774038314819336, 0.0, -0.1359405517578125, 4.542652130126953, 21.3228759765625, 45.6317138671875, 0.0, 0.0, 69.9534912109375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.019134521484375, 0.0, 0.0, 58.44378662109375, 90.1700553894043, 15.363479614257812, 17.190460205078125, 1.6767044067382812, 0.0, -0.7596054077148438, 0.0, 46.63677978515625, 0.0, 9.212944030761719, -0.0212860107421875, 0.0, 0.0, 24.873634338378906, 30.36883544921875, -0.0843505859375, 0.0, -0.0789794921875, 28.414520263671875, 55.62162780761719, 0.0, 0.0, 12.024505615234375, 0.19950103759765625, 0.0, -0.0095977783203125, 0.0, -0.0622711181640625, 47.030609130859375, 0.0, -0.07825469970703125, 10.561080932617188, 0.432281494140625, 36.119503021240234, -0.251495361328125, 51.48454284667969, 0.2613372802734375, 0.283477783203125, 0.0, 0.363922119140625, -0.2297821044921875, 7.046539306640625, 17.122329711914062, 17.408164978027344, 1.02227783203125, 0.0798797607421875, 20.02486801147461, 27.38128662109375, 0.0, 0.0, -0.0033111572265625, -0.7548828125, 25.65631866455078, 23.453277587890625, 40.4339599609375, 0.0, 0.0, 0.0, 0.3325347900390625, -0.00061798095703125, 11.83150863647461, 66.71751403808594, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 239, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 246, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 354, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 307, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.623765973111446, "mean_inference_ms": 4.945115908303742, "mean_action_processing_ms": 7.423083186548817, "mean_env_wait_ms": 11.370526331678713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 90.1700553894043, "episode_reward_min": -0.7596054077148438, "episode_reward_mean": 9.42556205997622, "episode_len_mean": 493.0569105691057, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.12872314453125, 0.0, -0.258636474609375, 0.159027099609375, 8.187797546386719, 0.0, 0.0106353759765625, 0.0, -0.5060577392578125, 11.33706283569336, 0.0, 0.0, 0.0, -0.1502227783203125, 0.89520263671875, 0.0, 0.0, 43.989418029785156, 56.606849670410156, 0.0, 0.046295166015625, 0.0129852294921875, 1.051727294921875, 1.2970829010009766, -0.468841552734375, 0.0, -0.2413787841796875, 0.0, 4.191505432128906, 0.0, 37.54291534423828, 0.013275146484375, 0.0, 0.11144256591796875, 0.0, 34.03403854370117, 0.1643047332763672, 1.3498077392578125, 0.0, 0.1173095703125, 0.0, 0.0, 25.774038314819336, 0.0, -0.1359405517578125, 4.542652130126953, 21.3228759765625, 45.6317138671875, 0.0, 0.0, 69.9534912109375, 0.0, 0.0, 0.0, 0.0, 0.0, -0.019134521484375, 0.0, 0.0, 58.44378662109375, 90.1700553894043, 15.363479614257812, 17.190460205078125, 1.6767044067382812, 0.0, -0.7596054077148438, 0.0, 46.63677978515625, 0.0, 9.212944030761719, -0.0212860107421875, 0.0, 0.0, 24.873634338378906, 30.36883544921875, -0.0843505859375, 0.0, -0.0789794921875, 28.414520263671875, 55.62162780761719, 0.0, 0.0, 12.024505615234375, 0.19950103759765625, 0.0, -0.0095977783203125, 0.0, -0.0622711181640625, 47.030609130859375, 0.0, -0.07825469970703125, 10.561080932617188, 0.432281494140625, 36.119503021240234, -0.251495361328125, 51.48454284667969, 0.2613372802734375, 0.283477783203125, 0.0, 0.363922119140625, -0.2297821044921875, 7.046539306640625, 17.122329711914062, 17.408164978027344, 1.02227783203125, 0.0798797607421875, 20.02486801147461, 27.38128662109375, 0.0, 0.0, -0.0033111572265625, -0.7548828125, 25.65631866455078, 23.453277587890625, 40.4339599609375, 0.0, 0.0, 0.0, 0.3325347900390625, -0.00061798095703125, 11.83150863647461, 66.71751403808594, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 239, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 246, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 354, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 307, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.623765973111446, "mean_inference_ms": 4.945115908303742, "mean_action_processing_ms": 7.423083186548817, "mean_env_wait_ms": 11.370526331678713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23422544, "num_agent_steps_trained": 23422544, "num_env_steps_sampled": 23422544, "num_env_steps_trained": 23422544, "num_env_steps_sampled_this_iter": 60646, "num_env_steps_trained_this_iter": 60646, "timesteps_total": 23422544, "num_steps_trained_this_iter": 60646, "agent_timesteps_total": 23422544, "timers": {"training_iteration_time_ms": 47159.132, "load_time_ms": 49.944, "load_throughput": 1219229.531, "learn_time_ms": 26818.593, "learn_throughput": 2270.54, "synch_weights_time_ms": 8.996}, "counters": {"num_env_steps_sampled": 23422544, "num_env_steps_trained": 23422544, "num_agent_steps_sampled": 23422544, "num_agent_steps_trained": 23422544}, "done": false, "episodes_total": 47437, "training_iteration": 386, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-14-05", "timestamp": 1735110845, "time_this_iter_s": 45.8551070690155, "time_total_s": 11947.909014463425, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3BEB0A0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CBF520>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 3090.77911567688, "timesteps_since_restore": 0, "iterations_since_restore": 65, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.659999999999997, "ram_util_percent": 96.39692307692306}}
{"custom_metrics": {"rewards/0_mean": 10.011609565920946, "rewards/0_min": -0.9608917236328125, "rewards/0_max": 79.39010620117188, "rewards/1_mean": 10.011609565920946, "rewards/1_min": -0.9608917236328125, "rewards/1_max": 79.39010620117188, "rewards/2_mean": 10.011609565920946, "rewards/2_min": -0.9608917236328125, "rewards/2_max": 79.39010620117188, "rewards/3_mean": 10.011609565920946, "rewards/3_min": -0.9608917236328125, "rewards/3_max": 79.39010620117188, "rewards/4_mean": 10.011609565920946, "rewards/4_min": -0.9608917236328125, "rewards/4_max": 79.39010620117188}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13953505554864745, "policy_loss": -0.009265607577334675, "vf_loss": 0.11611982599373848, "vf_explained_var": 0.9897544630936214, "kl": 0.01344697974577901, "entropy": 24.70700316050696, "entropy_coeff": 0.01, "grad_gnorm": 1.5344553943900836}, "model": {}, "num_grad_updates_lifetime": 41535.5, "diff_num_grad_updates_vs_sampler_policy": 41534.5}}, "num_env_steps_sampled": 23483531, "num_env_steps_trained": 23483531, "num_agent_steps_sampled": 23483531, "num_agent_steps_trained": 23483531}, "sampler_results": {"episode_reward_max": 79.39010620117188, "episode_reward_min": -0.9608917236328125, "episode_reward_mean": 10.011609565920946, "episode_len_mean": 495.8292682926829, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.011609565920946, "rewards/0_min": -0.9608917236328125, "rewards/0_max": 79.39010620117188, "rewards/1_mean": 10.011609565920946, "rewards/1_min": -0.9608917236328125, "rewards/1_max": 79.39010620117188, "rewards/2_mean": 10.011609565920946, "rewards/2_min": -0.9608917236328125, "rewards/2_max": 79.39010620117188, "rewards/3_mean": 10.011609565920946, "rewards/3_min": -0.9608917236328125, "rewards/3_max": 79.39010620117188, "rewards/4_mean": 10.011609565920946, "rewards/4_min": -0.9608917236328125, "rewards/4_max": 79.39010620117188}, "hist_stats": {"episode_reward": [-0.08986663818359375, 0.0, 16.46755599975586, -0.03635406494140625, 0.0, 0.0, 0.54644775390625, 0.0, 0.12298583984375, -0.1916656494140625, 0.0, 37.29523468017578, 22.6593017578125, 0.0, -0.26788330078125, 0.0, 0.0, 51.255165100097656, 20.54430389404297, 64.0876693725586, 79.39010620117188, 0.0, 38.606224060058594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.15789031982422, 0.2387237548828125, 0.36962890625, 0.0, 0.0, -0.446624755859375, 29.67273712158203, 0.0, -0.3647918701171875, -0.112640380859375, 49.69306564331055, -0.13304901123046875, 0.0, 0.0, 0.0, 20.415653228759766, 0.0, -0.7307624816894531, 0.08464813232421875, 0.0, 0.0520782470703125, 5.113067626953125, 0.0, 59.122724533081055, 0.0, -0.9608917236328125, 0.0, 0.0, 0.0, 5.454425811767578, 0.0, 0.0, 0.0, 15.837471008300781, -0.09100341796875, 49.84320831298828, 52.231353759765625, 0.0, -0.5861778259277344, 16.4564208984375, 11.336044311523438, 0.0, 47.136112213134766, 0.0, 0.0, 41.472434997558594, -0.18488311767578125, 0.0, 20.606185913085938, 33.076995849609375, 0.0, -0.4631233215332031, 0.0118255615234375, 0.14850616455078125, 0.0, 0.0, 0.0, 38.57157897949219, -0.835968017578125, 32.387556076049805, 0.0, 66.44064331054688, 46.722299575805664, 0.0, 0.0, 0.0, 0.0, 0.0, 67.99083709716797, 0.3869476318359375, 0.0, 5.592315673828125, 0.0, 0.0, -0.16080474853515625, 0.0, 0.0, 0.0, 56.0009880065918, 0.0, 0.0, 0.0, 0.0, -0.1272735595703125, 4.9673614501953125, 0.0, 0.0, 0.7223129272460938, -0.03265380859375, 32.126251220703125, 22.676605224609375, 0.0, 1.1525001525878906], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 478, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 396, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625781571929236, "mean_inference_ms": 4.943587596475332, "mean_action_processing_ms": 7.420877382973004, "mean_env_wait_ms": 11.367992133590317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 79.39010620117188, "episode_reward_min": -0.9608917236328125, "episode_reward_mean": 10.011609565920946, "episode_len_mean": 495.8292682926829, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-0.08986663818359375, 0.0, 16.46755599975586, -0.03635406494140625, 0.0, 0.0, 0.54644775390625, 0.0, 0.12298583984375, -0.1916656494140625, 0.0, 37.29523468017578, 22.6593017578125, 0.0, -0.26788330078125, 0.0, 0.0, 51.255165100097656, 20.54430389404297, 64.0876693725586, 79.39010620117188, 0.0, 38.606224060058594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.15789031982422, 0.2387237548828125, 0.36962890625, 0.0, 0.0, -0.446624755859375, 29.67273712158203, 0.0, -0.3647918701171875, -0.112640380859375, 49.69306564331055, -0.13304901123046875, 0.0, 0.0, 0.0, 20.415653228759766, 0.0, -0.7307624816894531, 0.08464813232421875, 0.0, 0.0520782470703125, 5.113067626953125, 0.0, 59.122724533081055, 0.0, -0.9608917236328125, 0.0, 0.0, 0.0, 5.454425811767578, 0.0, 0.0, 0.0, 15.837471008300781, -0.09100341796875, 49.84320831298828, 52.231353759765625, 0.0, -0.5861778259277344, 16.4564208984375, 11.336044311523438, 0.0, 47.136112213134766, 0.0, 0.0, 41.472434997558594, -0.18488311767578125, 0.0, 20.606185913085938, 33.076995849609375, 0.0, -0.4631233215332031, 0.0118255615234375, 0.14850616455078125, 0.0, 0.0, 0.0, 38.57157897949219, -0.835968017578125, 32.387556076049805, 0.0, 66.44064331054688, 46.722299575805664, 0.0, 0.0, 0.0, 0.0, 0.0, 67.99083709716797, 0.3869476318359375, 0.0, 5.592315673828125, 0.0, 0.0, -0.16080474853515625, 0.0, 0.0, 0.0, 56.0009880065918, 0.0, 0.0, 0.0, 0.0, -0.1272735595703125, 4.9673614501953125, 0.0, 0.0, 0.7223129272460938, -0.03265380859375, 32.126251220703125, 22.676605224609375, 0.0, 1.1525001525878906], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 478, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 254, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 396, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625781571929236, "mean_inference_ms": 4.943587596475332, "mean_action_processing_ms": 7.420877382973004, "mean_env_wait_ms": 11.367992133590317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23483531, "num_agent_steps_trained": 23483531, "num_env_steps_sampled": 23483531, "num_env_steps_trained": 23483531, "num_env_steps_sampled_this_iter": 60987, "num_env_steps_trained_this_iter": 60987, "timesteps_total": 23483531, "num_steps_trained_this_iter": 60987, "agent_timesteps_total": 23483531, "timers": {"training_iteration_time_ms": 46893.748, "load_time_ms": 48.227, "load_throughput": 1261496.042, "learn_time_ms": 26615.411, "learn_throughput": 2285.826, "synch_weights_time_ms": 8.996}, "counters": {"num_env_steps_sampled": 23483531, "num_env_steps_trained": 23483531, "num_agent_steps_sampled": 23483531, "num_agent_steps_trained": 23483531}, "done": false, "episodes_total": 47560, "training_iteration": 387, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-14-51", "timestamp": 1735110891, "time_this_iter_s": 46.26967692375183, "time_total_s": 11994.178691387177, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3AE6F80>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CBF490>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 3137.0487926006317, "timesteps_since_restore": 0, "iterations_since_restore": 66, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.556923076923077, "ram_util_percent": 96.37538461538462}}
{"custom_metrics": {"rewards/0_mean": 10.525055100840907, "rewards/0_min": -1.02667236328125, "rewards/0_max": 84.57307815551758, "rewards/1_mean": 10.525055100840907, "rewards/1_min": -1.02667236328125, "rewards/1_max": 84.57307815551758, "rewards/2_mean": 10.525055100840907, "rewards/2_min": -1.02667236328125, "rewards/2_max": 84.57307815551758, "rewards/3_mean": 10.525055100840907, "rewards/3_min": -1.02667236328125, "rewards/3_max": 84.57307815551758, "rewards/4_mean": 10.525055100840907, "rewards/4_min": -1.02667236328125, "rewards/4_max": 84.57307815551758}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13994743202236437, "policy_loss": 0.0009598126546258018, "vf_loss": 0.08440254574848546, "vf_explained_var": 0.9875929422794827, "kl": 0.01212266910089446, "entropy": 22.59235062977624, "entropy_coeff": 0.01, "grad_gnorm": 1.3676988374619257}, "model": {}, "num_grad_updates_lifetime": 42165.5, "diff_num_grad_updates_vs_sampler_policy": 42164.5}}, "num_env_steps_sampled": 23544679, "num_env_steps_trained": 23544679, "num_agent_steps_sampled": 23544679, "num_agent_steps_trained": 23544679}, "sampler_results": {"episode_reward_max": 84.57307815551758, "episode_reward_min": -1.02667236328125, "episode_reward_mean": 10.525055100840907, "episode_len_mean": 493.1290322580645, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.525055100840907, "rewards/0_min": -1.02667236328125, "rewards/0_max": 84.57307815551758, "rewards/1_mean": 10.525055100840907, "rewards/1_min": -1.02667236328125, "rewards/1_max": 84.57307815551758, "rewards/2_mean": 10.525055100840907, "rewards/2_min": -1.02667236328125, "rewards/2_max": 84.57307815551758, "rewards/3_mean": 10.525055100840907, "rewards/3_min": -1.02667236328125, "rewards/3_max": 84.57307815551758, "rewards/4_mean": 10.525055100840907, "rewards/4_min": -1.02667236328125, "rewards/4_max": 84.57307815551758}, "hist_stats": {"episode_reward": [0.0, 31.82298469543457, 0.0, 0.05096626281738281, 48.43043518066406, 36.43976402282715, -1.02667236328125, 0.0, 0.0, 0.0, 0.0, 29.13166046142578, 0.0, 0.0, 28.0257568359375, 0.0, 0.0, 71.40555572509766, 0.0, 3.0206222534179688, 63.5383358001709, 0.2566070556640625, 19.01437759399414, 0.0, 26.193809509277344, 36.11602783203125, 0.0, 3.122161865234375, 0.0, 0.0, 0.2144775390625, 31.611419677734375, 0.0, 0.0, 84.57307815551758, 0.0, 0.0, -0.3065032958984375, 31.12154769897461, 0.44140625, 26.743247985839844, 0.0, 37.62022399902344, -0.03955078125, 0.0, 0.16085052490234375, 0.04148101806640625, 3.6423797607421875, 0.0, 0.0, 0.0, 5.846746444702148, 0.0, 0.0, 8.038955688476562, 0.0, -0.18071365356445312, 0.0, 0.0, -0.0142974853515625, 9.085250854492188, 0.0, 0.0, 0.0, -0.08986663818359375, -0.0131683349609375, -0.2509765625, 38.14111328125, 0.011371612548828125, 0.6156749725341797, 0.0, -0.21463775634765625, 61.04423522949219, 0.0, 46.43490219116211, 43.15531539916992, 0.0, 0.0, 0.0, 0.0, 17.62383270263672, 10.2999267578125, 12.722000122070312, -0.19353485107421875, 0.0, 54.73951721191406, 0.0, 1.165252685546875, -0.08934783935546875, -0.5105781555175781, -0.10237884521484375, 0.15252685546875, 40.84648895263672, 0.0, 22.14892578125, 0.0, 51.79509353637695, 0.1103515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1572723388671875, 0.0, 19.022659301757812, 0.0, 0.0, 39.89234733581543, 0.108978271484375, 0.0, 0.0, 57.0017204284668, 20.13385772705078, 0.0, 24.22296142578125, 51.862403869628906, 50.70893096923828, 0.10857009887695312, 0.0, 3.9840469360351562, -0.17822265625, 4.396873474121094], "episode_lengths": [500, 261, 500, 500, 500, 465, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 352, 500, 500, 500, 500, 378, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 333, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625713410791695, "mean_inference_ms": 4.941783617437905, "mean_action_processing_ms": 7.419451144886912, "mean_env_wait_ms": 11.367530270599397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 84.57307815551758, "episode_reward_min": -1.02667236328125, "episode_reward_mean": 10.525055100840907, "episode_len_mean": 493.1290322580645, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 31.82298469543457, 0.0, 0.05096626281738281, 48.43043518066406, 36.43976402282715, -1.02667236328125, 0.0, 0.0, 0.0, 0.0, 29.13166046142578, 0.0, 0.0, 28.0257568359375, 0.0, 0.0, 71.40555572509766, 0.0, 3.0206222534179688, 63.5383358001709, 0.2566070556640625, 19.01437759399414, 0.0, 26.193809509277344, 36.11602783203125, 0.0, 3.122161865234375, 0.0, 0.0, 0.2144775390625, 31.611419677734375, 0.0, 0.0, 84.57307815551758, 0.0, 0.0, -0.3065032958984375, 31.12154769897461, 0.44140625, 26.743247985839844, 0.0, 37.62022399902344, -0.03955078125, 0.0, 0.16085052490234375, 0.04148101806640625, 3.6423797607421875, 0.0, 0.0, 0.0, 5.846746444702148, 0.0, 0.0, 8.038955688476562, 0.0, -0.18071365356445312, 0.0, 0.0, -0.0142974853515625, 9.085250854492188, 0.0, 0.0, 0.0, -0.08986663818359375, -0.0131683349609375, -0.2509765625, 38.14111328125, 0.011371612548828125, 0.6156749725341797, 0.0, -0.21463775634765625, 61.04423522949219, 0.0, 46.43490219116211, 43.15531539916992, 0.0, 0.0, 0.0, 0.0, 17.62383270263672, 10.2999267578125, 12.722000122070312, -0.19353485107421875, 0.0, 54.73951721191406, 0.0, 1.165252685546875, -0.08934783935546875, -0.5105781555175781, -0.10237884521484375, 0.15252685546875, 40.84648895263672, 0.0, 22.14892578125, 0.0, 51.79509353637695, 0.1103515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1572723388671875, 0.0, 19.022659301757812, 0.0, 0.0, 39.89234733581543, 0.108978271484375, 0.0, 0.0, 57.0017204284668, 20.13385772705078, 0.0, 24.22296142578125, 51.862403869628906, 50.70893096923828, 0.10857009887695312, 0.0, 3.9840469360351562, -0.17822265625, 4.396873474121094], "episode_lengths": [500, 261, 500, 500, 500, 465, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 359, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 352, 500, 500, 500, 500, 378, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 333, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.625713410791695, "mean_inference_ms": 4.941783617437905, "mean_action_processing_ms": 7.419451144886912, "mean_env_wait_ms": 11.367530270599397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23544679, "num_agent_steps_trained": 23544679, "num_env_steps_sampled": 23544679, "num_env_steps_trained": 23544679, "num_env_steps_sampled_this_iter": 61148, "num_env_steps_trained_this_iter": 61148, "timesteps_total": 23544679, "num_steps_trained_this_iter": 61148, "agent_timesteps_total": 23544679, "timers": {"training_iteration_time_ms": 46763.777, "load_time_ms": 48.109, "load_throughput": 1264730.704, "learn_time_ms": 26537.497, "learn_throughput": 2292.805, "synch_weights_time_ms": 8.99}, "counters": {"num_env_steps_sampled": 23544679, "num_env_steps_trained": 23544679, "num_agent_steps_sampled": 23544679, "num_agent_steps_trained": 23544679}, "done": false, "episodes_total": 47684, "training_iteration": 388, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-15-38", "timestamp": 1735110938, "time_this_iter_s": 46.57515597343445, "time_total_s": 12040.753847360611, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B093F0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CBEEF0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 3183.623948574066, "timesteps_since_restore": 0, "iterations_since_restore": 67, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 22.329230769230765, "ram_util_percent": 96.32769230769233}}
{"custom_metrics": {"rewards/0_mean": 10.140627430331323, "rewards/0_min": -0.31573486328125, "rewards/0_max": 88.61549377441406, "rewards/1_mean": 10.140627430331323, "rewards/1_min": -0.31573486328125, "rewards/1_max": 88.61549377441406, "rewards/2_mean": 10.140627430331323, "rewards/2_min": -0.31573486328125, "rewards/2_max": 88.61549377441406, "rewards/3_mean": 10.140627430331323, "rewards/3_min": -0.31573486328125, "rewards/3_max": 88.61549377441406, "rewards/4_mean": 10.140627430331323, "rewards/4_min": -0.31573486328125, "rewards/4_max": 88.61549377441406}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.12180267147394637, "policy_loss": -0.005527795217044297, "vf_loss": 0.11464343849007809, "vf_explained_var": 0.9877046643741547, "kl": 0.012601788534915873, "entropy": 23.155628543429906, "entropy_coeff": 0.01, "grad_gnorm": 1.3849065827708396}, "model": {}, "num_grad_updates_lifetime": 42795.5, "diff_num_grad_updates_vs_sampler_policy": 42794.5}}, "num_env_steps_sampled": 23605876, "num_env_steps_trained": 23605876, "num_agent_steps_sampled": 23605876, "num_agent_steps_trained": 23605876}, "sampler_results": {"episode_reward_max": 88.61549377441406, "episode_reward_min": -0.31573486328125, "episode_reward_mean": 10.140627430331323, "episode_len_mean": 493.5241935483871, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.140627430331323, "rewards/0_min": -0.31573486328125, "rewards/0_max": 88.61549377441406, "rewards/1_mean": 10.140627430331323, "rewards/1_min": -0.31573486328125, "rewards/1_max": 88.61549377441406, "rewards/2_mean": 10.140627430331323, "rewards/2_min": -0.31573486328125, "rewards/2_max": 88.61549377441406, "rewards/3_mean": 10.140627430331323, "rewards/3_min": -0.31573486328125, "rewards/3_max": 88.61549377441406, "rewards/4_mean": 10.140627430331323, "rewards/4_min": -0.31573486328125, "rewards/4_max": 88.61549377441406}, "hist_stats": {"episode_reward": [0.0, 0.309417724609375, 9.317798614501953, 0.0645751953125, 14.811363220214844, 0.0, 74.96621704101562, 37.064308166503906, 29.62945556640625, 0.0, 0.7757034301757812, 0.0, 0.0, -0.162353515625, 0.0, 0.0, 0.3476715087890625, 60.30626106262207, 0.18849563598632812, 74.0403823852539, 0.329132080078125, 13.250373840332031, 88.61549377441406, 0.0, -0.31573486328125, 0.0, 0.2572021484375, 4.812999725341797, 0.0, 39.46221923828125, 46.74700164794922, 27.930885314941406, 0.0, 0.0, -0.2378082275390625, 0.0, 51.21516990661621, -0.15892791748046875, 1.594940185546875, 28.501861572265625, 0.116912841796875, 0.0, 22.38311767578125, 0.0, -0.0693511962890625, 0.0, 0.26425933837890625, 54.689697265625, 3.05487060546875, 0.0, 21.22657012939453, 0.16983795166015625, 0.0, 0.0, 0.0, -0.1732635498046875, 0.0, 20.210220336914062, 0.0, 38.25144958496094, 0.0, 58.145606994628906, 0.0, 0.0, 0.0, -0.1099395751953125, 39.507232666015625, 0.26685333251953125, 0.0, 0.0, 26.19353485107422, -0.18711090087890625, 11.120094299316406, 0.0, -0.07330322265625, 0.0, 0.0, 43.41883087158203, 0.0, -0.01747894287109375, 0.0, 9.004283905029297, 0.0, 0.0, 19.79277801513672, 31.88861083984375, 25.172210693359375, 0.0, 23.246299743652344, 1.9593734741210938, 17.62298583984375, 0.0, 0.341552734375, 0.0, 0.17021942138671875, 61.22038269042969, 0.0, -0.0920257568359375, 0.0, 0.0, 0.0, -0.2290496826171875, 0.0, 0.0, 0.0, 0.0, 2.5537033081054688, 24.84844970703125, -0.3091583251953125, 10.217666625976562, 0.0, 0.0037384033203125, 10.201087951660156, 0.0, 0.0, 0.0, 0.0, -0.0176544189453125, 0.0, 2.5580825805664062, 61.33030700683594, 9.09158706665039, 1.20672607421875, 3.6028976440429688], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 133, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 358, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.6231861697835, "mean_inference_ms": 4.939494111513113, "mean_action_processing_ms": 7.414590043333748, "mean_env_wait_ms": 11.362704771125697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 88.61549377441406, "episode_reward_min": -0.31573486328125, "episode_reward_mean": 10.140627430331323, "episode_len_mean": 493.5241935483871, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.309417724609375, 9.317798614501953, 0.0645751953125, 14.811363220214844, 0.0, 74.96621704101562, 37.064308166503906, 29.62945556640625, 0.0, 0.7757034301757812, 0.0, 0.0, -0.162353515625, 0.0, 0.0, 0.3476715087890625, 60.30626106262207, 0.18849563598632812, 74.0403823852539, 0.329132080078125, 13.250373840332031, 88.61549377441406, 0.0, -0.31573486328125, 0.0, 0.2572021484375, 4.812999725341797, 0.0, 39.46221923828125, 46.74700164794922, 27.930885314941406, 0.0, 0.0, -0.2378082275390625, 0.0, 51.21516990661621, -0.15892791748046875, 1.594940185546875, 28.501861572265625, 0.116912841796875, 0.0, 22.38311767578125, 0.0, -0.0693511962890625, 0.0, 0.26425933837890625, 54.689697265625, 3.05487060546875, 0.0, 21.22657012939453, 0.16983795166015625, 0.0, 0.0, 0.0, -0.1732635498046875, 0.0, 20.210220336914062, 0.0, 38.25144958496094, 0.0, 58.145606994628906, 0.0, 0.0, 0.0, -0.1099395751953125, 39.507232666015625, 0.26685333251953125, 0.0, 0.0, 26.19353485107422, -0.18711090087890625, 11.120094299316406, 0.0, -0.07330322265625, 0.0, 0.0, 43.41883087158203, 0.0, -0.01747894287109375, 0.0, 9.004283905029297, 0.0, 0.0, 19.79277801513672, 31.88861083984375, 25.172210693359375, 0.0, 23.246299743652344, 1.9593734741210938, 17.62298583984375, 0.0, 0.341552734375, 0.0, 0.17021942138671875, 61.22038269042969, 0.0, -0.0920257568359375, 0.0, 0.0, 0.0, -0.2290496826171875, 0.0, 0.0, 0.0, 0.0, 2.5537033081054688, 24.84844970703125, -0.3091583251953125, 10.217666625976562, 0.0, 0.0037384033203125, 10.201087951660156, 0.0, 0.0, 0.0, 0.0, -0.0176544189453125, 0.0, 2.5580825805664062, 61.33030700683594, 9.09158706665039, 1.20672607421875, 3.6028976440429688], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 464, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 242, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 133, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 358, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.6231861697835, "mean_inference_ms": 4.939494111513113, "mean_action_processing_ms": 7.414590043333748, "mean_env_wait_ms": 11.362704771125697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23605876, "num_agent_steps_trained": 23605876, "num_env_steps_sampled": 23605876, "num_env_steps_trained": 23605876, "num_env_steps_sampled_this_iter": 61197, "num_env_steps_trained_this_iter": 61197, "timesteps_total": 23605876, "num_steps_trained_this_iter": 61197, "agent_timesteps_total": 23605876, "timers": {"training_iteration_time_ms": 46713.098, "load_time_ms": 48.738, "load_throughput": 1248617.024, "learn_time_ms": 26554.998, "learn_throughput": 2291.663, "synch_weights_time_ms": 8.997}, "counters": {"num_env_steps_sampled": 23605876, "num_env_steps_trained": 23605876, "num_agent_steps_sampled": 23605876, "num_agent_steps_trained": 23605876}, "done": false, "episodes_total": 47808, "training_iteration": 389, "trial_id": "8510f_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_15-16-25", "timestamp": 1735110985, "time_this_iter_s": 47.2976291179657, "time_total_s": 12088.051476478577, "pid": 22980, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000001F7E3B0A410>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000001F7E3CBD120>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 3230.921577692032, "timesteps_since_restore": 0, "iterations_since_restore": 68, "warmup_time": 27.565417051315308, "perf": {"cpu_util_percent": 21.90597014925373, "ram_util_percent": 96.68059701492537}}
