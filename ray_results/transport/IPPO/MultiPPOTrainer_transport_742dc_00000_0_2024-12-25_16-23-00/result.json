{"evaluation": {"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 0.0, "rewards/0_min": 0.0, "rewards/0_max": 0.0, "rewards/1_mean": 0.0, "rewards/1_min": 0.0, "rewards/1_max": 0.0, "rewards/2_mean": 0.0, "rewards/2_min": 0.0, "rewards/2_max": 0.0, "rewards/3_mean": 0.0, "rewards/3_min": 0.0, "rewards/3_max": 0.0, "rewards/4_mean": 0.0, "rewards/4_min": 0.0, "rewards/4_max": 0.0}, "hist_stats": {"episode_reward": [0.0], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4403286589357905, "mean_inference_ms": 2.213067875174943, "mean_action_processing_ms": 0.26341065199313285, "mean_env_wait_ms": 3.3362597048639535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 13.942929819226265, "rewards/0_min": -0.5146331787109375, "rewards/0_max": 91.12462615966797, "rewards/1_mean": 13.942929819226265, "rewards/1_min": -0.5146331787109375, "rewards/1_max": 91.12462615966797, "rewards/2_mean": 13.942929819226265, "rewards/2_min": -0.5146331787109375, "rewards/2_max": 91.12462615966797, "rewards/3_mean": 13.942929819226265, "rewards/3_min": -0.5146331787109375, "rewards/3_max": 91.12462615966797, "rewards/4_mean": 13.942929819226265, "rewards/4_min": -0.5146331787109375, "rewards/4_max": 91.12462615966797}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.07742459046255265, "policy_loss": -0.009847219919209324, "vf_loss": 0.14098057259642888, "vf_explained_var": 0.9894178445377048, "kl": 0.00877815982447325, "entropy": 20.90023424511864, "entropy_coeff": 0.01, "grad_gnorm": 1.1674800300408923}, "model": {}, "num_grad_updates_lifetime": 315.5, "diff_num_grad_updates_vs_sampler_policy": 314.5}}, "num_env_steps_sampled": 23667242, "num_env_steps_trained": 23667242, "num_agent_steps_sampled": 23667242, "num_agent_steps_trained": 23667242}, "sampler_results": {"episode_reward_max": 91.12462615966797, "episode_reward_min": -0.5146331787109375, "episode_reward_mean": 13.942929819226265, "episode_len_mean": 479.421875, "episode_media": {}, "episodes_this_iter": 128, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 13.942929819226265, "rewards/0_min": -0.5146331787109375, "rewards/0_max": 91.12462615966797, "rewards/1_mean": 13.942929819226265, "rewards/1_min": -0.5146331787109375, "rewards/1_max": 91.12462615966797, "rewards/2_mean": 13.942929819226265, "rewards/2_min": -0.5146331787109375, "rewards/2_max": 91.12462615966797, "rewards/3_mean": 13.942929819226265, "rewards/3_min": -0.5146331787109375, "rewards/3_max": 91.12462615966797, "rewards/4_mean": 13.942929819226265, "rewards/4_min": -0.5146331787109375, "rewards/4_max": 91.12462615966797}, "hist_stats": {"episode_reward": [40.79288673400879, 0.0, -0.22906494140625, 0.0, 30.511917114257812, 1.6144485473632812, 38.05712890625, 8.155242919921875, 0.0, 59.13652420043945, 0.63494873046875, 39.58062744140625, 23.591583251953125, 4.595115661621094, 5.441495895385742, 0.517425537109375, 0.0, 0.0, 0.0092926025390625, 52.42125701904297, -0.178314208984375, 7.578758239746094, 0.08068084716796875, 20.911453247070312, 7.926540374755859, 3.7997074127197266, 54.58819389343262, 28.85049057006836, 0.0, 3.149017333984375, 55.47156524658203, 31.57452392578125, -0.035430908203125, 0.0, 0.3350067138671875, 0.0, 32.68242645263672, 51.57884979248047, -0.0713348388671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19170761108398438, 0.48026275634765625, 26.948501586914062, 41.66560363769531, 59.21253204345703, 0.0, 39.59484100341797, 20.18349266052246, 0.0373077392578125, 19.0863037109375, 0.59674072265625, 0.0, 1.0708389282226562, 0.0, 0.0, 20.743284225463867, 0.0, 54.300987243652344, 4.098915100097656, 0.0105743408203125, 18.246612548828125, 53.31768798828125, 0.0, 51.706321716308594, 0.0, 0.0, 44.136924743652344, 0.0, 0.0, 0.0, 16.704587936401367, 0.04730224609375, 19.691814422607422, 2.9112167358398438, 45.33366012573242, 0.3997802734375, 0.1919708251953125, 14.99017333984375, 11.4605712890625, 0.0, 0.0, 8.983455657958984, 13.226814270019531, 0.33928680419921875, 34.84172058105469, 10.247207641601562, 37.45925521850586, 0.0, 0.133148193359375, 0.0, -0.358917236328125, 0.0, 4.958307266235352, 0.0, 89.38699340820312, 0.0, 19.60310173034668, -0.5146331787109375, 1.3561992645263672, 10.326454162597656, 0.0, 0.628509521484375, 39.71494674682617, -0.1440277099609375, 0.04579734802246094, 0.0, -0.06803131103515625, 65.50369644165039, 0.0, 0.05167388916015625, 26.13970947265625, 0.0, 0.0, 0.0, 14.131568908691406, 0.0, 23.029296875, 91.12462615966797, 0.0, 0.0, 43.11213684082031, -0.1505584716796875, 39.166717529296875, 41.98707962036133], "episode_lengths": [485, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 320, 313, 456, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 302, 344, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 213, 500, 204, 339, 356, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 44, 299, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.280414935195353, "mean_inference_ms": 3.253284310022622, "mean_action_processing_ms": 4.532605210309257, "mean_env_wait_ms": 7.227913018115216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 91.12462615966797, "episode_reward_min": -0.5146331787109375, "episode_reward_mean": 13.942929819226265, "episode_len_mean": 479.421875, "episodes_this_iter": 128, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [40.79288673400879, 0.0, -0.22906494140625, 0.0, 30.511917114257812, 1.6144485473632812, 38.05712890625, 8.155242919921875, 0.0, 59.13652420043945, 0.63494873046875, 39.58062744140625, 23.591583251953125, 4.595115661621094, 5.441495895385742, 0.517425537109375, 0.0, 0.0, 0.0092926025390625, 52.42125701904297, -0.178314208984375, 7.578758239746094, 0.08068084716796875, 20.911453247070312, 7.926540374755859, 3.7997074127197266, 54.58819389343262, 28.85049057006836, 0.0, 3.149017333984375, 55.47156524658203, 31.57452392578125, -0.035430908203125, 0.0, 0.3350067138671875, 0.0, 32.68242645263672, 51.57884979248047, -0.0713348388671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19170761108398438, 0.48026275634765625, 26.948501586914062, 41.66560363769531, 59.21253204345703, 0.0, 39.59484100341797, 20.18349266052246, 0.0373077392578125, 19.0863037109375, 0.59674072265625, 0.0, 1.0708389282226562, 0.0, 0.0, 20.743284225463867, 0.0, 54.300987243652344, 4.098915100097656, 0.0105743408203125, 18.246612548828125, 53.31768798828125, 0.0, 51.706321716308594, 0.0, 0.0, 44.136924743652344, 0.0, 0.0, 0.0, 16.704587936401367, 0.04730224609375, 19.691814422607422, 2.9112167358398438, 45.33366012573242, 0.3997802734375, 0.1919708251953125, 14.99017333984375, 11.4605712890625, 0.0, 0.0, 8.983455657958984, 13.226814270019531, 0.33928680419921875, 34.84172058105469, 10.247207641601562, 37.45925521850586, 0.0, 0.133148193359375, 0.0, -0.358917236328125, 0.0, 4.958307266235352, 0.0, 89.38699340820312, 0.0, 19.60310173034668, -0.5146331787109375, 1.3561992645263672, 10.326454162597656, 0.0, 0.628509521484375, 39.71494674682617, -0.1440277099609375, 0.04579734802246094, 0.0, -0.06803131103515625, 65.50369644165039, 0.0, 0.05167388916015625, 26.13970947265625, 0.0, 0.0, 0.0, 14.131568908691406, 0.0, 23.029296875, 91.12462615966797, 0.0, 0.0, 43.11213684082031, -0.1505584716796875, 39.166717529296875, 41.98707962036133], "episode_lengths": [485, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 320, 313, 456, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 302, 344, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 213, 500, 204, 339, 356, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 191, 500, 44, 299, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.280414935195353, "mean_inference_ms": 3.253284310022622, "mean_action_processing_ms": 4.532605210309257, "mean_env_wait_ms": 7.227913018115216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23667242, "num_agent_steps_trained": 23667242, "num_env_steps_sampled": 23667242, "num_env_steps_trained": 23667242, "num_env_steps_sampled_this_iter": 61366, "num_env_steps_trained_this_iter": 61366, "timesteps_total": 23667242, "num_steps_trained_this_iter": 61366, "agent_timesteps_total": 23667242, "timers": {"training_iteration_time_ms": 38320.595, "load_time_ms": 31.25, "load_throughput": 1963741.964, "learn_time_ms": 19904.849, "learn_throughput": 3082.967, "synch_weights_time_ms": 5.925}, "counters": {"num_env_steps_sampled": 23667242, "num_env_steps_trained": 23667242, "num_agent_steps_sampled": 23667242, "num_agent_steps_trained": 23667242}, "done": false, "episodes_total": 47936, "training_iteration": 390, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-24-04", "timestamp": 1735115044, "time_this_iter_s": 38.32953214645386, "time_total_s": 12126.38100862503, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8C4BB0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F4D51B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 38.32953214645386, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 35.77272727272727, "ram_util_percent": 97.89818181818178}}
{"custom_metrics": {"rewards/0_mean": 8.46361395983192, "rewards/0_min": -0.41620635986328125, "rewards/0_max": 79.71276473999023, "rewards/1_mean": 8.46361395983192, "rewards/1_min": -0.41620635986328125, "rewards/1_max": 79.71276473999023, "rewards/2_mean": 8.46361395983192, "rewards/2_min": -0.41620635986328125, "rewards/2_max": 79.71276473999023, "rewards/3_mean": 8.46361395983192, "rewards/3_min": -0.41620635986328125, "rewards/3_max": 79.71276473999023, "rewards/4_mean": 8.46361395983192, "rewards/4_min": -0.41620635986328125, "rewards/4_max": 79.71276473999023}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.15605551073298093, "policy_loss": -0.0069874711371662596, "vf_loss": 0.09711362629692764, "vf_explained_var": 0.9823743023569622, "kl": 0.01226363634868037, "entropy": 24.68025181331332, "entropy_coeff": 0.01, "grad_gnorm": 1.5318434607651499}, "model": {}, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 23728100, "num_env_steps_trained": 23728100, "num_agent_steps_sampled": 23728100, "num_agent_steps_trained": 23728100}, "sampler_results": {"episode_reward_max": 79.71276473999023, "episode_reward_min": -0.41620635986328125, "episode_reward_mean": 8.46361395983192, "episode_len_mean": 494.780487804878, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.46361395983192, "rewards/0_min": -0.41620635986328125, "rewards/0_max": 79.71276473999023, "rewards/1_mean": 8.46361395983192, "rewards/1_min": -0.41620635986328125, "rewards/1_max": 79.71276473999023, "rewards/2_mean": 8.46361395983192, "rewards/2_min": -0.41620635986328125, "rewards/2_max": 79.71276473999023, "rewards/3_mean": 8.46361395983192, "rewards/3_min": -0.41620635986328125, "rewards/3_max": 79.71276473999023, "rewards/4_mean": 8.46361395983192, "rewards/4_min": -0.41620635986328125, "rewards/4_max": 79.71276473999023}, "hist_stats": {"episode_reward": [16.886022567749023, 0.0, 0.0, 0.0, 7.549976348876953, 0.0379638671875, 44.99131774902344, -0.0153045654296875, 0.0, 0.0, 0.0, 5.18804931640625, 8.842941284179688, 3.3366241455078125, 18.368927001953125, 0.0, 58.363609313964844, 0.0, 33.66161346435547, 20.839332580566406, 34.93068313598633, 26.90906524658203, 24.39794158935547, 26.987241744995117, 0.0, 0.0, 24.765777587890625, 0.0, 23.080184936523438, 0.0, -0.35445404052734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.41620635986328125, 0.0, 79.71276473999023, -0.22088623046875, 0.0, 0.014892578125, 0.0936126708984375, -0.3826751708984375, 27.27630615234375, 1.7739410400390625, 0.0, 0.33141326904296875, 0.0, 0.0, 0.0, 0.0, 14.857688903808594, 0.0, 45.86116027832031, 0.0, 0.0, 17.514419555664062, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0713577270507812, 0.0, 0.0, -0.0629425048828125, 0.0, 0.0, 0.0, -0.2737884521484375, 55.84838104248047, 62.66841125488281, 0.5598258972167969, 15.0167236328125, -0.062225341796875, 3.7762908935546875, 0.0, 35.856475830078125, 66.68848419189453, 31.164352416992188, 0.0, 0.2601776123046875, 0.0, 0.0, 0.444183349609375, 11.400360107421875, 0.0, 5.4902496337890625, 5.170036315917969, 0.1543731689453125, 14.421058654785156, 0.0, 0.35406494140625, 29.84814453125, 0.0, -0.13499832153320312, 47.299713134765625, -0.188232421875, 0.113128662109375, 0.0, 0.0751495361328125, 0.0, 16.51453399658203, 0.0, 12.074676513671875, 4.298484802246094, 0.09961700439453125, 48.292755126953125, 0.0, 0.0, -0.0296478271484375, 0.0, 0.0, 0.0, 0.26873016357421875, 5.362667083740234, 0.0, 0.0], "episode_lengths": [326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 204, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 443, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 385, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.716216833841481, "mean_inference_ms": 3.078057458293335, "mean_action_processing_ms": 4.491315965766687, "mean_env_wait_ms": 7.013204271115937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 79.71276473999023, "episode_reward_min": -0.41620635986328125, "episode_reward_mean": 8.46361395983192, "episode_len_mean": 494.780487804878, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [16.886022567749023, 0.0, 0.0, 0.0, 7.549976348876953, 0.0379638671875, 44.99131774902344, -0.0153045654296875, 0.0, 0.0, 0.0, 5.18804931640625, 8.842941284179688, 3.3366241455078125, 18.368927001953125, 0.0, 58.363609313964844, 0.0, 33.66161346435547, 20.839332580566406, 34.93068313598633, 26.90906524658203, 24.39794158935547, 26.987241744995117, 0.0, 0.0, 24.765777587890625, 0.0, 23.080184936523438, 0.0, -0.35445404052734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.41620635986328125, 0.0, 79.71276473999023, -0.22088623046875, 0.0, 0.014892578125, 0.0936126708984375, -0.3826751708984375, 27.27630615234375, 1.7739410400390625, 0.0, 0.33141326904296875, 0.0, 0.0, 0.0, 0.0, 14.857688903808594, 0.0, 45.86116027832031, 0.0, 0.0, 17.514419555664062, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0713577270507812, 0.0, 0.0, -0.0629425048828125, 0.0, 0.0, 0.0, -0.2737884521484375, 55.84838104248047, 62.66841125488281, 0.5598258972167969, 15.0167236328125, -0.062225341796875, 3.7762908935546875, 0.0, 35.856475830078125, 66.68848419189453, 31.164352416992188, 0.0, 0.2601776123046875, 0.0, 0.0, 0.444183349609375, 11.400360107421875, 0.0, 5.4902496337890625, 5.170036315917969, 0.1543731689453125, 14.421058654785156, 0.0, 0.35406494140625, 29.84814453125, 0.0, -0.13499832153320312, 47.299713134765625, -0.188232421875, 0.113128662109375, 0.0, 0.0751495361328125, 0.0, 16.51453399658203, 0.0, 12.074676513671875, 4.298484802246094, 0.09961700439453125, 48.292755126953125, 0.0, 0.0, -0.0296478271484375, 0.0, 0.0, 0.0, 0.26873016357421875, 5.362667083740234, 0.0, 0.0], "episode_lengths": [326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 204, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 443, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 385, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.716216833841481, "mean_inference_ms": 3.078057458293335, "mean_action_processing_ms": 4.491315965766687, "mean_env_wait_ms": 7.013204271115937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23728100, "num_agent_steps_trained": 23728100, "num_env_steps_sampled": 23728100, "num_env_steps_trained": 23728100, "num_env_steps_sampled_this_iter": 60858, "num_env_steps_trained_this_iter": 60858, "timesteps_total": 23728100, "num_steps_trained_this_iter": 60858, "agent_timesteps_total": 23728100, "timers": {"training_iteration_time_ms": 35931.746, "load_time_ms": 39.058, "load_throughput": 1564629.546, "learn_time_ms": 19404.173, "learn_throughput": 3149.426, "synch_weights_time_ms": 3.717}, "counters": {"num_env_steps_sampled": 23728100, "num_env_steps_trained": 23728100, "num_agent_steps_sampled": 23728100, "num_agent_steps_trained": 23728100}, "done": false, "episodes_total": 48059, "training_iteration": 391, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-24-38", "timestamp": 1735115078, "time_this_iter_s": 33.54913139343262, "time_total_s": 12159.930140018463, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8EE200>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F02D2D0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 71.87866353988647, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 22.71276595744681, "ram_util_percent": 96.76595744680851}}
{"custom_metrics": {"rewards/0_mean": 10.34332782466237, "rewards/0_min": -0.7725639343261719, "rewards/0_max": 74.29769897460938, "rewards/1_mean": 10.34332782466237, "rewards/1_min": -0.7725639343261719, "rewards/1_max": 74.29769897460938, "rewards/2_mean": 10.34332782466237, "rewards/2_min": -0.7725639343261719, "rewards/2_max": 74.29769897460938, "rewards/3_mean": 10.34332782466237, "rewards/3_min": -0.7725639343261719, "rewards/3_max": 74.29769897460938, "rewards/4_mean": 10.34332782466237, "rewards/4_min": -0.7725639343261719, "rewards/4_max": 74.29769897460938}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.12880479543859513, "policy_loss": 0.002112244377060542, "vf_loss": 0.11402137466809815, "vf_explained_var": 0.9892269957633245, "kl": 0.013034215500755678, "entropy": 24.559827647133478, "entropy_coeff": 0.01, "grad_gnorm": 1.5456386589341693}, "model": {}, "num_grad_updates_lifetime": 1575.5, "diff_num_grad_updates_vs_sampler_policy": 1574.5}}, "num_env_steps_sampled": 23789004, "num_env_steps_trained": 23789004, "num_agent_steps_sampled": 23789004, "num_agent_steps_trained": 23789004}, "sampler_results": {"episode_reward_max": 74.29769897460938, "episode_reward_min": -0.7725639343261719, "episode_reward_mean": 10.34332782466237, "episode_len_mean": 495.1544715447154, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.34332782466237, "rewards/0_min": -0.7725639343261719, "rewards/0_max": 74.29769897460938, "rewards/1_mean": 10.34332782466237, "rewards/1_min": -0.7725639343261719, "rewards/1_max": 74.29769897460938, "rewards/2_mean": 10.34332782466237, "rewards/2_min": -0.7725639343261719, "rewards/2_max": 74.29769897460938, "rewards/3_mean": 10.34332782466237, "rewards/3_min": -0.7725639343261719, "rewards/3_max": 74.29769897460938, "rewards/4_mean": 10.34332782466237, "rewards/4_min": -0.7725639343261719, "rewards/4_max": 74.29769897460938}, "hist_stats": {"episode_reward": [39.13803291320801, -0.37142181396484375, -0.2073516845703125, 0.0, 0.0, 0.0, 12.874526977539062, 0.0, 27.05829620361328, 0.033939361572265625, 0.0, 0.0, 7.5933837890625, 0.0, 0.0, 0.0465545654296875, 10.714759826660156, 6.991363525390625, 0.0, 0.0, 42.451852798461914, 0.0, 0.0, 0.0, 33.30506706237793, 0.0, 0.0, 0.0, 0.0, 68.02018737792969, 0.0, 0.0, 2.0972137451171875, 5.680450439453125, -0.206268310546875, -0.0426788330078125, 12.8670654296875, 0.0, 0.0, 0.0, 0.0, 25.594894409179688, 0.0, 0.0, 0.0, -0.04473876953125, 0.0, 0.0, 0.0, 0.0, 30.81249237060547, 0.0, 9.024261474609375, 37.50218200683594, 0.0, 0.0470428466796875, 48.53596878051758, 0.0544281005859375, 0.0, 0.0, -0.310760498046875, 0.28436279296875, 0.0, 24.858253479003906, 0.1313629150390625, 0.0, 35.88810729980469, 49.72846984863281, 40.20051956176758, 0.0, 0.23209762573242188, 0.5845947265625, 0.0, 0.0, 44.352346420288086, 9.410049438476562, 0.7244491577148438, -0.1150360107421875, 0.0, 74.29769897460938, 0.0, 0.0, 0.0, 52.07631301879883, 7.62939453125e-06, 0.3612937927246094, 64.7367172241211, 13.376556396484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.939777374267578, 29.618942260742188, -0.7725639343261719, 28.342063903808594, 56.887447357177734, 5.296253204345703, 0.0, 37.26695251464844, 8.172103881835938, 0.0, 30.94750213623047, 0.0431671142578125, 0.05458831787109375, 0.0, 0.0, 0.0, 63.55078125, 34.125823974609375, 58.052581787109375, 0.0080718994140625, 7.125923156738281, 0.0, 0.0, -0.061405181884765625, 31.289730072021484, 0.0, 0.0, 22.952672958374023, 0.0], "episode_lengths": [455, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 424, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 366, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 322, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 337, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.058389398818752, "mean_inference_ms": 3.0250778125970594, "mean_action_processing_ms": 4.4393220672247695, "mean_env_wait_ms": 6.942087349358116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 74.29769897460938, "episode_reward_min": -0.7725639343261719, "episode_reward_mean": 10.34332782466237, "episode_len_mean": 495.1544715447154, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [39.13803291320801, -0.37142181396484375, -0.2073516845703125, 0.0, 0.0, 0.0, 12.874526977539062, 0.0, 27.05829620361328, 0.033939361572265625, 0.0, 0.0, 7.5933837890625, 0.0, 0.0, 0.0465545654296875, 10.714759826660156, 6.991363525390625, 0.0, 0.0, 42.451852798461914, 0.0, 0.0, 0.0, 33.30506706237793, 0.0, 0.0, 0.0, 0.0, 68.02018737792969, 0.0, 0.0, 2.0972137451171875, 5.680450439453125, -0.206268310546875, -0.0426788330078125, 12.8670654296875, 0.0, 0.0, 0.0, 0.0, 25.594894409179688, 0.0, 0.0, 0.0, -0.04473876953125, 0.0, 0.0, 0.0, 0.0, 30.81249237060547, 0.0, 9.024261474609375, 37.50218200683594, 0.0, 0.0470428466796875, 48.53596878051758, 0.0544281005859375, 0.0, 0.0, -0.310760498046875, 0.28436279296875, 0.0, 24.858253479003906, 0.1313629150390625, 0.0, 35.88810729980469, 49.72846984863281, 40.20051956176758, 0.0, 0.23209762573242188, 0.5845947265625, 0.0, 0.0, 44.352346420288086, 9.410049438476562, 0.7244491577148438, -0.1150360107421875, 0.0, 74.29769897460938, 0.0, 0.0, 0.0, 52.07631301879883, 7.62939453125e-06, 0.3612937927246094, 64.7367172241211, 13.376556396484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.939777374267578, 29.618942260742188, -0.7725639343261719, 28.342063903808594, 56.887447357177734, 5.296253204345703, 0.0, 37.26695251464844, 8.172103881835938, 0.0, 30.94750213623047, 0.0431671142578125, 0.05458831787109375, 0.0, 0.0, 0.0, 63.55078125, 34.125823974609375, 58.052581787109375, 0.0080718994140625, 7.125923156738281, 0.0, 0.0, -0.061405181884765625, 31.289730072021484, 0.0, 0.0, 22.952672958374023, 0.0], "episode_lengths": [455, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 424, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 366, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 322, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 337, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.058389398818752, "mean_inference_ms": 3.0250778125970594, "mean_action_processing_ms": 4.4393220672247695, "mean_env_wait_ms": 6.942087349358116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23789004, "num_agent_steps_trained": 23789004, "num_env_steps_sampled": 23789004, "num_env_steps_trained": 23789004, "num_env_steps_sampled_this_iter": 60904, "num_env_steps_trained_this_iter": 60904, "timesteps_total": 23789004, "num_steps_trained_this_iter": 60904, "agent_timesteps_total": 23789004, "timers": {"training_iteration_time_ms": 34551.44, "load_time_ms": 41.667, "load_throughput": 1465021.206, "learn_time_ms": 19141.115, "learn_throughput": 3189.086, "synch_weights_time_ms": 5.808}, "counters": {"num_env_steps_sampled": 23789004, "num_env_steps_trained": 23789004, "num_agent_steps_sampled": 23789004, "num_agent_steps_trained": 23789004}, "done": false, "episodes_total": 48182, "training_iteration": 392, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-25-10", "timestamp": 1735115110, "time_this_iter_s": 31.801779747009277, "time_total_s": 12191.731919765472, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8C6E00>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B3910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 103.68044328689575, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 23.46, "ram_util_percent": 97.18666666666665}}
{"custom_metrics": {"rewards/0_mean": 11.100925678160133, "rewards/0_min": -0.378448486328125, "rewards/0_max": 70.83916473388672, "rewards/1_mean": 11.100925678160133, "rewards/1_min": -0.378448486328125, "rewards/1_max": 70.83916473388672, "rewards/2_mean": 11.100925678160133, "rewards/2_min": -0.378448486328125, "rewards/2_max": 70.83916473388672, "rewards/3_mean": 11.100925678160133, "rewards/3_min": -0.378448486328125, "rewards/3_max": 70.83916473388672, "rewards/4_mean": 11.100925678160133, "rewards/4_min": -0.378448486328125, "rewards/4_max": 70.83916473388672}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.08774853642616007, "policy_loss": -0.0017859307561247121, "vf_loss": 0.14325547116616416, "vf_explained_var": 0.9869819598538535, "kl": 0.011895476372557737, "entropy": 22.982029117099824, "entropy_coeff": 0.01, "grad_gnorm": 1.2391334183868907}, "model": {}, "num_grad_updates_lifetime": 2205.5, "diff_num_grad_updates_vs_sampler_policy": 2204.5}}, "num_env_steps_sampled": 23849839, "num_env_steps_trained": 23849839, "num_agent_steps_sampled": 23849839, "num_agent_steps_trained": 23849839}, "sampler_results": {"episode_reward_max": 70.83916473388672, "episode_reward_min": -0.378448486328125, "episode_reward_mean": 11.100925678160133, "episode_len_mean": 494.5934959349593, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 11.100925678160133, "rewards/0_min": -0.378448486328125, "rewards/0_max": 70.83916473388672, "rewards/1_mean": 11.100925678160133, "rewards/1_min": -0.378448486328125, "rewards/1_max": 70.83916473388672, "rewards/2_mean": 11.100925678160133, "rewards/2_min": -0.378448486328125, "rewards/2_max": 70.83916473388672, "rewards/3_mean": 11.100925678160133, "rewards/3_min": -0.378448486328125, "rewards/3_max": 70.83916473388672, "rewards/4_mean": 11.100925678160133, "rewards/4_min": -0.378448486328125, "rewards/4_max": 70.83916473388672}, "hist_stats": {"episode_reward": [0.4273681640625, 0.0, 0.0, 44.20158004760742, 31.574642181396484, 0.0568389892578125, -0.09186553955078125, 0.017757415771484375, 0.0, 0.0, 0.0, 51.858314514160156, 10.759788513183594, 0.0, 0.0, 0.02111053466796875, -0.378448486328125, 0.0, 0.0, 0.0098114013671875, 70.62518310546875, 0.28324127197265625, 3.7148876190185547, 44.25019836425781, 0.0, 0.0, 0.23669052124023438, 4.667686462402344, 0.0, 0.0, -0.13367080688476562, 0.0, 0.0, 0.0, -0.1832275390625, 23.639312744140625, 17.034988403320312, 0.0, 0.0, 0.0, 0.0, 50.94880676269531, 0.4493560791015625, 0.0, 0.0, -0.107574462890625, 0.2284393310546875, 0.0, 0.0, 25.013925552368164, 33.284217834472656, 33.79037284851074, 0.0, 0.0, 0.0, 0.0, 70.83916473388672, -0.0391082763671875, 13.392173767089844, 0.0, -0.171875, 60.01749038696289, 45.860931396484375, 32.0308837890625, 30.96563720703125, 0.0, 0.0, 0.0, 0.0, 0.5857696533203125, 0.0, 26.624610900878906, 55.410133361816406, 39.42648696899414, 0.0621490478515625, 0.0, 1.3078994750976562, 37.950782775878906, 0.0, 0.0, 14.256607055664062, 0.030548095703125, 0.0, 32.046630859375, 0.0, 23.568138122558594, 0.0, -0.0689697265625, -0.18906402587890625, 1.169525146484375, 5.254375457763672, 2.1501007080078125, 0.0, 51.914390563964844, 15.6788330078125, 28.85443878173828, 37.47602844238281, -0.35926055908203125, 0.0, 13.293746948242188, -0.29120635986328125, 0.0, 0.0, 51.54484558105469, 46.09381103515625, 0.0, 0.0, -0.02716064453125, 54.137332916259766, 5.9901885986328125, 0.0, 0.0, 0.16779327392578125, 66.14923095703125, 0.0, 0.32833099365234375, 10.011451721191406, 0.0, 46.025718688964844, -0.25540924072265625, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 312, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 320, 500, 445, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 258, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.084081869369268, "mean_inference_ms": 2.9375339734830357, "mean_action_processing_ms": 4.381246403482427, "mean_env_wait_ms": 6.883298488638351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 70.83916473388672, "episode_reward_min": -0.378448486328125, "episode_reward_mean": 11.100925678160133, "episode_len_mean": 494.5934959349593, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.4273681640625, 0.0, 0.0, 44.20158004760742, 31.574642181396484, 0.0568389892578125, -0.09186553955078125, 0.017757415771484375, 0.0, 0.0, 0.0, 51.858314514160156, 10.759788513183594, 0.0, 0.0, 0.02111053466796875, -0.378448486328125, 0.0, 0.0, 0.0098114013671875, 70.62518310546875, 0.28324127197265625, 3.7148876190185547, 44.25019836425781, 0.0, 0.0, 0.23669052124023438, 4.667686462402344, 0.0, 0.0, -0.13367080688476562, 0.0, 0.0, 0.0, -0.1832275390625, 23.639312744140625, 17.034988403320312, 0.0, 0.0, 0.0, 0.0, 50.94880676269531, 0.4493560791015625, 0.0, 0.0, -0.107574462890625, 0.2284393310546875, 0.0, 0.0, 25.013925552368164, 33.284217834472656, 33.79037284851074, 0.0, 0.0, 0.0, 0.0, 70.83916473388672, -0.0391082763671875, 13.392173767089844, 0.0, -0.171875, 60.01749038696289, 45.860931396484375, 32.0308837890625, 30.96563720703125, 0.0, 0.0, 0.0, 0.0, 0.5857696533203125, 0.0, 26.624610900878906, 55.410133361816406, 39.42648696899414, 0.0621490478515625, 0.0, 1.3078994750976562, 37.950782775878906, 0.0, 0.0, 14.256607055664062, 0.030548095703125, 0.0, 32.046630859375, 0.0, 23.568138122558594, 0.0, -0.0689697265625, -0.18906402587890625, 1.169525146484375, 5.254375457763672, 2.1501007080078125, 0.0, 51.914390563964844, 15.6788330078125, 28.85443878173828, 37.47602844238281, -0.35926055908203125, 0.0, 13.293746948242188, -0.29120635986328125, 0.0, 0.0, 51.54484558105469, 46.09381103515625, 0.0, 0.0, -0.02716064453125, 54.137332916259766, 5.9901885986328125, 0.0, 0.0, 0.16779327392578125, 66.14923095703125, 0.0, 0.32833099365234375, 10.011451721191406, 0.0, 46.025718688964844, -0.25540924072265625, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 312, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 320, 500, 445, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 258, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.084081869369268, "mean_inference_ms": 2.9375339734830357, "mean_action_processing_ms": 4.381246403482427, "mean_env_wait_ms": 6.883298488638351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23849839, "num_agent_steps_trained": 23849839, "num_env_steps_sampled": 23849839, "num_env_steps_trained": 23849839, "num_env_steps_sampled_this_iter": 60835, "num_env_steps_trained_this_iter": 60835, "timesteps_total": 23849839, "num_steps_trained_this_iter": 60835, "agent_timesteps_total": 23849839, "timers": {"training_iteration_time_ms": 33516.781, "load_time_ms": 43.532, "load_throughput": 1401070.445, "learn_time_ms": 19104.409, "learn_throughput": 3192.496, "synch_weights_time_ms": 4.356}, "counters": {"num_env_steps_sampled": 23849839, "num_env_steps_trained": 23849839, "num_agent_steps_sampled": 23849839, "num_agent_steps_trained": 23849839}, "done": false, "episodes_total": 48305, "training_iteration": 393, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-25-40", "timestamp": 1735115140, "time_this_iter_s": 30.412803649902344, "time_total_s": 12222.144723415375, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8ED5D0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B37F0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 134.0932469367981, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 21.744186046511626, "ram_util_percent": 97.18139534883721}}
{"custom_metrics": {"rewards/0_mean": 12.323256622314453, "rewards/0_min": -0.59564208984375, "rewards/0_max": 76.47708892822266, "rewards/1_mean": 12.323256622314453, "rewards/1_min": -0.59564208984375, "rewards/1_max": 76.47708892822266, "rewards/2_mean": 12.323256622314453, "rewards/2_min": -0.59564208984375, "rewards/2_max": 76.47708892822266, "rewards/3_mean": 12.323256622314453, "rewards/3_min": -0.59564208984375, "rewards/3_max": 76.47708892822266, "rewards/4_mean": 12.323256622314453, "rewards/4_min": -0.59564208984375, "rewards/4_max": 76.47708892822266}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.10577530233219029, "policy_loss": -0.005765769569691093, "vf_loss": 0.12558509381857538, "vf_explained_var": 0.9852033599028511, "kl": 0.013224886203302987, "entropy": 22.62641421424018, "entropy_coeff": 0.01, "grad_gnorm": 1.4608761822420453}, "model": {}, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 2834.5}}, "num_env_steps_sampled": 23911070, "num_env_steps_trained": 23911070, "num_agent_steps_sampled": 23911070, "num_agent_steps_trained": 23911070}, "sampler_results": {"episode_reward_max": 76.47708892822266, "episode_reward_min": -0.59564208984375, "episode_reward_mean": 12.323256622314453, "episode_len_mean": 489.848, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 12.323256622314453, "rewards/0_min": -0.59564208984375, "rewards/0_max": 76.47708892822266, "rewards/1_mean": 12.323256622314453, "rewards/1_min": -0.59564208984375, "rewards/1_max": 76.47708892822266, "rewards/2_mean": 12.323256622314453, "rewards/2_min": -0.59564208984375, "rewards/2_max": 76.47708892822266, "rewards/3_mean": 12.323256622314453, "rewards/3_min": -0.59564208984375, "rewards/3_max": 76.47708892822266, "rewards/4_mean": 12.323256622314453, "rewards/4_min": -0.59564208984375, "rewards/4_max": 76.47708892822266}, "hist_stats": {"episode_reward": [27.286170959472656, 0.0, -0.02593231201171875, 2.3431053161621094, 14.4312744140625, 0.0152435302734375, 61.074188232421875, 8.33477783203125, 0.0, 0.0, 0.0, 0.0, 1.8088264465332031, 0.11086273193359375, 0.0, 0.0, 1.9897918701171875, 0.0, 46.734161376953125, 16.74248504638672, 0.046993255615234375, 26.620288848876953, 66.4714241027832, 22.51502227783203, 0.1783599853515625, 0.17139434814453125, 32.79481506347656, 23.347671508789062, 0.0, -0.12155914306640625, 0.0, 0.0, 0.0, 64.96401977539062, 0.0, 0.1275787353515625, 0.04274749755859375, 0.0, 0.171295166015625, -0.1149749755859375, 16.042091369628906, 0.0, 0.0, 11.6435546875, 0.0, -0.144012451171875, 0.0, 23.826496124267578, 76.47708892822266, 6.282678604125977, 0.0, 25.79517936706543, 0.10482025146484375, 22.44631576538086, -0.3902015686035156, 69.02230834960938, -0.054538726806640625, 52.815277099609375, 0.0058917999267578125, 67.67480087280273, 0.0, 0.0, -0.21033477783203125, 0.0, 54.72030067443848, 0.0, 20.393230438232422, 3.503650665283203, -0.40374755859375, 0.0, 0.0, 0.0, 0.07625198364257812, 57.49616813659668, -0.59564208984375, 17.456634521484375, 19.579818725585938, 11.060043334960938, 11.463912963867188, 4.674934387207031, 6.833465576171875, 0.0, 24.91082763671875, 0.0, 0.0, 0.0, 0.0, 31.520732879638672, 3.604736328125, 33.355552673339844, 0.0, 0.0, 14.714340209960938, -0.3261260986328125, 57.25328063964844, 0.0, 10.928817749023438, 50.92041015625, 0.0, 0.1378936767578125, 48.80955696105957, 52.30701446533203, 0.0, 0.0, 6.564582824707031, -0.136505126953125, 0.0, 18.108062744140625, 45.301239013671875, 28.296844482421875, 0.0, 0.0, 48.425323486328125, 0.0, -0.007232666015625, 0.0, 0.0, 0.0, 54.42848205566406, -0.251220703125, 0.0, 14.7635498046875, 0.0, 1.1204452514648438, 0.0], "episode_lengths": [451, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 313, 442, 271, 500, 500, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 135, 500, 330, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.116826266129006, "mean_inference_ms": 2.9446755055484255, "mean_action_processing_ms": 4.329370549135514, "mean_env_wait_ms": 6.8871980167697835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 76.47708892822266, "episode_reward_min": -0.59564208984375, "episode_reward_mean": 12.323256622314453, "episode_len_mean": 489.848, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [27.286170959472656, 0.0, -0.02593231201171875, 2.3431053161621094, 14.4312744140625, 0.0152435302734375, 61.074188232421875, 8.33477783203125, 0.0, 0.0, 0.0, 0.0, 1.8088264465332031, 0.11086273193359375, 0.0, 0.0, 1.9897918701171875, 0.0, 46.734161376953125, 16.74248504638672, 0.046993255615234375, 26.620288848876953, 66.4714241027832, 22.51502227783203, 0.1783599853515625, 0.17139434814453125, 32.79481506347656, 23.347671508789062, 0.0, -0.12155914306640625, 0.0, 0.0, 0.0, 64.96401977539062, 0.0, 0.1275787353515625, 0.04274749755859375, 0.0, 0.171295166015625, -0.1149749755859375, 16.042091369628906, 0.0, 0.0, 11.6435546875, 0.0, -0.144012451171875, 0.0, 23.826496124267578, 76.47708892822266, 6.282678604125977, 0.0, 25.79517936706543, 0.10482025146484375, 22.44631576538086, -0.3902015686035156, 69.02230834960938, -0.054538726806640625, 52.815277099609375, 0.0058917999267578125, 67.67480087280273, 0.0, 0.0, -0.21033477783203125, 0.0, 54.72030067443848, 0.0, 20.393230438232422, 3.503650665283203, -0.40374755859375, 0.0, 0.0, 0.0, 0.07625198364257812, 57.49616813659668, -0.59564208984375, 17.456634521484375, 19.579818725585938, 11.060043334960938, 11.463912963867188, 4.674934387207031, 6.833465576171875, 0.0, 24.91082763671875, 0.0, 0.0, 0.0, 0.0, 31.520732879638672, 3.604736328125, 33.355552673339844, 0.0, 0.0, 14.714340209960938, -0.3261260986328125, 57.25328063964844, 0.0, 10.928817749023438, 50.92041015625, 0.0, 0.1378936767578125, 48.80955696105957, 52.30701446533203, 0.0, 0.0, 6.564582824707031, -0.136505126953125, 0.0, 18.108062744140625, 45.301239013671875, 28.296844482421875, 0.0, 0.0, 48.425323486328125, 0.0, -0.007232666015625, 0.0, 0.0, 0.0, 54.42848205566406, -0.251220703125, 0.0, 14.7635498046875, 0.0, 1.1204452514648438, 0.0], "episode_lengths": [451, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 313, 442, 271, 500, 500, 361, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 135, 500, 330, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 428, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.116826266129006, "mean_inference_ms": 2.9446755055484255, "mean_action_processing_ms": 4.329370549135514, "mean_env_wait_ms": 6.8871980167697835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23911070, "num_agent_steps_trained": 23911070, "num_env_steps_sampled": 23911070, "num_env_steps_trained": 23911070, "num_env_steps_sampled_this_iter": 61231, "num_env_steps_trained_this_iter": 61231, "timesteps_total": 23911070, "num_steps_trained_this_iter": 61231, "agent_timesteps_total": 23911070, "timers": {"training_iteration_time_ms": 33025.272, "load_time_ms": 45.294, "load_throughput": 1347607.734, "learn_time_ms": 19076.544, "learn_throughput": 3199.678, "synch_weights_time_ms": 5.492}, "counters": {"num_env_steps_sampled": 23911070, "num_env_steps_trained": 23911070, "num_agent_steps_sampled": 23911070, "num_agent_steps_trained": 23911070}, "done": false, "episodes_total": 48430, "training_iteration": 394, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-26-12", "timestamp": 1735115172, "time_this_iter_s": 31.06914973258972, "time_total_s": 12253.213873147964, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F930970>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F02D2D0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 165.16239666938782, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 22.654545454545456, "ram_util_percent": 96.9022727272727}}
{"evaluation": {"episode_reward_max": -0.185577392578125, "episode_reward_min": -0.185577392578125, "episode_reward_mean": -0.185577392578125, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": -0.185577392578125, "rewards/0_min": -0.185577392578125, "rewards/0_max": -0.185577392578125, "rewards/1_mean": -0.185577392578125, "rewards/1_min": -0.185577392578125, "rewards/1_max": -0.185577392578125, "rewards/2_mean": -0.185577392578125, "rewards/2_min": -0.185577392578125, "rewards/2_max": -0.185577392578125, "rewards/3_mean": -0.185577392578125, "rewards/3_min": -0.185577392578125, "rewards/3_max": -0.185577392578125, "rewards/4_mean": -0.185577392578125, "rewards/4_min": -0.185577392578125, "rewards/4_max": -0.185577392578125}, "hist_stats": {"episode_reward": [-0.185577392578125], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.38368670971362623, "mean_inference_ms": 2.0524135955444702, "mean_action_processing_ms": 0.2895837778097147, "mean_env_wait_ms": 3.223433718457446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 10.434059143066406, "rewards/0_min": -0.8049087524414062, "rewards/0_max": 84.81594467163086, "rewards/1_mean": 10.434059143066406, "rewards/1_min": -0.8049087524414062, "rewards/1_max": 84.81594467163086, "rewards/2_mean": 10.434059143066406, "rewards/2_min": -0.8049087524414062, "rewards/2_max": 84.81594467163086, "rewards/3_mean": 10.434059143066406, "rewards/3_min": -0.8049087524414062, "rewards/3_max": 84.81594467163086, "rewards/4_mean": 10.434059143066406, "rewards/4_min": -0.8049087524414062, "rewards/4_max": 84.81594467163086}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.13696939475184847, "policy_loss": 0.010279118861827946, "vf_loss": 0.08947668444838315, "vf_explained_var": 0.9816018273906102, "kl": 0.015878774975204752, "entropy": 23.75290674482073, "entropy_coeff": 0.01, "grad_gnorm": 1.5611020984630737}, "model": {}, "num_grad_updates_lifetime": 3465.5, "diff_num_grad_updates_vs_sampler_policy": 3464.5}}, "num_env_steps_sampled": 23972028, "num_env_steps_trained": 23972028, "num_agent_steps_sampled": 23972028, "num_agent_steps_trained": 23972028}, "sampler_results": {"episode_reward_max": 84.81594467163086, "episode_reward_min": -0.8049087524414062, "episode_reward_mean": 10.434059143066406, "episode_len_mean": 487.664, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.434059143066406, "rewards/0_min": -0.8049087524414062, "rewards/0_max": 84.81594467163086, "rewards/1_mean": 10.434059143066406, "rewards/1_min": -0.8049087524414062, "rewards/1_max": 84.81594467163086, "rewards/2_mean": 10.434059143066406, "rewards/2_min": -0.8049087524414062, "rewards/2_max": 84.81594467163086, "rewards/3_mean": 10.434059143066406, "rewards/3_min": -0.8049087524414062, "rewards/3_max": 84.81594467163086, "rewards/4_mean": 10.434059143066406, "rewards/4_min": -0.8049087524414062, "rewards/4_max": 84.81594467163086}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.743499755859375, 0.0, -0.10630416870117188, 2.087158203125, 0.0, 0.0, 0.00058746337890625, 1.0059814453125, 0.0, -0.42325592041015625, 0.0, 0.0, 0.0, 39.749656677246094, -0.45941162109375, 5.5643463134765625, 0.0, 0.0, 9.352388381958008, 8.054210662841797, 0.0, 37.195884704589844, 3.1355819702148438, 53.21054267883301, 0.0, 61.376220703125, 3.660675048828125, 57.39371871948242, 0.0, -0.2301177978515625, 0.0, 0.0, 11.725481033325195, -0.04831695556640625, -0.3457603454589844, 12.139320373535156, -0.2330780029296875, 24.38697052001953, 0.176116943359375, 1.2396926879882812, 0.0, -0.8049087524414062, 0.0, 49.90869140625, 19.703170776367188, 0.0, 0.0, -0.32047271728515625, -0.3103790283203125, 0.8003463745117188, 62.531551361083984, 21.883731842041016, 19.980079650878906, 0.0, 56.74287414550781, 0.0, 0.0, 0.0, 0.0, 18.481109619140625, 10.840694427490234, 0.0, 0.0, 11.238861083984375, 41.77943801879883, -0.17650604248046875, 0.0, 0.0, 11.2088623046875, 0.0, 18.38054847717285, 45.036376953125, -0.14128494262695312, 7.392120361328125, 43.2408561706543, 0.0, 0.0, 0.0, 74.93598937988281, 0.0, 0.191162109375, 0.0, 0.0, 0.0, 46.852691650390625, 18.509048461914062, 2.4404144287109375, 0.0, 51.23434829711914, 0.0, 0.0, 0.0, -0.38684844970703125, 53.55513000488281, 0.0, 0.0, 49.102996826171875, 7.6829833984375, 0.0, 0.0, -0.6308746337890625, -0.194793701171875, 0.0, 72.80904769897461, 0.14764404296875, 0.0, 0.0, 0.0, 5.1785430908203125, 3.104888916015625, 0.0, 0.39569854736328125, -0.207366943359375, 0.0, 0.008331298828125, 84.81594467163086, 0.1376190185546875, 7.842628479003906, 2.654247283935547, 45.647315979003906, 0.0, 0.0, 12.170051574707031], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 159, 392, 500, 389, 500, 433, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 460, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 225, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 149, 251, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.29601648643335, "mean_inference_ms": 2.9940147696198123, "mean_action_processing_ms": 4.351502514646933, "mean_env_wait_ms": 6.927570155901981, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 84.81594467163086, "episode_reward_min": -0.8049087524414062, "episode_reward_mean": 10.434059143066406, "episode_len_mean": 487.664, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.743499755859375, 0.0, -0.10630416870117188, 2.087158203125, 0.0, 0.0, 0.00058746337890625, 1.0059814453125, 0.0, -0.42325592041015625, 0.0, 0.0, 0.0, 39.749656677246094, -0.45941162109375, 5.5643463134765625, 0.0, 0.0, 9.352388381958008, 8.054210662841797, 0.0, 37.195884704589844, 3.1355819702148438, 53.21054267883301, 0.0, 61.376220703125, 3.660675048828125, 57.39371871948242, 0.0, -0.2301177978515625, 0.0, 0.0, 11.725481033325195, -0.04831695556640625, -0.3457603454589844, 12.139320373535156, -0.2330780029296875, 24.38697052001953, 0.176116943359375, 1.2396926879882812, 0.0, -0.8049087524414062, 0.0, 49.90869140625, 19.703170776367188, 0.0, 0.0, -0.32047271728515625, -0.3103790283203125, 0.8003463745117188, 62.531551361083984, 21.883731842041016, 19.980079650878906, 0.0, 56.74287414550781, 0.0, 0.0, 0.0, 0.0, 18.481109619140625, 10.840694427490234, 0.0, 0.0, 11.238861083984375, 41.77943801879883, -0.17650604248046875, 0.0, 0.0, 11.2088623046875, 0.0, 18.38054847717285, 45.036376953125, -0.14128494262695312, 7.392120361328125, 43.2408561706543, 0.0, 0.0, 0.0, 74.93598937988281, 0.0, 0.191162109375, 0.0, 0.0, 0.0, 46.852691650390625, 18.509048461914062, 2.4404144287109375, 0.0, 51.23434829711914, 0.0, 0.0, 0.0, -0.38684844970703125, 53.55513000488281, 0.0, 0.0, 49.102996826171875, 7.6829833984375, 0.0, 0.0, -0.6308746337890625, -0.194793701171875, 0.0, 72.80904769897461, 0.14764404296875, 0.0, 0.0, 0.0, 5.1785430908203125, 3.104888916015625, 0.0, 0.39569854736328125, -0.207366943359375, 0.0, 0.008331298828125, 84.81594467163086, 0.1376190185546875, 7.842628479003906, 2.654247283935547, 45.647315979003906, 0.0, 0.0, 12.170051574707031], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 159, 392, 500, 389, 500, 433, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 460, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 225, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 149, 251, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.29601648643335, "mean_inference_ms": 2.9940147696198123, "mean_action_processing_ms": 4.351502514646933, "mean_env_wait_ms": 6.927570155901981, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23972028, "num_agent_steps_trained": 23972028, "num_env_steps_sampled": 23972028, "num_env_steps_trained": 23972028, "num_env_steps_sampled_this_iter": 60958, "num_env_steps_trained_this_iter": 60958, "timesteps_total": 23972028, "num_steps_trained_this_iter": 60958, "agent_timesteps_total": 23972028, "timers": {"training_iteration_time_ms": 32824.271, "load_time_ms": 47.24, "load_throughput": 1291820.851, "learn_time_ms": 19115.3, "learn_throughput": 3192.486, "synch_weights_time_ms": 4.576}, "counters": {"num_env_steps_sampled": 23972028, "num_env_steps_trained": 23972028, "num_agent_steps_sampled": 23972028, "num_agent_steps_trained": 23972028}, "done": false, "episodes_total": 48555, "training_iteration": 395, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-26-44", "timestamp": 1735115204, "time_this_iter_s": 31.829265832901, "time_total_s": 12285.043138980865, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8EE950>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B3640>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 196.99166250228882, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 27.393333333333334, "ram_util_percent": 97.05333333333334}}
{"custom_metrics": {"rewards/0_mean": 7.784547884602192, "rewards/0_min": -0.74884033203125, "rewards/0_max": 80.30733489990234, "rewards/1_mean": 7.784547884602192, "rewards/1_min": -0.74884033203125, "rewards/1_max": 80.30733489990234, "rewards/2_mean": 7.784547884602192, "rewards/2_min": -0.74884033203125, "rewards/2_max": 80.30733489990234, "rewards/3_mean": 7.784547884602192, "rewards/3_min": -0.74884033203125, "rewards/3_max": 80.30733489990234, "rewards/4_mean": 7.784547884602192, "rewards/4_min": -0.74884033203125, "rewards/4_max": 80.30733489990234}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.17374248446255464, "policy_loss": 0.0008543478576318612, "vf_loss": 0.0787909501498299, "vf_explained_var": 0.986889583250833, "kl": 0.014285497354816587, "entropy": 25.4110991493104, "entropy_coeff": 0.01, "grad_gnorm": 0.8065080101527865}, "model": {}, "num_grad_updates_lifetime": 4095.5, "diff_num_grad_updates_vs_sampler_policy": 4094.5}}, "num_env_steps_sampled": 24032320, "num_env_steps_trained": 24032320, "num_agent_steps_sampled": 24032320, "num_agent_steps_trained": 24032320}, "sampler_results": {"episode_reward_max": 80.30733489990234, "episode_reward_min": -0.74884033203125, "episode_reward_mean": 7.784547884602192, "episode_len_mean": 498.2809917355372, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.784547884602192, "rewards/0_min": -0.74884033203125, "rewards/0_max": 80.30733489990234, "rewards/1_mean": 7.784547884602192, "rewards/1_min": -0.74884033203125, "rewards/1_max": 80.30733489990234, "rewards/2_mean": 7.784547884602192, "rewards/2_min": -0.74884033203125, "rewards/2_max": 80.30733489990234, "rewards/3_mean": 7.784547884602192, "rewards/3_min": -0.74884033203125, "rewards/3_max": 80.30733489990234, "rewards/4_mean": 7.784547884602192, "rewards/4_min": -0.74884033203125, "rewards/4_max": 80.30733489990234}, "hist_stats": {"episode_reward": [0.0, 0.0, 9.790870666503906, 14.523239135742188, 0.0, 0.0, 9.591438293457031, -0.74884033203125, 0.0, 25.581695556640625, 0.1434478759765625, 0.0, 28.07171630859375, 0.0, 0.0, 0.0, 0.0, 80.30733489990234, 1.8693389892578125, 0.0, 20.541976928710938, 0.4837493896484375, 0.0, 0.0, 0.0, -0.3185577392578125, 0.0, -0.32932281494140625, 40.296024322509766, 0.0, 0.0, 31.337234497070312, 0.0, 0.0, 0.0, 36.930973052978516, -0.11534881591796875, 19.152908325195312, 3.601287841796875, 0.0, 0.0, 16.279922485351562, 0.154327392578125, 0.0, 0.0, -0.239654541015625, 0.0, 7.722747802734375, 0.2187957763671875, 0.0, -0.234588623046875, 26.182815551757812, 0.0, 9.393178939819336, 0.0, 15.889030456542969, 0.0, 0.0, 15.621971130371094, 0.0, 0.0, 5.288970947265625, 0.8747444152832031, 36.91922187805176, -0.21891021728515625, 0.0, 55.75682830810547, 0.0359039306640625, 0.0, 0.0, 0.41699981689453125, 37.45025634765625, 3.570648193359375, 0.0, 34.402320861816406, 0.0, 0.0, 0.0, 30.70654296875, 0.0, 0.0, 0.0, -0.1921234130859375, 0.0, 0.0, 0.0, 0.0, 26.79174041748047, 0.0, 0.0, 0.12953948974609375, 0.0, 4.458595275878906, 2.005107879638672, 10.495830535888672, 0.0, 9.750473022460938, 0.0, 0.0, 24.24072265625, 0.0, 0.0, 0.0, -0.02422332763671875, 0.0, 65.08885955810547, 0.8145980834960938, 0.0, 0.0, 0.0, 0.0, 0.0, 45.83598327636719, -0.056121826171875, 5.330291748046875, 22.520050048828125, 44.489288330078125, 0.0, 0.2002105712890625, 0.0, 63.148231506347656], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 292, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.382809471004663, "mean_inference_ms": 3.0357175213176606, "mean_action_processing_ms": 4.2987996967377935, "mean_env_wait_ms": 6.904798277029129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 80.30733489990234, "episode_reward_min": -0.74884033203125, "episode_reward_mean": 7.784547884602192, "episode_len_mean": 498.2809917355372, "episodes_this_iter": 121, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 9.790870666503906, 14.523239135742188, 0.0, 0.0, 9.591438293457031, -0.74884033203125, 0.0, 25.581695556640625, 0.1434478759765625, 0.0, 28.07171630859375, 0.0, 0.0, 0.0, 0.0, 80.30733489990234, 1.8693389892578125, 0.0, 20.541976928710938, 0.4837493896484375, 0.0, 0.0, 0.0, -0.3185577392578125, 0.0, -0.32932281494140625, 40.296024322509766, 0.0, 0.0, 31.337234497070312, 0.0, 0.0, 0.0, 36.930973052978516, -0.11534881591796875, 19.152908325195312, 3.601287841796875, 0.0, 0.0, 16.279922485351562, 0.154327392578125, 0.0, 0.0, -0.239654541015625, 0.0, 7.722747802734375, 0.2187957763671875, 0.0, -0.234588623046875, 26.182815551757812, 0.0, 9.393178939819336, 0.0, 15.889030456542969, 0.0, 0.0, 15.621971130371094, 0.0, 0.0, 5.288970947265625, 0.8747444152832031, 36.91922187805176, -0.21891021728515625, 0.0, 55.75682830810547, 0.0359039306640625, 0.0, 0.0, 0.41699981689453125, 37.45025634765625, 3.570648193359375, 0.0, 34.402320861816406, 0.0, 0.0, 0.0, 30.70654296875, 0.0, 0.0, 0.0, -0.1921234130859375, 0.0, 0.0, 0.0, 0.0, 26.79174041748047, 0.0, 0.0, 0.12953948974609375, 0.0, 4.458595275878906, 2.005107879638672, 10.495830535888672, 0.0, 9.750473022460938, 0.0, 0.0, 24.24072265625, 0.0, 0.0, 0.0, -0.02422332763671875, 0.0, 65.08885955810547, 0.8145980834960938, 0.0, 0.0, 0.0, 0.0, 0.0, 45.83598327636719, -0.056121826171875, 5.330291748046875, 22.520050048828125, 44.489288330078125, 0.0, 0.2002105712890625, 0.0, 63.148231506347656], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 292, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.382809471004663, "mean_inference_ms": 3.0357175213176606, "mean_action_processing_ms": 4.2987996967377935, "mean_env_wait_ms": 6.904798277029129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24032320, "num_agent_steps_trained": 24032320, "num_env_steps_sampled": 24032320, "num_env_steps_trained": 24032320, "num_env_steps_sampled_this_iter": 60292, "num_env_steps_trained_this_iter": 60292, "timesteps_total": 24032320, "num_steps_trained_this_iter": 60292, "agent_timesteps_total": 24032320, "timers": {"training_iteration_time_ms": 32578.102, "load_time_ms": 49.092, "load_throughput": 1240959.428, "learn_time_ms": 19137.701, "learn_throughput": 3183.275, "synch_weights_time_ms": 3.923}, "counters": {"num_env_steps_sampled": 24032320, "num_env_steps_trained": 24032320, "num_agent_steps_sampled": 24032320, "num_agent_steps_trained": 24032320}, "done": false, "episodes_total": 48676, "training_iteration": 396, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-27-15", "timestamp": 1735115235, "time_this_iter_s": 31.11108708381653, "time_total_s": 12316.154226064682, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F931450>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F8575B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 228.10274958610535, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 24.54090909090909, "ram_util_percent": 97.74999999999999}}
{"custom_metrics": {"rewards/0_mean": 10.529056783582343, "rewards/0_min": -1.003387451171875, "rewards/0_max": 82.54278564453125, "rewards/1_mean": 10.529056783582343, "rewards/1_min": -1.003387451171875, "rewards/1_max": 82.54278564453125, "rewards/2_mean": 10.529056783582343, "rewards/2_min": -1.003387451171875, "rewards/2_max": 82.54278564453125, "rewards/3_mean": 10.529056783582343, "rewards/3_min": -1.003387451171875, "rewards/3_max": 82.54278564453125, "rewards/4_mean": 10.529056783582343, "rewards/4_min": -1.003387451171875, "rewards/4_max": 82.54278564453125}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.09927856462105872, "policy_loss": 0.0042988868928447, "vf_loss": 0.15212823005674023, "vf_explained_var": 0.9781302829583486, "kl": 0.014054547066962908, "entropy": 25.64171981206016, "entropy_coeff": 0.01, "grad_gnorm": 1.6427223424235033}, "model": {}, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 4724.5}}, "num_env_steps_sampled": 24093050, "num_env_steps_trained": 24093050, "num_agent_steps_sampled": 24093050, "num_agent_steps_trained": 24093050}, "sampler_results": {"episode_reward_max": 82.54278564453125, "episode_reward_min": -1.003387451171875, "episode_reward_mean": 10.529056783582343, "episode_len_mean": 497.78688524590166, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.529056783582343, "rewards/0_min": -1.003387451171875, "rewards/0_max": 82.54278564453125, "rewards/1_mean": 10.529056783582343, "rewards/1_min": -1.003387451171875, "rewards/1_max": 82.54278564453125, "rewards/2_mean": 10.529056783582343, "rewards/2_min": -1.003387451171875, "rewards/2_max": 82.54278564453125, "rewards/3_mean": 10.529056783582343, "rewards/3_min": -1.003387451171875, "rewards/3_max": 82.54278564453125, "rewards/4_mean": 10.529056783582343, "rewards/4_min": -1.003387451171875, "rewards/4_max": 82.54278564453125}, "hist_stats": {"episode_reward": [5.172206878662109, 0.0, -0.2603912353515625, -0.2624053955078125, 0.0, 8.913322448730469, 0.0, 73.68335342407227, 25.557037353515625, 0.0, 0.22957611083984375, 0.0, 40.093360900878906, 0.0, 7.5475006103515625, 0.0, -0.1015472412109375, 0.0, 66.15178680419922, 0.0, 0.0, 2.486083984375, 0.0, 0.0, 6.7902374267578125, 0.0, 0.0, 15.987480163574219, 0.0, -0.4987030029296875, 0.0, 0.4540996551513672, 0.0, -0.24401092529296875, 0.0, 0.1265411376953125, -0.0431976318359375, -1.003387451171875, 0.39347076416015625, 0.0, 0.0, 19.668502807617188, 0.2729339599609375, 46.715576171875, -0.098846435546875, 0.0, 0.0, 0.0, 40.29030799865723, 42.14159393310547, 0.0, 0.0, 0.0, 0.05748748779296875, -0.123077392578125, 18.663719177246094, 0.0, -0.174224853515625, 7.792633056640625, 0.0, 0.19003677368164062, 0.0, -0.26030731201171875, -0.40129852294921875, 0.41263580322265625, 0.0, 68.08204650878906, 0.0, 0.03447723388671875, -0.04974365234375, -0.6255874633789062, 0.0, 0.11522674560546875, 42.418067932128906, 0.15645599365234375, 0.0, 1.3589630126953125, 68.91693878173828, 0.0, 0.18236541748046875, 4.203346252441406, 0.0, 28.007308959960938, 40.268001556396484, 0.0, 0.0, 0.0, 0.13626861572265625, 0.0, 0.0, 21.006778717041016, -0.19589996337890625, 0.0, 11.795242309570312, 0.2091522216796875, 0.0, 55.41432189941406, 0.0, 0.0, 78.63239288330078, 51.225502014160156, 28.87525177001953, 0.0, -0.8565521240234375, 7.310205459594727, 80.56512451171875, 0.0, 0.0, -0.11083984375, 0.0, 82.54278564453125, -0.5610198974609375, 0.0442962646484375, 0.0, 71.56877136230469, 0.0, 56.66466522216797, 0.497283935546875, 0.0, -0.2252349853515625, 57.797889709472656, 2.820587158203125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 342, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.377450173251763, "mean_inference_ms": 3.0592388181393595, "mean_action_processing_ms": 4.285527233082134, "mean_env_wait_ms": 6.911118355785863, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 82.54278564453125, "episode_reward_min": -1.003387451171875, "episode_reward_mean": 10.529056783582343, "episode_len_mean": 497.78688524590166, "episodes_this_iter": 122, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [5.172206878662109, 0.0, -0.2603912353515625, -0.2624053955078125, 0.0, 8.913322448730469, 0.0, 73.68335342407227, 25.557037353515625, 0.0, 0.22957611083984375, 0.0, 40.093360900878906, 0.0, 7.5475006103515625, 0.0, -0.1015472412109375, 0.0, 66.15178680419922, 0.0, 0.0, 2.486083984375, 0.0, 0.0, 6.7902374267578125, 0.0, 0.0, 15.987480163574219, 0.0, -0.4987030029296875, 0.0, 0.4540996551513672, 0.0, -0.24401092529296875, 0.0, 0.1265411376953125, -0.0431976318359375, -1.003387451171875, 0.39347076416015625, 0.0, 0.0, 19.668502807617188, 0.2729339599609375, 46.715576171875, -0.098846435546875, 0.0, 0.0, 0.0, 40.29030799865723, 42.14159393310547, 0.0, 0.0, 0.0, 0.05748748779296875, -0.123077392578125, 18.663719177246094, 0.0, -0.174224853515625, 7.792633056640625, 0.0, 0.19003677368164062, 0.0, -0.26030731201171875, -0.40129852294921875, 0.41263580322265625, 0.0, 68.08204650878906, 0.0, 0.03447723388671875, -0.04974365234375, -0.6255874633789062, 0.0, 0.11522674560546875, 42.418067932128906, 0.15645599365234375, 0.0, 1.3589630126953125, 68.91693878173828, 0.0, 0.18236541748046875, 4.203346252441406, 0.0, 28.007308959960938, 40.268001556396484, 0.0, 0.0, 0.0, 0.13626861572265625, 0.0, 0.0, 21.006778717041016, -0.19589996337890625, 0.0, 11.795242309570312, 0.2091522216796875, 0.0, 55.41432189941406, 0.0, 0.0, 78.63239288330078, 51.225502014160156, 28.87525177001953, 0.0, -0.8565521240234375, 7.310205459594727, 80.56512451171875, 0.0, 0.0, -0.11083984375, 0.0, 82.54278564453125, -0.5610198974609375, 0.0442962646484375, 0.0, 71.56877136230469, 0.0, 56.66466522216797, 0.497283935546875, 0.0, -0.2252349853515625, 57.797889709472656, 2.820587158203125], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 342, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 388, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.377450173251763, "mean_inference_ms": 3.0592388181393595, "mean_action_processing_ms": 4.285527233082134, "mean_env_wait_ms": 6.911118355785863, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24093050, "num_agent_steps_trained": 24093050, "num_env_steps_sampled": 24093050, "num_env_steps_trained": 24093050, "num_env_steps_sampled_this_iter": 60730, "num_env_steps_trained_this_iter": 60730, "timesteps_total": 24093050, "num_steps_trained_this_iter": 60730, "agent_timesteps_total": 24093050, "timers": {"training_iteration_time_ms": 32357.399, "load_time_ms": 48.815, "load_throughput": 1247511.886, "learn_time_ms": 19103.875, "learn_throughput": 3187.665, "synch_weights_time_ms": 3.432}, "counters": {"num_env_steps_sampled": 24093050, "num_env_steps_trained": 24093050, "num_agent_steps_sampled": 24093050, "num_agent_steps_trained": 24093050}, "done": false, "episodes_total": 48798, "training_iteration": 397, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-27-46", "timestamp": 1735115266, "time_this_iter_s": 30.81248188018799, "time_total_s": 12346.96670794487, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F8EEDD0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B35B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 258.91523146629333, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 23.82558139534884, "ram_util_percent": 97.53720930232559}}
{"custom_metrics": {"rewards/0_mean": 7.797250111897786, "rewards/0_min": -0.7726593017578125, "rewards/0_max": 72.38419342041016, "rewards/1_mean": 7.797250111897786, "rewards/1_min": -0.7726593017578125, "rewards/1_max": 72.38419342041016, "rewards/2_mean": 7.797250111897786, "rewards/2_min": -0.7726593017578125, "rewards/2_max": 72.38419342041016, "rewards/3_mean": 7.797250111897786, "rewards/3_min": -0.7726593017578125, "rewards/3_max": 72.38419342041016, "rewards/4_mean": 7.797250111897786, "rewards/4_min": -0.7726593017578125, "rewards/4_max": 72.38419342041016}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.17038516758955896, "policy_loss": 0.000298664163768528, "vf_loss": 0.08595450162251908, "vf_explained_var": 0.9811238537705134, "kl": 0.011655950419131726, "entropy": 25.7228422164917, "entropy_coeff": 0.01, "grad_gnorm": 1.1083691531230533}, "model": {}, "num_grad_updates_lifetime": 5355.5, "diff_num_grad_updates_vs_sampler_policy": 5354.5}}, "num_env_steps_sampled": 24153671, "num_env_steps_trained": 24153671, "num_agent_steps_sampled": 24153671, "num_agent_steps_trained": 24153671}, "sampler_results": {"episode_reward_max": 72.38419342041016, "episode_reward_min": -0.7726593017578125, "episode_reward_mean": 7.797250111897786, "episode_len_mean": 492.8536585365854, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 7.797250111897786, "rewards/0_min": -0.7726593017578125, "rewards/0_max": 72.38419342041016, "rewards/1_mean": 7.797250111897786, "rewards/1_min": -0.7726593017578125, "rewards/1_max": 72.38419342041016, "rewards/2_mean": 7.797250111897786, "rewards/2_min": -0.7726593017578125, "rewards/2_max": 72.38419342041016, "rewards/3_mean": 7.797250111897786, "rewards/3_min": -0.7726593017578125, "rewards/3_max": 72.38419342041016, "rewards/4_mean": 7.797250111897786, "rewards/4_min": -0.7726593017578125, "rewards/4_max": 72.38419342041016}, "hist_stats": {"episode_reward": [0.0, 65.31454467773438, -0.3998260498046875, 0.0, 0.0, 0.0, 0.0, 12.1143798828125, 0.0, 12.035593032836914, 19.70801544189453, 0.0, 0.2726783752441406, -0.7726593017578125, 0.0, 0.0, -0.5306549072265625, 0.0, 35.38306427001953, 2.22314453125, 0.0, 26.97645378112793, 11.96834945678711, 19.781158447265625, 0.0, 0.0, 0.0, 0.0, 31.039230346679688, 0.0, 0.0, 4.5388031005859375, 0.0, 3.0134201049804688, 0.0, 0.306884765625, 0.0, 12.775753021240234, 18.892250061035156, 11.90304946899414, 19.106929779052734, 20.293548583984375, -0.1468658447265625, 0.0, 0.0, 0.0, -0.2574005126953125, 0.0, -0.0940399169921875, 0.1602630615234375, 0.22149658203125, 0.0, 0.0, 0.6822586059570312, 0.0, -0.69622802734375, 0.0, 0.40416717529296875, 0.0, 0.0, 0.0, 0.0, 0.05001068115234375, -0.06610870361328125, 56.15583038330078, 0.0, 0.29901885986328125, -0.2166595458984375, 0.0, 0.0, 17.246789932250977, 0.0, 0.0, 43.55251502990723, 0.0, 25.59918975830078, 0.0, 0.0, -0.022735595703125, 37.61174011230469, 72.38419342041016, 2.1407318115234375, 0.0, 0.0, 0.0, 0.0, 3.8814544677734375, 21.942062377929688, 0.0, 0.0, 23.804039001464844, 0.0, 0.0, 40.72654724121094, -0.09210205078125, 19.779136657714844, 0.000652313232421875, 47.099884033203125, 0.0, 52.98966979980469, 0.0, 14.805839538574219, 0.0, 0.0, 0.3711967468261719, 0.0, 17.617149353027344, 0.0, 0.0, 0.0, 0.0, 0.0, -0.21903610229492188, 0.0, 0.0, 8.296272277832031, 0.0, 2.2222557067871094, 39.648189544677734, 0.0, 70.3428726196289, 14.893402099609375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 325, 336, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 289, 500, 500, 326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 345, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.396780822469907, "mean_inference_ms": 3.0409094594663553, "mean_action_processing_ms": 4.238741689886609, "mean_env_wait_ms": 6.849518240159185, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 72.38419342041016, "episode_reward_min": -0.7726593017578125, "episode_reward_mean": 7.797250111897786, "episode_len_mean": 492.8536585365854, "episodes_this_iter": 123, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 65.31454467773438, -0.3998260498046875, 0.0, 0.0, 0.0, 0.0, 12.1143798828125, 0.0, 12.035593032836914, 19.70801544189453, 0.0, 0.2726783752441406, -0.7726593017578125, 0.0, 0.0, -0.5306549072265625, 0.0, 35.38306427001953, 2.22314453125, 0.0, 26.97645378112793, 11.96834945678711, 19.781158447265625, 0.0, 0.0, 0.0, 0.0, 31.039230346679688, 0.0, 0.0, 4.5388031005859375, 0.0, 3.0134201049804688, 0.0, 0.306884765625, 0.0, 12.775753021240234, 18.892250061035156, 11.90304946899414, 19.106929779052734, 20.293548583984375, -0.1468658447265625, 0.0, 0.0, 0.0, -0.2574005126953125, 0.0, -0.0940399169921875, 0.1602630615234375, 0.22149658203125, 0.0, 0.0, 0.6822586059570312, 0.0, -0.69622802734375, 0.0, 0.40416717529296875, 0.0, 0.0, 0.0, 0.0, 0.05001068115234375, -0.06610870361328125, 56.15583038330078, 0.0, 0.29901885986328125, -0.2166595458984375, 0.0, 0.0, 17.246789932250977, 0.0, 0.0, 43.55251502990723, 0.0, 25.59918975830078, 0.0, 0.0, -0.022735595703125, 37.61174011230469, 72.38419342041016, 2.1407318115234375, 0.0, 0.0, 0.0, 0.0, 3.8814544677734375, 21.942062377929688, 0.0, 0.0, 23.804039001464844, 0.0, 0.0, 40.72654724121094, -0.09210205078125, 19.779136657714844, 0.000652313232421875, 47.099884033203125, 0.0, 52.98966979980469, 0.0, 14.805839538574219, 0.0, 0.0, 0.3711967468261719, 0.0, 17.617149353027344, 0.0, 0.0, 0.0, 0.0, 0.0, -0.21903610229492188, 0.0, 0.0, 8.296272277832031, 0.0, 2.2222557067871094, 39.648189544677734, 0.0, 70.3428726196289, 14.893402099609375, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 325, 336, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 289, 500, 500, 326, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 345, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.396780822469907, "mean_inference_ms": 3.0409094594663553, "mean_action_processing_ms": 4.238741689886609, "mean_env_wait_ms": 6.849518240159185, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24153671, "num_agent_steps_trained": 24153671, "num_env_steps_sampled": 24153671, "num_env_steps_trained": 24153671, "num_env_steps_sampled_this_iter": 60621, "num_env_steps_trained_this_iter": 60621, "timesteps_total": 24153671, "num_steps_trained_this_iter": 60621, "agent_timesteps_total": 24153671, "timers": {"training_iteration_time_ms": 32126.31, "load_time_ms": 48.606, "load_throughput": 1252235.928, "learn_time_ms": 19100.449, "learn_throughput": 3186.633, "synch_weights_time_ms": 4.162}, "counters": {"num_env_steps_sampled": 24153671, "num_env_steps_trained": 24153671, "num_agent_steps_sampled": 24153671, "num_agent_steps_trained": 24153671}, "done": false, "episodes_total": 48921, "training_iteration": 398, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-28-16", "timestamp": 1735115296, "time_this_iter_s": 30.287596940994263, "time_total_s": 12377.254304885864, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F932860>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B3640>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 289.2028284072876, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 21.53953488372093, "ram_util_percent": 96.96976744186048}}
{"custom_metrics": {"rewards/0_mean": 10.235183485092655, "rewards/0_min": -0.52349853515625, "rewards/0_max": 90.80801200866699, "rewards/1_mean": 10.235183485092655, "rewards/1_min": -0.52349853515625, "rewards/1_max": 90.80801200866699, "rewards/2_mean": 10.235183485092655, "rewards/2_min": -0.52349853515625, "rewards/2_max": 90.80801200866699, "rewards/3_mean": 10.235183485092655, "rewards/3_min": -0.52349853515625, "rewards/3_max": 90.80801200866699, "rewards/4_mean": 10.235183485092655, "rewards/4_min": -0.52349853515625, "rewards/4_max": 90.80801200866699}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.05062500000000002, "cur_lr": 0.0001, "total_loss": -0.12207049685096116, "policy_loss": 0.0004912090557650478, "vf_loss": 0.1304179457341513, "vf_explained_var": 0.98982695473565, "kl": 0.01365395199197034, "entropy": 25.36708872658866, "entropy_coeff": 0.01, "grad_gnorm": 1.6527975325073514}, "model": {}, "num_grad_updates_lifetime": 5985.5, "diff_num_grad_updates_vs_sampler_policy": 5984.5}}, "num_env_steps_sampled": 24214930, "num_env_steps_trained": 24214930, "num_agent_steps_sampled": 24214930, "num_agent_steps_trained": 24214930}, "sampler_results": {"episode_reward_max": 90.80801200866699, "episode_reward_min": -0.52349853515625, "episode_reward_mean": 10.235183485092655, "episode_len_mean": 494.0241935483871, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 10.235183485092655, "rewards/0_min": -0.52349853515625, "rewards/0_max": 90.80801200866699, "rewards/1_mean": 10.235183485092655, "rewards/1_min": -0.52349853515625, "rewards/1_max": 90.80801200866699, "rewards/2_mean": 10.235183485092655, "rewards/2_min": -0.52349853515625, "rewards/2_max": 90.80801200866699, "rewards/3_mean": 10.235183485092655, "rewards/3_min": -0.52349853515625, "rewards/3_max": 90.80801200866699, "rewards/4_mean": 10.235183485092655, "rewards/4_min": -0.52349853515625, "rewards/4_max": 90.80801200866699}, "hist_stats": {"episode_reward": [0.0, -0.09263992309570312, 0.0, 6.4615020751953125, 66.69942474365234, 0.6262741088867188, 0.3784141540527344, 35.36529541015625, 29.10314178466797, -0.52349853515625, 0.0, -0.2225799560546875, 0.0, 61.973846435546875, 0.0, 30.571014404296875, 0.10670089721679688, 0.0, 70.70089721679688, 24.922971725463867, 37.286617279052734, 0.0, -0.09009552001953125, 45.11463165283203, 0.0, 0.33514404296875, 0.1468505859375, 90.80801200866699, 0.0, 0.4325103759765625, 0.0, 0.0, 0.0, -0.19964599609375, 0.0, 0.1869659423828125, 35.38151931762695, 0.0, 0.0, 39.387664794921875, 10.545860290527344, 0.0, -0.0527496337890625, 5.0259552001953125, 0.0, 0.0, 0.0, 24.0179443359375, 0.0, 45.34730529785156, 40.50901985168457, 0.0, 0.5505905151367188, 0.0, 0.29175567626953125, -0.3179168701171875, 0.0, 4.717243194580078, -0.07172393798828125, 0.0, 0.0, 44.970611572265625, 0.0, 1.8019332885742188, 3.670917510986328, -0.39588165283203125, 35.73139953613281, 10.030952453613281, 0.0, 0.0, 0.0, 0.16436767578125, 0.0, 0.0, 16.456253051757812, 1.4497528076171875, 21.010656356811523, 0.0, -0.22129058837890625, 0.0, 74.04371643066406, 0.2555389404296875, 0.21390533447265625, -0.015262603759765625, 0.06891632080078125, 7.684711456298828, 0.3098945617675781, 0.07754898071289062, 0.0, 0.138885498046875, 35.95362091064453, 0.0, 44.46043395996094, 7.300010681152344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.343158721923828, 0.0, 15.665695190429688, 0.0, 0.0, 0.08678436279296875, 0.0, 0.0, 84.04475212097168, 0.0, 36.568214416503906, 46.96887969970703, 20.807518005371094, 8.911697387695312, 0.0, 42.26573944091797, -0.135101318359375, 0.006866455078125, 0.0, 0.04273223876953125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 401, 353, 500, 500, 331, 500, 500, 500, 466, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.425015283687975, "mean_inference_ms": 3.0264335370887796, "mean_action_processing_ms": 4.192082519512135, "mean_env_wait_ms": 6.818515093028089, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 90.80801200866699, "episode_reward_min": -0.52349853515625, "episode_reward_mean": 10.235183485092655, "episode_len_mean": 494.0241935483871, "episodes_this_iter": 124, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, -0.09263992309570312, 0.0, 6.4615020751953125, 66.69942474365234, 0.6262741088867188, 0.3784141540527344, 35.36529541015625, 29.10314178466797, -0.52349853515625, 0.0, -0.2225799560546875, 0.0, 61.973846435546875, 0.0, 30.571014404296875, 0.10670089721679688, 0.0, 70.70089721679688, 24.922971725463867, 37.286617279052734, 0.0, -0.09009552001953125, 45.11463165283203, 0.0, 0.33514404296875, 0.1468505859375, 90.80801200866699, 0.0, 0.4325103759765625, 0.0, 0.0, 0.0, -0.19964599609375, 0.0, 0.1869659423828125, 35.38151931762695, 0.0, 0.0, 39.387664794921875, 10.545860290527344, 0.0, -0.0527496337890625, 5.0259552001953125, 0.0, 0.0, 0.0, 24.0179443359375, 0.0, 45.34730529785156, 40.50901985168457, 0.0, 0.5505905151367188, 0.0, 0.29175567626953125, -0.3179168701171875, 0.0, 4.717243194580078, -0.07172393798828125, 0.0, 0.0, 44.970611572265625, 0.0, 1.8019332885742188, 3.670917510986328, -0.39588165283203125, 35.73139953613281, 10.030952453613281, 0.0, 0.0, 0.0, 0.16436767578125, 0.0, 0.0, 16.456253051757812, 1.4497528076171875, 21.010656356811523, 0.0, -0.22129058837890625, 0.0, 74.04371643066406, 0.2555389404296875, 0.21390533447265625, -0.015262603759765625, 0.06891632080078125, 7.684711456298828, 0.3098945617675781, 0.07754898071289062, 0.0, 0.138885498046875, 35.95362091064453, 0.0, 44.46043395996094, 7.300010681152344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.343158721923828, 0.0, 15.665695190429688, 0.0, 0.0, 0.08678436279296875, 0.0, 0.0, 84.04475212097168, 0.0, 36.568214416503906, 46.96887969970703, 20.807518005371094, 8.911697387695312, 0.0, 42.26573944091797, -0.135101318359375, 0.006866455078125, 0.0, 0.04273223876953125, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 401, 353, 500, 500, 331, 500, 500, 500, 466, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 332, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.425015283687975, "mean_inference_ms": 3.0264335370887796, "mean_action_processing_ms": 4.192082519512135, "mean_env_wait_ms": 6.818515093028089, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24214930, "num_agent_steps_trained": 24214930, "num_env_steps_sampled": 24214930, "num_env_steps_trained": 24214930, "num_env_steps_sampled_this_iter": 61259, "num_env_steps_trained_this_iter": 61259, "timesteps_total": 24214930, "num_steps_trained_this_iter": 61259, "agent_timesteps_total": 24214930, "timers": {"training_iteration_time_ms": 31941.276, "load_time_ms": 48.508, "load_throughput": 1255567.54, "learn_time_ms": 19049.662, "learn_throughput": 3197.191, "synch_weights_time_ms": 4.742}, "counters": {"num_env_steps_sampled": 24214930, "num_env_steps_trained": 24214930, "num_agent_steps_sampled": 24214930, "num_agent_steps_trained": 24214930}, "done": false, "episodes_total": 49045, "training_iteration": 399, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-28-46", "timestamp": 1735115326, "time_this_iter_s": 30.28595757484436, "time_total_s": 12407.540262460709, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F932C20>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F8575B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 319.48878598213196, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 21.357142857142854, "ram_util_percent": 97.25714285714284}}
{"evaluation": {"episode_reward_max": 8.398910522460938, "episode_reward_min": 8.398910522460938, "episode_reward_mean": 8.398910522460938, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.398910522460938, "rewards/0_min": 8.398910522460938, "rewards/0_max": 8.398910522460938, "rewards/1_mean": 8.398910522460938, "rewards/1_min": 8.398910522460938, "rewards/1_max": 8.398910522460938, "rewards/2_mean": 8.398910522460938, "rewards/2_min": 8.398910522460938, "rewards/2_max": 8.398910522460938, "rewards/3_mean": 8.398910522460938, "rewards/3_min": 8.398910522460938, "rewards/3_max": 8.398910522460938, "rewards/4_mean": 8.398910522460938, "rewards/4_min": 8.398910522460938, "rewards/4_max": 8.398910522460938}, "hist_stats": {"episode_reward": [8.398910522460938], "episode_lengths": [500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.37463834331799634, "mean_inference_ms": 2.0582836362062333, "mean_action_processing_ms": 0.23489233496028689, "mean_env_wait_ms": 3.1790701569437108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_agent_steps_sampled_this_iter": 500, "num_env_steps_sampled_this_iter": 500, "timesteps_this_iter": 500, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0}, "custom_metrics": {"rewards/0_mean": 8.578478088378906, "rewards/0_min": -0.50482177734375, "rewards/0_max": 84.47523880004883, "rewards/1_mean": 8.578478088378906, "rewards/1_min": -0.50482177734375, "rewards/1_max": 84.47523880004883, "rewards/2_mean": 8.578478088378906, "rewards/2_min": -0.50482177734375, "rewards/2_max": 84.47523880004883, "rewards/3_mean": 8.578478088378906, "rewards/3_min": -0.50482177734375, "rewards/3_max": 84.47523880004883, "rewards/4_mean": 8.578478088378906, "rewards/4_min": -0.50482177734375, "rewards/4_max": 84.47523880004883}, "episode_media": {}, "info": {"learner": {"default_policy": {"custom_metrics": {}, "learner_stats": {"cur_kl_coeff": 0.050625000000000024, "cur_lr": 0.0001, "total_loss": -0.16747821156832354, "policy_loss": -0.00032959542513169625, "vf_loss": 0.08489965105636252, "vf_explained_var": 0.9805538750577856, "kl": 0.01182421977131593, "entropy": 25.26468745196307, "entropy_coeff": 0.009999999999999998, "grad_gnorm": 1.2819483155343268}, "model": {}, "num_grad_updates_lifetime": 6638.0, "diff_num_grad_updates_vs_sampler_policy": 6637.0}}, "num_env_steps_sampled": 24276454, "num_env_steps_trained": 24276454, "num_agent_steps_sampled": 24276454, "num_agent_steps_trained": 24276454}, "sampler_results": {"episode_reward_max": 84.47523880004883, "episode_reward_min": -0.50482177734375, "episode_reward_mean": 8.578478088378906, "episode_len_mean": 492.192, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"rewards/0_mean": 8.578478088378906, "rewards/0_min": -0.50482177734375, "rewards/0_max": 84.47523880004883, "rewards/1_mean": 8.578478088378906, "rewards/1_min": -0.50482177734375, "rewards/1_max": 84.47523880004883, "rewards/2_mean": 8.578478088378906, "rewards/2_min": -0.50482177734375, "rewards/2_max": 84.47523880004883, "rewards/3_mean": 8.578478088378906, "rewards/3_min": -0.50482177734375, "rewards/3_max": 84.47523880004883, "rewards/4_mean": 8.578478088378906, "rewards/4_min": -0.50482177734375, "rewards/4_max": 84.47523880004883}, "hist_stats": {"episode_reward": [32.5998420715332, 0.41663360595703125, 20.995494842529297, 42.76543426513672, 34.37402153015137, 0.0, 84.47523880004883, 0.0, 0.16303253173828125, 0.86676025390625, 0.2528533935546875, 0.06712722778320312, 63.71742248535156, -0.00494384765625, 19.808609008789062, 0.0, 0.0, 52.78414535522461, 46.50360107421875, 7.844306945800781, 0.0, 14.432662963867188, -0.24604034423828125, 38.89338493347168, -0.1842498779296875, 0.0, 2.2804718017578125, 0.0, 26.8571720123291, 2.80291748046875, 0.0, 0.0, 0.0, 36.2406005859375, 0.0, 0.0, 25.53852081298828, 30.146560668945312, 0.00160980224609375, 0.029022216796875, 29.897724151611328, 3.6283035278320312, 9.238037109375, 0.0, 0.0, -0.1457977294921875, 15.185823440551758, 0.0, -0.09798431396484375, 0.0, 0.0, 0.0, 17.577957153320312, 0.0, 16.951000213623047, 7.184638977050781, -0.1016998291015625, 11.82574462890625, 35.36751937866211, 0.0, 0.0, 5.87255859375, -0.10663604736328125, 0.0746307373046875, 0.0, 0.0, 42.585182189941406, 0.0, 0.0, 0.0, -0.0831146240234375, 65.65538787841797, 16.00627899169922, 0.0, 0.0, 0.0, 0.5860443115234375, 5.146097183227539, 0.0, 0.0, 12.57733154296875, 0.0, 0.0, 0.0, 8.604053497314453, -0.3369293212890625, 0.0, 0.0, 23.704940795898438, 0.0, -0.0393218994140625, 28.670021057128906, 0.0, 0.0, 31.696090698242188, 0.0, 0.0, 0.0, -0.2700958251953125, 0.0, 50.09303092956543, -0.25670623779296875, 0.0, 0.0, -0.0742340087890625, 0.16807174682617188, 0.0, 0.0, -0.015377044677734375, 0.0, -0.50482177734375, 0.0, 0.0, 0.0, 0.0, 0.06485366821289062, -0.1969757080078125, 0.30220794677734375, -0.2251434326171875, 7.867805480957031, 0.0, 43.81105041503906, 0.0, 0.0, 0.0], "episode_lengths": [408, 500, 500, 500, 303, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 392, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 367, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 463, 500, 500, 500, 500, 500, 155, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 436, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.44731233101749, "mean_inference_ms": 2.9981589026076234, "mean_action_processing_ms": 4.179244559045569, "mean_env_wait_ms": 6.811911736990397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 84.47523880004883, "episode_reward_min": -0.50482177734375, "episode_reward_mean": 8.578478088378906, "episode_len_mean": 492.192, "episodes_this_iter": 125, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [32.5998420715332, 0.41663360595703125, 20.995494842529297, 42.76543426513672, 34.37402153015137, 0.0, 84.47523880004883, 0.0, 0.16303253173828125, 0.86676025390625, 0.2528533935546875, 0.06712722778320312, 63.71742248535156, -0.00494384765625, 19.808609008789062, 0.0, 0.0, 52.78414535522461, 46.50360107421875, 7.844306945800781, 0.0, 14.432662963867188, -0.24604034423828125, 38.89338493347168, -0.1842498779296875, 0.0, 2.2804718017578125, 0.0, 26.8571720123291, 2.80291748046875, 0.0, 0.0, 0.0, 36.2406005859375, 0.0, 0.0, 25.53852081298828, 30.146560668945312, 0.00160980224609375, 0.029022216796875, 29.897724151611328, 3.6283035278320312, 9.238037109375, 0.0, 0.0, -0.1457977294921875, 15.185823440551758, 0.0, -0.09798431396484375, 0.0, 0.0, 0.0, 17.577957153320312, 0.0, 16.951000213623047, 7.184638977050781, -0.1016998291015625, 11.82574462890625, 35.36751937866211, 0.0, 0.0, 5.87255859375, -0.10663604736328125, 0.0746307373046875, 0.0, 0.0, 42.585182189941406, 0.0, 0.0, 0.0, -0.0831146240234375, 65.65538787841797, 16.00627899169922, 0.0, 0.0, 0.0, 0.5860443115234375, 5.146097183227539, 0.0, 0.0, 12.57733154296875, 0.0, 0.0, 0.0, 8.604053497314453, -0.3369293212890625, 0.0, 0.0, 23.704940795898438, 0.0, -0.0393218994140625, 28.670021057128906, 0.0, 0.0, 31.696090698242188, 0.0, 0.0, 0.0, -0.2700958251953125, 0.0, 50.09303092956543, -0.25670623779296875, 0.0, 0.0, -0.0742340087890625, 0.16807174682617188, 0.0, 0.0, -0.015377044677734375, 0.0, -0.50482177734375, 0.0, 0.0, 0.0, 0.0, 0.06485366821289062, -0.1969757080078125, 0.30220794677734375, -0.2251434326171875, 7.867805480957031, 0.0, 43.81105041503906, 0.0, 0.0, 0.0], "episode_lengths": [408, 500, 500, 500, 303, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 392, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 367, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 463, 500, 500, 500, 500, 500, 155, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 436, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.44731233101749, "mean_inference_ms": 2.9981589026076234, "mean_action_processing_ms": 4.179244559045569, "mean_env_wait_ms": 6.811911736990397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 5, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24276454, "num_agent_steps_trained": 24276454, "num_env_steps_sampled": 24276454, "num_env_steps_trained": 24276454, "num_env_steps_sampled_this_iter": 61524, "num_env_steps_trained_this_iter": 61524, "timesteps_total": 24276454, "num_steps_trained_this_iter": 61524, "agent_timesteps_total": 24276454, "timers": {"training_iteration_time_ms": 31352.749, "load_time_ms": 51.641, "load_throughput": 1179716.684, "learn_time_ms": 19018.029, "learn_throughput": 3203.339, "synch_weights_time_ms": 4.149}, "counters": {"num_env_steps_sampled": 24276454, "num_env_steps_trained": 24276454, "num_agent_steps_sampled": 24276454, "num_agent_steps_trained": 24276454}, "done": true, "episodes_total": 49170, "training_iteration": 400, "trial_id": "742dc_00000", "experiment_id": "5cc4bae0edfa4382948e6ba4b6dbc25a", "date": "2024-12-25_16-29-19", "timestamp": 1735115359, "time_this_iter_s": 32.44678330421448, "time_total_s": 12439.987045764923, "pid": 25368, "hostname": "LAPTOP-U8S8F1MK", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "transport", "env_config": {"device": "cpu", "num_envs": 24, "scenario_name": "transport", "continuous_actions": true, "max_steps": 500, "scenario_config": {"n_agents": 5}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 24, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 500, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0001, "train_batch_size": 60000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "IPPO", "custom_model_config": {"activation_fn": "tanh", "use_beta": false, "aggr": "add", "pos_start": 0, "pos_dim": 2, "vel_start": 2, "vel_dim": 2, "trainer": "MultiPPOTrainer"}, "custom_action_dist": "hom_multi_action", "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": true, "evaluation_config": {"num_envs_per_worker": 1, "env_config": {"num_envs": 1}}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 1, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 42, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.01, "sgd_minibatch_size": 4096, "num_sgd_iter": 45, "shuffle_sequences": true, "vf_loss_coeff": 1, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": Infinity, "grad_clip": 40, "kl_target": 0.01, "vf_share_layers": -1, "use_expert": false, "restore": false, "lambda": 0.9, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x000002508F940DF0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x000002508F7B35B0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'utils.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 5}, "time_since_restore": 351.93556928634644, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 18.959474802017212, "perf": {"cpu_util_percent": 20.669565217391302, "ram_util_percent": 97.03260869565217}}
